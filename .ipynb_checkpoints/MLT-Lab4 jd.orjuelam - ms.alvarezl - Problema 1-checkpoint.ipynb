{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juan David Orjuela - Sofía Álvarez López"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTRA COSA: COMO VOLVI A CORRER CROSS VALIDATION, TOCA VER CUAL ES EL MEJOR MODELO QUE ESCOGE EN CADA CASO Y CAMBIAR LO QUE HAYA ESCRITO EN ESE MOMENTO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, make_scorer\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Conv2DTranspose, AveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Laboratorio 4: Machine Learning Techniques</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema 1\n",
    "\n",
    "Utilice el conjunto de datos Fashion-MNIST para construir un clasificador de imágenes de productos. Para la construcción del modelo utilice los tres esquemas que se describen a continuación y compare los resultados:\n",
    "\n",
    "1. Entrenamiento de un perceptrón multicapa.\n",
    "2. Entrenamiento de un encoder para realizar una reducción de la dimensionalidad. Sobre el nuevo conjunto de características construya el modelo de clasificación con un perceptrón multicapa.\n",
    "3. Entrenamiento de un denoising autoendoder para preentrenar una red profunda. Reuse las primeras capas de este autoencoder para construir un perceptron multicapa (con solo el 10% de los datos).\n",
    "\n",
    "Para los puntos 2 y 3 compruebe, y muestre con ejemplos, que las imágenes están bien reconstruidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Perfilamiento y entendimiento de los datos \n",
    "En este caso, nos enfocamos en el data-set Fashion-MNIST, un conjunto de datos de 70.000 imágenes (60.000 para entrenamiento y 10.000 de test) de artículos de moda. Cada ejemplo es una imagen en escala de grises de tamaño 28x28, asociada con una etiqueta de 10 clases [1].\n",
    "\n",
    "En la imagen a continuación, podemos ver una representación del dataset, con sus respectivas etiquetas:\n",
    "<img src='fashion-MNIST.png' width=70%/>\n",
    "<p align='center'> Figura 1: Conjunto de datos Fashion-MNIST con sus respectivas etiquetas de clase.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el conjunto de datos de la librería de Tensorflow, y tomamos las imágenes de train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asimismo, dividimos el conjunto de entrenamiento en entrenamiento y validación, con una partición 80%-20%. Note que ambos conjuntos de test y validación los guardamos en la caja fuerte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiquemos que no haya valores nulos en nuestro conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X_train).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos una de las imágenes que hemos cargado en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(28)\n",
    "i = random.randint(1,len(X_train))\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_train[i] , cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que se ha cargado un zapato. Asimismo, podemos comprobar que el tamaño de la imagen es (28,28):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[i].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con la imagen de arriba, esperamos que la etiqueta de esta foto sea 7 (Sneaker):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El label de la figura es: 7\n"
     ]
    }
   ],
   "source": [
    "print('El label de la figura es:', y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el fin de facilitar el entendimiento de nuestro conjunto de datos, mapeemos la etiqueta de clase con el nombre de artículo de vestimenta relacionado, de acuerdo con la figura (1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_etiquetas = {0 : 'T-shirt/top',\n",
    "            1 : 'Trouser',\n",
    "            2 : 'Pullover',\n",
    "            3 : 'Dress',\n",
    "            4 : 'Coat',\n",
    "            5 : 'Sandal',\n",
    "            6 : 'Shirt',\n",
    "            7 : 'Sneaker',\n",
    "            8 : 'Bag',\n",
    "            9 : 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto, ya podemos visualizar algunas imágenes más de nuestro conjunto de datos y ver que los nombres (etiquetas) corresponden con el objeto mostrado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4, 4, figsize = (6,6))\n",
    "for row in axes:\n",
    "    for axe in row:\n",
    "        indice =  random.randint(0,len(X_train))\n",
    "        axe.imshow(X_train[indice], cmap='gray')\n",
    "        axe.set_title(map_etiquetas[y_train[indice]])\n",
    "        axe.set_axis_off()\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, revisemos la distribución de clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 4817]\n",
      " [   1 4819]\n",
      " [   2 4790]\n",
      " [   3 4780]\n",
      " [   4 4788]\n",
      " [   5 4850]\n",
      " [   6 4784]\n",
      " [   7 4743]\n",
      " [   8 4801]\n",
      " [   9 4828]]\n"
     ]
    }
   ],
   "source": [
    "unicos, cantidad = np.unique(y_train, return_counts=True)\n",
    "frecuencias = np.asarray((unicos, cantidad)).T\n",
    "print(frecuencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(len(frecuencias)), frecuencias[:,1],color='pink')\n",
    "plt.xticks(unicos)\n",
    "plt.xlabel('Etiqueta')\n",
    "plt.ylabel('Conteos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el conjunto de entrenamiento está aproximadamente balanceado: no hay necesidad de hacer _oversampling_ ni _subsampling_ ni considerar pesos en el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Perfilamiento y entendimiento de los datos \n",
    "Los valores de los pixeles usualmente se almacenan como números enteros en un rango entre 0 y 255. Con el fin de asegurar $\\mu = 0$ y $\\sigma^2 = 1$, hacemos una normalización (reescalamiento) para que las imágenes queden en el rango de 0 a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_val = X_val/255\n",
    "# TO DO: Escribir lo de One-Hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_val = to_categorical(y_val, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que esto no afecta la construcción de la imagen. Es exactamente igual a la que obtuvimos al inicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAACOCAYAAADn/TAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAIOUlEQVR4nO2dXYhVVRTH/8txRh0/0PxiqKFCB2VIMJBUCAxSGVMQRKF5CgwTMU0KoQzfRHrqzZeBNBCZXgqKHhwq60UzLEixcnIMInWacfzKjxEdXT3c0+2s7Z25Z9a9c8+5M/8fHO7573PvOXtm/rP3Onvvs66oKggZLuPSrgCpTmgc4oLGIS5oHOKCxiEuaBzioiTjiEiLiHSKSJeIvFuuSpHsI95xHBGpAfA7gFUALgI4BaBVVX8tX/VIVhlfwmdfANClqn8AgIh8AmA9gEGNIyIcbaw++lR1dlhYSlf1JIC/YvpiVEZGF38WKiylxUmEiLwB4I2Rvg6pLKUY5xKAxph+KiozqGobgDaAXdVoopSu6hSAJhF5VkTqALwK4IvyVItkHXeLo6oDIvImgA4ANQAOquovZasZyTTu23HXxdhVVSM/qeqSsJAjx8QFjUNc0DjEBY1DXNA4xAWNQ1zQOMQFjUNc0DjEBY1DXNA4xAWNQ1zQOMQFjUNc0DjEBY1DXNA4xAWNQ1zQOMQFjUNc0DjEBY1DXNA4xAWNQ1zQOMQFjUNc0DjEBY1DXIx4YqVqQUSMHk4yhnHj7P/fo0ePylKnSly/trbW6AcPHiS7ZuIrEBKjqHFE5KCI9IrI2VjZEyLylYicj15njGw1SdZI0uJ8DKAlKHsXwDeq2gTgm0iTMUSixEoi8gyAL1X1uUh3AnhJVbtFpAHAd6q6IMF5MptYqZQYJ2TatGlG19fXG719+3aj9+/fb3R/f7/RpcQwZYi/yppYaa6qdkf7fwOY6zwPqVJKvqtSVR2qJWG62tGJt8XpibooRK+9g71RVdtUdUmh5o5UL94W5wsArwH4IHr9vGw1Ssj48bbqAwMDJZ2vlJjmwIEDRm/YsMHoMK64d++e0UeOHDH63LlzQ35+OBT7bGtrq9Ht7e2JzpvkdrwdwPcAFojIRRF5HTnDrBKR8wBWRpqMIYq2OKraOsihl8tcF1JFcOSYuEh1rqqmpmZY74/HIaXGNMWYOHGi0SdPnhxUb9261Rw7ceKE0XPmzDH67t27Rq9cudLoMMYphZYWO3bb1tZmdGNjo9HHjh0zuqenp+B52eIQFzQOcUHjEBepxjgPHz6s2LXCcZ9du3YZff/+faO3bNli9OTJkwc938KFC82xWbNmGb1z506j169fb/SePXuMXrx4sdHHjx83OpwLW7LEjq3GY6YJEyaYY3fu3DG6u7vb6NWrVxt9+PBhFIItDnFB4xAXqX5f1ZQpU8zxBQvsyox169YZPW/evPz+2rVrzbHTp08bffToUaN3795tdG+vnV6bP3++0V1dXUYvX77c6KVLl+b3t23bZo6tWLHC6HDY4fr160aHyy7Cri5cGlGMW7du5ffDnzP8e4c/96FDh4zevHkzv6+KlA8ah7igcYiLisY49fX12tTUlNfhrd6iRYuMvnTJfht1fKg+7PdDHU5JhLel4e13uNQhfGxkxgy7Hn/u3P8XPYZLF65cuWJ0POYAHo95wr9BON0RLiUtxu3bt/P7YfwU3o6HMU5HR4fRGzduZIxDygeNQ1zQOMRFRacc+vv7cebMmbwOh9537Nhh9Jo1a4yOxzFhzFIsVguXMhRb0hHGLTdv3jT66tWr+f1wOiMkjJeKLQm5du3akMeLLZuNXy+c1gmnKyZNmmR0Q0PDkNf+D7Y4xAWNQ1zQOMRFRcdxamtrdfr06Xnd19c3rM9v2rSp4D4ALFu2zOhwSSRJxr59+4zeu3cvx3FI+aBxiAsah7hIdT1OOB4RPkYSphUL54CGIhw7CXVdXZ3R8dgLeHy8Y+bMmUZfvnw5vx/Oc4WEY0LFHssNx5jCebjwePizxee2bty4YY6Fv9Pw3PE5OAC4cOECYxxSPmgc4oLGIS5SfTwmnGOJxw2FmDp1an4/7Ndnz55tdHNz85DnCmO7cJ1KfC4KeHztbnxdcBirFYtJiqWNC3WxmGiouCVcxx0S1jV8XGbQzyV6FyEBSfLjNIrItyLyq4j8IiJvReVMWTuGSdLiDAB4R1WbASwDsF1EmsGUtWMbVR3WhlzatlUAOgE0RGUNADoTfFa5Vd32Y6G/5bBinCjf8fMAfgBT1o5pEt9VicgUAJ8C2KWq/8TvDIZKWct0taOUhN1TLYAOAG/HythVjY3N11VJrmn5CMBvqvph7NB/KWuBlFLWkhRJ0Eq8iJzzzgD4OdpeATATubup8wC+BvAEW5xRuRVscVKdHSdVAWfHSfmgcYgLGoe4oHGICxqHuKBxiAsah7igcYgLGoe4oHGICxqHuKBxiAsah7igcYgLGoe4oHGICxqHuKBxiAsah7igcYgLGoe4oHGICxqHuKBxiItKp3LrA/AngFnRfhbJat3SqtfThQor+iRn/qIiPxZ6OjALZLVuWasXuyrigsYhLtIyTltK101CVuuWqXqlEuOQ6oddFXFRUeOISIuIdIpIl4ikmt5WRA6KSK+InI2VZSJ3czXklq6YcUSkBsABAGsANANojfIlp8XHAFqCsqzkbs5+bunh5jn2bgCWA+iI6fcAvFep6w9Sp2cAnC0lIWaF6unOLT1SWyW7qicB/BXTF6OyLJG53M1ZzS3N4HgQNPdvneotZ5hbOn4s7fpV0jiXAMS/0/mpqCxL9IhIAwBEr71F3j9iiEgtcqY5oqqfZa1+lTTOKQBNIvKsiNQBeBW5XMlZIhO5m6sit3SFg7xXAPwO4AKA91MOONsBdAN4gFy89TocuZtHqG5lyy09UhtHjokLBsfEBY1DXNA4xAWNQ1zQOMQFjUNc0DjEBY1DXPwLIKZ56OfMiEwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_train[i] , cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Modelamiento\n",
    "### 1.3.1 Entrenamiento de un perceptrón multicapa\n",
    "El primer modelo que entrenaremos será un perceptrón multicapa. Tenemos varias opciones para implementarlo, dos de ellas son las más interesantes. Primero, como en el laboratorio pasado, podríamos aplanar la imagen y dársela como input a las capas de la red. La segunda opción es utilizar algunas capas convolucionales, las cuales han demostrado un gran desempeño en aplicaciones con imágenes [2]. En este ocasión, usaremos esta segunda opción: ¡queremos obtener los mejores resultados posibles!\n",
    "\n",
    "Como siempre, primero planteamos un modelo base, cuyos hiperparámetros ajustamos después.\n",
    "https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-fashion-mnist-clothing-classification/ \n",
    "https://blog.tensorflow.org/2018/04/fashion-mnist-with-tfkeras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1.1 Modelo inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo inicial, que será nuestro baseline, se conformará de dos partes: el front-end de extracción de características compuesto por capas convolucionales y de pooling, y el back-end clasificador que hará una predicción.\n",
    "\n",
    "Consideremos primero un modelo con una sola capa convolucional, con un tamaño de kernel pequeño (3,3) y una cantidad modesta de filtros (32 - usualmente se acostumbra poner entre 32 y 512 filtros por capa -), que utiliza <code>padding='same'</code> seguida de una capa de max pooling, que hará un pooling (2,2) como se acostumbra hacer [3]. Añadimos posteriormente una capa de aplanamiento, con el fin de pasarle las _features_ a las capas densas. Para nuestro modelo baseline, consideramos únicamente una capa densa, de 256 neuronas. Realmente, esta cantidad de neuronas es una decisión un poco arbitraria. Una forma naïve de calcular el número de neuronas de la capa oculta es que sea menos del doble de las de la capa de entrada [5]. No obstante, esas serían muchísimas neuronas en nuestro caso (pues la entrada de la capa densa es la imagen aplanada, después de pasar por la capa convolucional y maxpooling: $14 \\times 14 \\times 32 = 6272$, donde 32 es el número de filtros). Por lo tanto, seguramente habría overfitting y el costo computacional es inmenso. Tomamos 256 neuronas pues no son muy pocas, tal que haga underfitting, pero tampoco muchas. No obstante, este es un hiperparámetro que debemos ajustar más adelante. Para nuestro primer modelo naïve, utilizamos una única capa oculta. Esto es porque estamos intentando crear un modelo simple. No obstante, este será uno de los hiperparámetros que ajustaremos.\n",
    "\n",
    "Asimismo, antes de la capa de aplanamiento y después de la capa densa de 256 neuronas, ponemos una capa de dropout. Esto lo hacemos con fines de regularización de nuestro modelo. La máxima regularización corresponde a $p = 0.5$. Esta es la que utilizaremos para la segunda capa dropout (i.e. después de la capa densa de 128 neuronas). La primera considerará un valor de 0.3, pues no queremos limitar tanto el aprendizaje en las capas convolucionales. Esto también lo ajustaremos como hiperparámetro, pero es un buen punto de partida para nuestro primer modelo [6].\n",
    "\n",
    "Ahora, todas nuestras capas utilizan ReLu como función de activación. De acuerdo con la literatura, la función ReLu es la más utilizada en aplicaciones de Machine Learning. En la práctica, además, tiende a tener mejor convergencia que la sigmoide o la tanh [3]. Asimismo, la función de activación ReLu es la que corre en el menor tiempo de cómputo (es menos costoso calcular $\\max(0,a)$, donde a es la entrada de la neurona, que calcular, por ejemplo $(1+e^{-a})^{-1}$, para la logística). Por último, en varias aplicaciones y artículos, se ha visto que ReLu se desempeña muy bien en casi todos los casos. Y si hay otras mejores, en realidad la mejoría es muy baja [4]. Por lo tanto, por lo general (y sobre todo para problemas complejos como este), no vale la pena buscar una función de activación diferente. También utilizamos el esquema de inicialización de pesos He, con <code>he_uniform</code> pues se considera buena práctica [5].\n",
    "\n",
    "Finalmente, tenemos la capa de salida: compuesta por 10 neuronas (pues tenemos 10 clases), con función de activación softmax. Esta se usa con frecuencia en clasificación multiclase, por lo que es una decisión completamente adecuada para la salida de nuestra red. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 10 # pues tenemos 10 clases\n",
    "# Inicializamos el modelo\n",
    "baseline_MLP = Sequential(name='Baseline_MLP') \n",
    "# Agregamos una capa convolucional con 32 filtros, con un kernel pequenio, funcion de activacion relu e \n",
    "# inicializador he_uniform. Especificamos tambien las dimensiones de la entrada (28,28,1) donde el 1 significa\n",
    "# que esta en escala de grises.\n",
    "baseline_MLP.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', \n",
    "                        input_shape=(28, 28, 1), padding='same'))\n",
    "# Capa de max pooling de tamanio de pool 2x2.\n",
    "baseline_MLP.add(MaxPooling2D((2, 2)))\n",
    "# Definimos la tasa de dropout para la parte convolucional\n",
    "baseline_MLP.add(Dropout(0.3))\n",
    "# Ponemos la capa de aplanamiento, para crear la capa densa\n",
    "baseline_MLP.add(Flatten())\n",
    "# Creamos la capa densa, de 256 neuronas, con funcion de activacion relu y kernel de inicializacion he_uniform\n",
    "baseline_MLP.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "# Definimos la tasa de dropout para la parte MLP\n",
    "baseline_MLP.add(Dropout(0.5))\n",
    "# Definimos la capa de salida, con funcion de activacion softmax, y 10 neuronas pues tenemos 10 clases\n",
    "baseline_MLP.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí, veamos cómo vamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Baseline_MLP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,608,778\n",
      "Trainable params: 1,608,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_MLP.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ahora, debemos elegir una métrica, una función de pérdida y un optimizador. En cuanto a la función de pérdida, la que se usa con frecuencia en problemas de clasificación es la de entropía cruzada. De hecho, se recomienda no cambiarla, a menos de que se tenga una razón lo suficientemente fuerte para hacerlo, pues es la función de pérdida preferida en el marco de la máxima verosimilitud. Para problemas multiclase, donde se tiene OneHotEncoding, se utiliza entropía cruzada categórica: categorical_crossentropy [7].\n",
    "\n",
    "En el caso del optimizador, elegimos adam. Por lo general, este es el que mejores resultados presenta, de acuerdo con la literatura, con el valor por defecto de tasa de aprendizaje de 0.001. Asimismo, nos quitamos de encima el ajustar un hiperparámetro extra (la tasa de aprendizaje), pues los algoritmos adaptativos como Adam van ajustando esta tasa a medida que entrenan [8]. Últimamente se ha visto que SGD, acompañado de un buen learning rate, puede arrojar resultados excelentes también. No obstante, esto implica el ajuste de un hiperparámetro que, dada la complejidad del problema, puede ser muy costosa computacionalmente.\n",
    "\n",
    "Asimismo, debemos definir la métrica que informa el éxito del modelo. En este caso elegimos la exactitud (accuracy) como métrica, pues el usuario aspira poder diagnosticar de forma amplia sobre las diez categorías. En consecuencia, tiene más sentido utilizar una métrica que reporte el éxito general del modelo sin privilegiar una categoría sobre otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_MLP.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Control de la complejidad y los tiempos de procesamiento**\n",
    "\n",
    "Una forma de controlar la complejidad y los tiempos de procesamiento es mediante el uso de callbacks. Estas son acciones durante las etapas del entrenamiento.\n",
    "\n",
    "De acuerdo con la documentación de Tensorflow, encontramos dos callbacks que consideramos útiles para este laboratorio. Primero, consideramos EarlyStopping. En este caso, ponemos la cantidad monitoreada como la medida que tomamos a la pérdida (loss) tal que, si después de 3 épocas no ha mejorado, entonces pare el entrenamiento y la actualización de los pesos.\n",
    "\n",
    "El otro callback que utilizaremos es TensorBoard. Este permite visualizar un reporte del entrenamiento, el cual nos será útil para concluir sobre el avance del modelo en función de los diferentes ciclos de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=1, mode='auto', baseline=None, restore_best_weights=False)\n",
    "tensorboard_callback = TensorBoard(log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), histogram_freq=0, write_graph=True, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=0, embeddings_metadata=None,)\n",
    "callbacks = [early_stopping,tensorboard_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.5278 - accuracy: 0.8116 - val_loss: 0.3383 - val_accuracy: 0.8777\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.3488 - accuracy: 0.8760 - val_loss: 0.3079 - val_accuracy: 0.8851\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 0.3038 - accuracy: 0.8895 - val_loss: 0.2661 - val_accuracy: 0.9042\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.2758 - accuracy: 0.8973 - val_loss: 0.2591 - val_accuracy: 0.9037\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.2604 - accuracy: 0.9035 - val_loss: 0.2434 - val_accuracy: 0.9112\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 0.2461 - accuracy: 0.9096 - val_loss: 0.2369 - val_accuracy: 0.9126\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 0.2317 - accuracy: 0.9133 - val_loss: 0.2503 - val_accuracy: 0.9095\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.2211 - accuracy: 0.9170 - val_loss: 0.2352 - val_accuracy: 0.9144\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.2093 - accuracy: 0.9218 - val_loss: 0.2323 - val_accuracy: 0.9163\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 11s 45ms/step - loss: 0.2035 - accuracy: 0.9229 - val_loss: 0.2309 - val_accuracy: 0.9176\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 0.1950 - accuracy: 0.9263 - val_loss: 0.2279 - val_accuracy: 0.9190\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 0.1868 - accuracy: 0.9308 - val_loss: 0.2295 - val_accuracy: 0.9158\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.1798 - accuracy: 0.9334 - val_loss: 0.2267 - val_accuracy: 0.9203\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 11s 45ms/step - loss: 0.1764 - accuracy: 0.9333 - val_loss: 0.2335 - val_accuracy: 0.9187\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 0.1702 - accuracy: 0.9358 - val_loss: 0.2298 - val_accuracy: 0.9169\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.1642 - accuracy: 0.9372 - val_loss: 0.2358 - val_accuracy: 0.9201\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.1593 - accuracy: 0.9392 - val_loss: 0.2218 - val_accuracy: 0.9226\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.1519 - accuracy: 0.9421 - val_loss: 0.2301 - val_accuracy: 0.9220\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 0.1495 - accuracy: 0.9439 - val_loss: 0.2253 - val_accuracy: 0.9244\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.1475 - accuracy: 0.9439 - val_loss: 0.2268 - val_accuracy: 0.9228\n"
     ]
    }
   ],
   "source": [
    "history_mlp_baseline = baseline_MLP.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=20, batch_size=200, callbacks=callbacks,\n",
    "                    validation_data=(\n",
    "                    X_val.reshape(-1, 28, 28, 1), \n",
    "                    y_val\n",
    "                    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='first.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Comentar resultados**\n",
    "\n",
    "----\n",
    "#### 1.3.1.2 Modelo MLP con búsqueda de hiperparámetros\n",
    "Ahora, queremos realizar la búsqueda de _algunos_ hiperparámetros para nuestro modelo. Decimos _algunos_ pues buscar todos los del espacio de hiperparámetros es prácticamente imposible con el poder de cómputo con el que contamos. \n",
    "\n",
    "Hay muchos hiperparámetros por afinar en el modelo que en principio podríamos seguir buscando mediante la función de GridSearch. Sin embargo, no es recomendable pues nos encontramos en un universo enorme de hiperparámetros si deseamos hacer una búsqueda exhaustiva.\n",
    "\n",
    "Por ello construimos una función que nos permita especificar la Red Neuronal esperada y utilizamos la función RandomizedSearchCV, que no hace una búsqueda exhaustiva sino aleatoria sobre algunas configuraciones del espacio de hiperparámetros, lo que es mucho más eficiente en términos de tiempo y poder computacional demandado.\n",
    "\n",
    "Los parámetros que son más importantes de ajustar son el número de neuronas por capa, el número total de capas y la tasa de dropout. Note que también podríamos ajustar los hiperparámetros de las capas convolucionales. No obstante, como no hemos visto esto aún en clase, dejamos los que teníamos para nuestro modelo inicial. Definimos entonces una función que nos permita hacer esto a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_red(nn1=256, nn2=256, n_layers= 3, dropout_conv = 0.1, dropout_dense=0.5):\n",
    "    output = 10 # Tenemos 10 neuronas en la capa oculta pues son las 10 clases de salida\n",
    "    clf = Sequential(name='MLP_CV')\n",
    "    clf.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', \n",
    "                        input_shape=(28, 28, 1), padding='same'))\n",
    "    # Capa de max pooling de tamanio de pool 2x2.\n",
    "    clf.add(MaxPooling2D((2, 2)))\n",
    "    # Capa de dropout tras convolución, con hiperparámetro a ajustar\n",
    "    clf.add(Dropout(dropout_conv, name='Dropout_conv_{0}'.format(dropout_conv))) # Dropout conv\n",
    "    clf.add(Flatten())\n",
    "    first = True\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            clf.add(Dense(nn1, activation='relu', name='Capa_Oculta_{0}'.format(i))) # num neuronas capa 1\n",
    "            first = False\n",
    "        else:\n",
    "            clf.add(Dense(nn2, activation='relu', name = 'Capa_Oculta_{0}'.format(i))) # num neuronas capa 2 y 3\n",
    "\n",
    "            \n",
    "    \n",
    "    clf.add(Dropout(dropout_dense,name='Dropout_dense_{0}'.format(dropout_dense))) # Dropout (parecido a regularizacion)\n",
    "    clf.add(Dense(output, activation='softmax', name= 'Capa_Salida')) # Capa de salidad\n",
    "\n",
    "    clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # Valores por defecto\n",
    "    \n",
    "    return clf\n",
    "\n",
    "# Modelo que utiliza el GridSearch\n",
    "modelCV_mlp = KerasClassifier(build_fn=entrenar_red, epochs=20, batch_size=500,verbose=1) # Modelo esqueleto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con nuestro código, la segunda y la tercera capa (cuando haya) siempre tendrán nn2 neuronas. Hacemos esto para que no aumentar el espacio de búsqueda de hiperparámetros.\n",
    "\n",
    "Debemos generar una métrica propia para la accuracy, para que la CV funcione bien y no haya problema con las dimensionalidad de y_true y y_pred:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_loss_func(y_true, y_pred):\n",
    "    return accuracy_score(y_true.argmax(1), y_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1 = Pipeline([('best_MLP', modelCV_mlp)]) # Creamos la pipeline\n",
    "\n",
    "# Tomamos la grilla de hiperparametros \n",
    "param_grid = dict(\n",
    "                  best_MLP__nn1 = [64,128,256],\n",
    "                  best_MLP__nn2 = [64,128,256],\n",
    "                  best_MLP__n_layers = [1,2,3],\n",
    "                  best_MLP__dropout_conv = [0.1,0.25,0.5],\n",
    "                  best_MLP__dropout_dense = [0.1,0.25,0.5]\n",
    "                  )\n",
    "\n",
    "# Definimos la metrica \n",
    "score = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "# Creamos la grilla\n",
    "# Podriamos usar mas iteraciones en el CV, pero lo intentamos correr y se murio el kernel.\n",
    "# Por eso lo redujimos\n",
    "grid = RandomizedSearchCV(pipe_1, param_grid, scoring=score, verbose=3, cv=3, n_iter=10, random_state=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de correr, unimos los conjuntos de entrenamiento y validación para hacer la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_joined_train = np.array(list(X_train) + list(X_val))\n",
    "y_joined_train = np.array(list(y_train) + list(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.6374 - accuracy: 0.7762\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.3485 - accuracy: 0.8759\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2948 - accuracy: 0.8929\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2611 - accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.2370 - accuracy: 0.9116\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2136 - accuracy: 0.9204\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.1904 - accuracy: 0.9300\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.1774 - accuracy: 0.9334\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.1630 - accuracy: 0.9391\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.1498 - accuracy: 0.9445\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.1404 - accuracy: 0.9475\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.1330 - accuracy: 0.9507\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.1199 - accuracy: 0.9556\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.1098 - accuracy: 0.9596\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1047 - accuracy: 0.9602\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.0915 - accuracy: 0.9658\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.0888 - accuracy: 0.9674\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0870 - accuracy: 0.9675\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.0810 - accuracy: 0.9699\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0703 - accuracy: 0.9735\n",
      "[CV 1/3] END best_MLP__dropout_conv=0.1, best_MLP__dropout_dense=0.25, best_MLP__n_layers=3, best_MLP__nn1=64, best_MLP__nn2=256;, score=0.914 total time= 2.7min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.6349 - accuracy: 0.7722\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.3639 - accuracy: 0.8699\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.3176 - accuracy: 0.8846\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.2764 - accuracy: 0.8997\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2493 - accuracy: 0.9090\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.2261 - accuracy: 0.9171\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.2099 - accuracy: 0.9233\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1952 - accuracy: 0.9279\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.1842 - accuracy: 0.9315\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.1688 - accuracy: 0.9376\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1593 - accuracy: 0.9405\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.1497 - accuracy: 0.9430\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1361 - accuracy: 0.9496\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1253 - accuracy: 0.9534\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1156 - accuracy: 0.9572\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1116 - accuracy: 0.9583\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.1020 - accuracy: 0.9631\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.0946 - accuracy: 0.9653\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0859 - accuracy: 0.9675\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.0846 - accuracy: 0.9678\n",
      "[CV 2/3] END best_MLP__dropout_conv=0.1, best_MLP__dropout_dense=0.25, best_MLP__n_layers=3, best_MLP__nn1=64, best_MLP__nn2=256;, score=0.913 total time= 2.9min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 103ms/step - loss: 0.6705 - accuracy: 0.7568\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3766 - accuracy: 0.8650\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.3161 - accuracy: 0.8848\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 9s 119ms/step - loss: 0.2838 - accuracy: 0.8970\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2589 - accuracy: 0.9047\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2372 - accuracy: 0.9116\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2239 - accuracy: 0.9186\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2010 - accuracy: 0.9258\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1884 - accuracy: 0.9292\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1773 - accuracy: 0.9338\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1635 - accuracy: 0.9392\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.1597 - accuracy: 0.9398\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1455 - accuracy: 0.9460\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.1407 - accuracy: 0.9466\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.1309 - accuracy: 0.9506\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1209 - accuracy: 0.9550\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1126 - accuracy: 0.9583\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1034 - accuracy: 0.9618\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0986 - accuracy: 0.9627\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.0967 - accuracy: 0.9632\n",
      "[CV 3/3] END best_MLP__dropout_conv=0.1, best_MLP__dropout_dense=0.25, best_MLP__n_layers=3, best_MLP__nn1=64, best_MLP__nn2=256;, score=0.913 total time= 2.8min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.6099 - accuracy: 0.7785\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.3827 - accuracy: 0.8605\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3309 - accuracy: 0.8787\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2977 - accuracy: 0.8921\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2731 - accuracy: 0.8987\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2574 - accuracy: 0.9049\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2448 - accuracy: 0.9099\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.2325 - accuracy: 0.9133\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.2201 - accuracy: 0.9189\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.2091 - accuracy: 0.9224\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2046 - accuracy: 0.9239\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.1941 - accuracy: 0.9285\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.1884 - accuracy: 0.9295\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1788 - accuracy: 0.9333\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1764 - accuracy: 0.9328\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.1683 - accuracy: 0.9377\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 9s 106ms/step - loss: 0.1635 - accuracy: 0.9379\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.1557 - accuracy: 0.9419\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.1534 - accuracy: 0.9426\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.1454 - accuracy: 0.9465\n",
      "[CV 1/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.1, best_MLP__n_layers=1, best_MLP__nn1=128, best_MLP__nn2=256;, score=0.923 total time= 2.9min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.5882 - accuracy: 0.7912\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.3678 - accuracy: 0.8699\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.3242 - accuracy: 0.8847\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2966 - accuracy: 0.8912\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2688 - accuracy: 0.9022\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.2598 - accuracy: 0.9045\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2428 - accuracy: 0.9104\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2304 - accuracy: 0.9159\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2249 - accuracy: 0.9166\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2115 - accuracy: 0.9228\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.2013 - accuracy: 0.9265\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.1949 - accuracy: 0.9266\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.1906 - accuracy: 0.9289\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.1807 - accuracy: 0.9318\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1737 - accuracy: 0.9370\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.1673 - accuracy: 0.9380\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.1628 - accuracy: 0.9391\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.1561 - accuracy: 0.9422\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.1498 - accuracy: 0.9448\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.1503 - accuracy: 0.9437\n",
      "[CV 2/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.1, best_MLP__n_layers=1, best_MLP__nn1=128, best_MLP__nn2=256;, score=0.919 total time= 2.9min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.7313 - accuracy: 0.7501\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.4199 - accuracy: 0.8499\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.3670 - accuracy: 0.8674\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.3302 - accuracy: 0.8802\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3100 - accuracy: 0.8872\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.2907 - accuracy: 0.8928\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.2779 - accuracy: 0.8989\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.2638 - accuracy: 0.9039\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.2562 - accuracy: 0.9050\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.2434 - accuracy: 0.9101\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.2343 - accuracy: 0.9128\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.2278 - accuracy: 0.9165\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.2187 - accuracy: 0.9206\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.2103 - accuracy: 0.9215\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.2030 - accuracy: 0.9244\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1995 - accuracy: 0.9251\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1938 - accuracy: 0.9290\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.1907 - accuracy: 0.9292\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1842 - accuracy: 0.9320\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.1804 - accuracy: 0.9330\n",
      "[CV 3/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.1, best_MLP__n_layers=1, best_MLP__nn1=128, best_MLP__nn2=256;, score=0.916 total time= 2.9min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.0192 - accuracy: 0.6339\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.6486 - accuracy: 0.7704\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.5684 - accuracy: 0.7964\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.5181 - accuracy: 0.8140\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.4881 - accuracy: 0.8232\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.4701 - accuracy: 0.8294\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.4468 - accuracy: 0.8364\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.4321 - accuracy: 0.8440\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.4204 - accuracy: 0.8467\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.4058 - accuracy: 0.8537\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.3970 - accuracy: 0.8553\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3845 - accuracy: 0.8589\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3771 - accuracy: 0.8623\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.3762 - accuracy: 0.8622\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.3659 - accuracy: 0.8656\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.3609 - accuracy: 0.8661\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.3523 - accuracy: 0.8689\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3549 - accuracy: 0.8687\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.3497 - accuracy: 0.8684\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.3432 - accuracy: 0.8734\n",
      "[CV 1/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.5, best_MLP__n_layers=1, best_MLP__nn1=64, best_MLP__nn2=256;, score=0.904 total time= 2.9min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 1.1118 - accuracy: 0.6018\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.7038 - accuracy: 0.7498\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.6137 - accuracy: 0.7796\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.5539 - accuracy: 0.8013\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.5207 - accuracy: 0.8130\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.5041 - accuracy: 0.8187\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.4739 - accuracy: 0.8307\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.4575 - accuracy: 0.8348\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.4388 - accuracy: 0.8422\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.4311 - accuracy: 0.8431\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.4274 - accuracy: 0.8465\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 9s 111ms/step - loss: 0.4103 - accuracy: 0.8516\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.4029 - accuracy: 0.8546\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.3966 - accuracy: 0.8558\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.3885 - accuracy: 0.8587\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3843 - accuracy: 0.8599\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.3771 - accuracy: 0.8620\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.3660 - accuracy: 0.8665\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.3611 - accuracy: 0.8681\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.3619 - accuracy: 0.8678\n",
      "[CV 2/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.5, best_MLP__n_layers=1, best_MLP__nn1=64, best_MLP__nn2=256;, score=0.901 total time= 3.0min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 10s 114ms/step - loss: 0.8578 - accuracy: 0.6963\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.5346 - accuracy: 0.8161\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.4641 - accuracy: 0.8376\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.4279 - accuracy: 0.8486\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.3984 - accuracy: 0.8591\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3825 - accuracy: 0.8639\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3668 - accuracy: 0.8701\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3592 - accuracy: 0.8705\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3448 - accuracy: 0.8771\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3373 - accuracy: 0.8796\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.3303 - accuracy: 0.8820\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.3236 - accuracy: 0.8824\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3170 - accuracy: 0.8841\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.3160 - accuracy: 0.8852\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.3097 - accuracy: 0.8879\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3006 - accuracy: 0.8910\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.3018 - accuracy: 0.8895\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.2965 - accuracy: 0.8914\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2928 - accuracy: 0.8923\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.2864 - accuracy: 0.8958\n",
      "[CV 3/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.5, best_MLP__n_layers=1, best_MLP__nn1=64, best_MLP__nn2=256;, score=0.906 total time= 3.1min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 10s 106ms/step - loss: 0.7128 - accuracy: 0.7502\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.4004 - accuracy: 0.8590\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.3380 - accuracy: 0.8792\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.2959 - accuracy: 0.8929\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.2725 - accuracy: 0.9001\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.2446 - accuracy: 0.9104\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2285 - accuracy: 0.9155\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2141 - accuracy: 0.9199\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.2012 - accuracy: 0.9264\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1825 - accuracy: 0.9323\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1709 - accuracy: 0.9375\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1618 - accuracy: 0.9401\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1480 - accuracy: 0.9461\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1424 - accuracy: 0.9473\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1336 - accuracy: 0.9506\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1233 - accuracy: 0.9553\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1126 - accuracy: 0.9592\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1089 - accuracy: 0.9599\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1008 - accuracy: 0.9633\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.0938 - accuracy: 0.9662\n",
      "[CV 1/3] END best_MLP__dropout_conv=0.1, best_MLP__dropout_dense=0.1, best_MLP__n_layers=2, best_MLP__nn1=256, best_MLP__nn2=64;, score=0.917 total time= 2.8min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.7280 - accuracy: 0.7413\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.4338 - accuracy: 0.8450\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.3690 - accuracy: 0.8674\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.3315 - accuracy: 0.8792\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3022 - accuracy: 0.8907\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2744 - accuracy: 0.9004\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2551 - accuracy: 0.9076\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2358 - accuracy: 0.9134\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2241 - accuracy: 0.9183\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2084 - accuracy: 0.9240\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2006 - accuracy: 0.9264\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1834 - accuracy: 0.9337\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1701 - accuracy: 0.9377\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1652 - accuracy: 0.9388\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1532 - accuracy: 0.9439\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1449 - accuracy: 0.9466\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1338 - accuracy: 0.9510\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1273 - accuracy: 0.9536\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1191 - accuracy: 0.9564\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1120 - accuracy: 0.9580\n",
      "[CV 2/3] END best_MLP__dropout_conv=0.1, best_MLP__dropout_dense=0.1, best_MLP__n_layers=2, best_MLP__nn1=256, best_MLP__nn2=64;, score=0.917 total time= 2.8min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.6765 - accuracy: 0.7541\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3926 - accuracy: 0.8623\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3278 - accuracy: 0.8826\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2897 - accuracy: 0.8950\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2585 - accuracy: 0.9058\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2401 - accuracy: 0.9114\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2195 - accuracy: 0.9193\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2015 - accuracy: 0.9262\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1903 - accuracy: 0.9299\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1781 - accuracy: 0.9344\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1698 - accuracy: 0.9381\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1527 - accuracy: 0.9436\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1440 - accuracy: 0.9481\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1338 - accuracy: 0.9514\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1256 - accuracy: 0.9546\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1185 - accuracy: 0.9575\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.1092 - accuracy: 0.9598\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.0988 - accuracy: 0.9641\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0941 - accuracy: 0.9653\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0879 - accuracy: 0.9671\n",
      "[CV 3/3] END best_MLP__dropout_conv=0.1, best_MLP__dropout_dense=0.1, best_MLP__n_layers=2, best_MLP__nn1=256, best_MLP__nn2=64;, score=0.913 total time= 2.8min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 103ms/step - loss: 0.8751 - accuracy: 0.6867\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.4769 - accuracy: 0.8321\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3992 - accuracy: 0.8614\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3613 - accuracy: 0.8730\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3338 - accuracy: 0.8809\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3083 - accuracy: 0.8882\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2951 - accuracy: 0.8926\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2791 - accuracy: 0.8989\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2694 - accuracy: 0.9012\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2621 - accuracy: 0.9053\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2528 - accuracy: 0.9066\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2483 - accuracy: 0.9077\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2367 - accuracy: 0.9124\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2291 - accuracy: 0.9158\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2289 - accuracy: 0.9149\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2174 - accuracy: 0.9196\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2138 - accuracy: 0.9220\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2083 - accuracy: 0.9228\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2039 - accuracy: 0.9258\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1954 - accuracy: 0.9280\n",
      "[CV 1/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.5, best_MLP__n_layers=2, best_MLP__nn1=64, best_MLP__nn2=128;, score=0.916 total time= 2.7min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 103ms/step - loss: 0.8289 - accuracy: 0.7098\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.4562 - accuracy: 0.8429\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.3917 - accuracy: 0.8638\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.3544 - accuracy: 0.8743\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.3271 - accuracy: 0.8837\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.3126 - accuracy: 0.8888\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2932 - accuracy: 0.8963\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2820 - accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2723 - accuracy: 0.9032\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2605 - accuracy: 0.9067\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2551 - accuracy: 0.9076\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2451 - accuracy: 0.9108\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2416 - accuracy: 0.9134\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2329 - accuracy: 0.9158\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2256 - accuracy: 0.9191\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2196 - accuracy: 0.9206\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2182 - accuracy: 0.9204\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2112 - accuracy: 0.9232\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2085 - accuracy: 0.9233\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.1999 - accuracy: 0.9277\n",
      "[CV 2/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.5, best_MLP__n_layers=2, best_MLP__nn1=64, best_MLP__nn2=128;, score=0.916 total time= 2.7min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.9683 - accuracy: 0.6595\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.5009 - accuracy: 0.8255\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.4174 - accuracy: 0.8555\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.3798 - accuracy: 0.8697\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.3495 - accuracy: 0.8758\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.3270 - accuracy: 0.8852\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.3097 - accuracy: 0.8896\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3002 - accuracy: 0.8938\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2896 - accuracy: 0.8957\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2795 - accuracy: 0.8986\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2691 - accuracy: 0.9038\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2629 - accuracy: 0.9061\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2571 - accuracy: 0.9072\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2526 - accuracy: 0.9087\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2468 - accuracy: 0.9115\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2382 - accuracy: 0.9136\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2336 - accuracy: 0.9154\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2283 - accuracy: 0.9171\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2274 - accuracy: 0.9179\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2200 - accuracy: 0.9204\n",
      "[CV 3/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.5, best_MLP__n_layers=2, best_MLP__nn1=64, best_MLP__nn2=128;, score=0.910 total time= 2.7min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 103ms/step - loss: 0.8462 - accuracy: 0.6970\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 8s 100ms/step - loss: 0.4480 - accuracy: 0.8436\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.3763 - accuracy: 0.8664\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.3363 - accuracy: 0.8792\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.3023 - accuracy: 0.8938\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2871 - accuracy: 0.8974\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2680 - accuracy: 0.9046\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2563 - accuracy: 0.9072\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2415 - accuracy: 0.9112\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2291 - accuracy: 0.9161\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2202 - accuracy: 0.9197\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2111 - accuracy: 0.9230\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2036 - accuracy: 0.9254\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2044 - accuracy: 0.9256\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.1894 - accuracy: 0.9298\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.1874 - accuracy: 0.9305\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1758 - accuracy: 0.9363\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1740 - accuracy: 0.9355\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1653 - accuracy: 0.9393\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1617 - accuracy: 0.9403\n",
      "[CV 1/3] END best_MLP__dropout_conv=0.25, best_MLP__dropout_dense=0.25, best_MLP__n_layers=3, best_MLP__nn1=64, best_MLP__nn2=64;, score=0.917 total time= 2.7min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.7975 - accuracy: 0.7121\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.4434 - accuracy: 0.8480\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.3756 - accuracy: 0.8681\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.3323 - accuracy: 0.8813\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.3006 - accuracy: 0.8927\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2821 - accuracy: 0.8987\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2638 - accuracy: 0.9057\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2462 - accuracy: 0.9109\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2345 - accuracy: 0.9166\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2213 - accuracy: 0.9206\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2096 - accuracy: 0.9237\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2053 - accuracy: 0.9252\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1929 - accuracy: 0.9296\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1907 - accuracy: 0.9319\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1799 - accuracy: 0.9344\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.1747 - accuracy: 0.9363\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1683 - accuracy: 0.9401\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.1616 - accuracy: 0.9409\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1561 - accuracy: 0.9423\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1505 - accuracy: 0.9462\n",
      "[CV 2/3] END best_MLP__dropout_conv=0.25, best_MLP__dropout_dense=0.25, best_MLP__n_layers=3, best_MLP__nn1=64, best_MLP__nn2=64;, score=0.917 total time= 2.7min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.9044 - accuracy: 0.6894\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.4636 - accuracy: 0.8429\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.3858 - accuracy: 0.8674\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.3495 - accuracy: 0.8790\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.3169 - accuracy: 0.8885\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2985 - accuracy: 0.8939\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2828 - accuracy: 0.8994\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2672 - accuracy: 0.9046\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2530 - accuracy: 0.9108\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2427 - accuracy: 0.9136\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2350 - accuracy: 0.9150\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2242 - accuracy: 0.9195\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2175 - accuracy: 0.9215\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2103 - accuracy: 0.9230\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2030 - accuracy: 0.9272\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1954 - accuracy: 0.9298\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1901 - accuracy: 0.9313\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.1872 - accuracy: 0.9328\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1795 - accuracy: 0.9348\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.1712 - accuracy: 0.9379\n",
      "[CV 3/3] END best_MLP__dropout_conv=0.25, best_MLP__dropout_dense=0.25, best_MLP__n_layers=3, best_MLP__nn1=64, best_MLP__nn2=64;, score=0.910 total time= 2.7min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.7943 - accuracy: 0.7338\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.4552 - accuracy: 0.8374\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3944 - accuracy: 0.8573\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3545 - accuracy: 0.8729\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3317 - accuracy: 0.8800\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.3147 - accuracy: 0.8852\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2973 - accuracy: 0.8914\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2807 - accuracy: 0.8968\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2665 - accuracy: 0.9025\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2563 - accuracy: 0.9064\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.2457 - accuracy: 0.9096\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2360 - accuracy: 0.9126\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2253 - accuracy: 0.9160\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2174 - accuracy: 0.9189\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2080 - accuracy: 0.9233\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2018 - accuracy: 0.92590s - loss: 0.2019 \n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1961 - accuracy: 0.9263\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1875 - accuracy: 0.9300\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1817 - accuracy: 0.9320\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1778 - accuracy: 0.9331\n",
      "[CV 1/3] END best_MLP__dropout_conv=0.1, best_MLP__dropout_dense=0.5, best_MLP__n_layers=1, best_MLP__nn1=256, best_MLP__nn2=128;, score=0.918 total time= 2.8min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 105ms/step - loss: 0.7032 - accuracy: 0.7527\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.4222 - accuracy: 0.8493\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3682 - accuracy: 0.8700\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.3334 - accuracy: 0.8812\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.3114 - accuracy: 0.8887\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2913 - accuracy: 0.8934\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2744 - accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2613 - accuracy: 0.9051\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2481 - accuracy: 0.9113\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2376 - accuracy: 0.9125\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2275 - accuracy: 0.9163\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2186 - accuracy: 0.9188\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.2098 - accuracy: 0.9243\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1998 - accuracy: 0.9263\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1961 - accuracy: 0.9273\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1927 - accuracy: 0.9287\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1848 - accuracy: 0.9323\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1778 - accuracy: 0.9347\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1714 - accuracy: 0.9376\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1633 - accuracy: 0.9391\n",
      "[CV 2/3] END best_MLP__dropout_conv=0.1, best_MLP__dropout_dense=0.5, best_MLP__n_layers=1, best_MLP__nn1=256, best_MLP__nn2=128;, score=0.915 total time= 2.7min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 105ms/step - loss: 0.5891 - accuracy: 0.7893\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.3660 - accuracy: 0.8705\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3209 - accuracy: 0.8858\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2882 - accuracy: 0.8943\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2673 - accuracy: 0.9045\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2473 - accuracy: 0.9094\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2340 - accuracy: 0.9136\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2204 - accuracy: 0.9185\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2093 - accuracy: 0.9229\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1978 - accuracy: 0.9282\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1929 - accuracy: 0.9283\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1817 - accuracy: 0.9329\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1739 - accuracy: 0.9354\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1663 - accuracy: 0.9390\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1567 - accuracy: 0.9423\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1560 - accuracy: 0.9419\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1477 - accuracy: 0.9456\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1449 - accuracy: 0.9467\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1354 - accuracy: 0.9494\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1352 - accuracy: 0.9502\n",
      "[CV 3/3] END best_MLP__dropout_conv=0.1, best_MLP__dropout_dense=0.5, best_MLP__n_layers=1, best_MLP__nn1=256, best_MLP__nn2=128;, score=0.916 total time= 2.7min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 1.0689 - accuracy: 0.6283\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.5983 - accuracy: 0.7967\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.4967 - accuracy: 0.8310\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.4456 - accuracy: 0.8475\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.4145 - accuracy: 0.8594\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.3887 - accuracy: 0.8690\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.3695 - accuracy: 0.8712\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.3455 - accuracy: 0.8801\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3411 - accuracy: 0.8842\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.3254 - accuracy: 0.8847\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 95ms/step - loss: 0.3092 - accuracy: 0.8892\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.3005 - accuracy: 0.8942\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.2928 - accuracy: 0.8965\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.2862 - accuracy: 0.9001\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.2793 - accuracy: 0.9011\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.2760 - accuracy: 0.9018\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.2679 - accuracy: 0.9058\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.2652 - accuracy: 0.9063\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2584 - accuracy: 0.9069\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2524 - accuracy: 0.9097\n",
      "[CV 1/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.5, best_MLP__n_layers=2, best_MLP__nn1=64, best_MLP__nn2=64;, score=0.911 total time= 2.6min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.9726 - accuracy: 0.6640\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.5645 - accuracy: 0.8064\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.4804 - accuracy: 0.8362\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.4267 - accuracy: 0.8564\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3959 - accuracy: 0.8640\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.3683 - accuracy: 0.8742\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.3567 - accuracy: 0.8777\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.3454 - accuracy: 0.8797\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.3325 - accuracy: 0.8843\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.3191 - accuracy: 0.8906\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.3108 - accuracy: 0.8911\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.3022 - accuracy: 0.8932\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.2968 - accuracy: 0.8955\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 8s 96ms/step - loss: 0.2902 - accuracy: 0.8954\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.2818 - accuracy: 0.9013\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.2741 - accuracy: 0.9031\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.2678 - accuracy: 0.9046\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.2611 - accuracy: 0.9073\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.2563 - accuracy: 0.9082\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2553 - accuracy: 0.9078\n",
      "[CV 2/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.5, best_MLP__n_layers=2, best_MLP__nn1=64, best_MLP__nn2=64;, score=0.909 total time= 2.6min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 1.1484 - accuracy: 0.5863\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.6165 - accuracy: 0.7870\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.5230 - accuracy: 0.8207\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.4717 - accuracy: 0.8390\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.4394 - accuracy: 0.8507\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.4084 - accuracy: 0.8610\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.3904 - accuracy: 0.8686\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.3736 - accuracy: 0.8735\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.3660 - accuracy: 0.8750\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.3522 - accuracy: 0.8824\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.3416 - accuracy: 0.8814\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.3314 - accuracy: 0.8859\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.3257 - accuracy: 0.8890\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.3159 - accuracy: 0.8907\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3059 - accuracy: 0.8940\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.3023 - accuracy: 0.8957\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.2957 - accuracy: 0.8977\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.2912 - accuracy: 0.8986\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.2853 - accuracy: 0.9007\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.2802 - accuracy: 0.9034\n",
      "[CV 3/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.5, best_MLP__n_layers=2, best_MLP__nn1=64, best_MLP__nn2=64;, score=0.908 total time= 2.6min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 105ms/step - loss: 0.6617 - accuracy: 0.7667\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.4004 - accuracy: 0.8549\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3469 - accuracy: 0.8735\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3191 - accuracy: 0.8827\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2922 - accuracy: 0.8924\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2732 - accuracy: 0.8977\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2617 - accuracy: 0.9033\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2483 - accuracy: 0.9075\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2371 - accuracy: 0.9103\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2268 - accuracy: 0.9145\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2152 - accuracy: 0.9214\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2050 - accuracy: 0.9235\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2003 - accuracy: 0.9260\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1926 - accuracy: 0.9280\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1901 - accuracy: 0.9287\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1791 - accuracy: 0.9335\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1751 - accuracy: 0.9335\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1670 - accuracy: 0.9373\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1621 - accuracy: 0.9397\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1576 - accuracy: 0.9403\n",
      "[CV 1/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.25, best_MLP__n_layers=1, best_MLP__nn1=256, best_MLP__nn2=128;, score=0.921 total time= 2.8min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.6661 - accuracy: 0.7667\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3963 - accuracy: 0.8576\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3473 - accuracy: 0.8735\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.3191 - accuracy: 0.8830\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2947 - accuracy: 0.8917\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2744 - accuracy: 0.8986\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2596 - accuracy: 0.9044\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2467 - accuracy: 0.9093\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2379 - accuracy: 0.9120\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2250 - accuracy: 0.9170\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2171 - accuracy: 0.9205\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2097 - accuracy: 0.9228\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2022 - accuracy: 0.9248\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1937 - accuracy: 0.9272\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1904 - accuracy: 0.9293\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1819 - accuracy: 0.9307\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1764 - accuracy: 0.9331\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1710 - accuracy: 0.9362\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1668 - accuracy: 0.9386\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1628 - accuracy: 0.9398\n",
      "[CV 2/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.25, best_MLP__n_layers=1, best_MLP__nn1=256, best_MLP__nn2=128;, score=0.919 total time= 2.8min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.7194 - accuracy: 0.7509\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.4078 - accuracy: 0.8518\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3552 - accuracy: 0.8711\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.3241 - accuracy: 0.8818\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.3000 - accuracy: 0.8897\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2825 - accuracy: 0.8949\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2677 - accuracy: 0.9011\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2547 - accuracy: 0.9052\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2408 - accuracy: 0.9103\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2311 - accuracy: 0.9134\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2209 - accuracy: 0.9179\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2172 - accuracy: 0.9191\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.2064 - accuracy: 0.9244\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1974 - accuracy: 0.9269\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1920 - accuracy: 0.9294\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1848 - accuracy: 0.9314\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1803 - accuracy: 0.9327\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1755 - accuracy: 0.9341\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1687 - accuracy: 0.9358\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1665 - accuracy: 0.9376\n",
      "[CV 3/3] END best_MLP__dropout_conv=0.5, best_MLP__dropout_dense=0.25, best_MLP__n_layers=1, best_MLP__nn1=256, best_MLP__nn2=128;, score=0.917 total time= 2.8min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.7622 - accuracy: 0.7338\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.4415 - accuracy: 0.8445\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3841 - accuracy: 0.8636\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.3462 - accuracy: 0.8763\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3200 - accuracy: 0.8828\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2988 - accuracy: 0.8924\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.2824 - accuracy: 0.8971\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2688 - accuracy: 0.9031\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2571 - accuracy: 0.9072\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2453 - accuracy: 0.9113\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2334 - accuracy: 0.9137\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2269 - accuracy: 0.9180\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2180 - accuracy: 0.9191\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2078 - accuracy: 0.9219\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2025 - accuracy: 0.9252\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1929 - accuracy: 0.9289\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1869 - accuracy: 0.9318\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1816 - accuracy: 0.9331\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1721 - accuracy: 0.9354\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1682 - accuracy: 0.9380\n",
      "[CV 1/3] END best_MLP__dropout_conv=0.1, best_MLP__dropout_dense=0.5, best_MLP__n_layers=1, best_MLP__nn1=256, best_MLP__nn2=256;, score=0.919 total time= 2.8min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.7056 - accuracy: 0.7548\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.4152 - accuracy: 0.8534\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3574 - accuracy: 0.8708\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3187 - accuracy: 0.8850\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2939 - accuracy: 0.8931\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2747 - accuracy: 0.9008\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2615 - accuracy: 0.9057\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2459 - accuracy: 0.9106\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2333 - accuracy: 0.9154\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2261 - accuracy: 0.9179\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2139 - accuracy: 0.9217\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2022 - accuracy: 0.9265\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1948 - accuracy: 0.9271\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1900 - accuracy: 0.9296\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1840 - accuracy: 0.9325\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.1730 - accuracy: 0.9362\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1688 - accuracy: 0.9370\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1632 - accuracy: 0.9407\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1561 - accuracy: 0.9435\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1499 - accuracy: 0.9452\n",
      "[CV 2/3] END best_MLP__dropout_conv=0.1, best_MLP__dropout_dense=0.5, best_MLP__n_layers=1, best_MLP__nn1=256, best_MLP__nn2=256;, score=0.916 total time= 2.8min\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.7705 - accuracy: 0.7342\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.4592 - accuracy: 0.8376\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.4042 - accuracy: 0.8558\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3655 - accuracy: 0.8679\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3447 - accuracy: 0.8761\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3211 - accuracy: 0.8838\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.3059 - accuracy: 0.8895\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2885 - accuracy: 0.8951\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2746 - accuracy: 0.9002\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.2640 - accuracy: 0.9037\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2555 - accuracy: 0.9075\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2481 - accuracy: 0.9094\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2331 - accuracy: 0.9148\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2258 - accuracy: 0.9180\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2210 - accuracy: 0.9197\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2127 - accuracy: 0.9214\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2075 - accuracy: 0.9230\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2012 - accuracy: 0.9265\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1935 - accuracy: 0.9287\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1896 - accuracy: 0.9305\n",
      "[CV 3/3] END best_MLP__dropout_conv=0.1, best_MLP__dropout_dense=0.5, best_MLP__n_layers=1, best_MLP__nn1=256, best_MLP__nn2=256;, score=0.912 total time= 2.8min\n",
      "Epoch 1/20\n",
      "120/120 [==============================] - 12s 98ms/step - loss: 0.6088 - accuracy: 0.7821\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 11s 95ms/step - loss: 0.3721 - accuracy: 0.8658\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 12s 97ms/step - loss: 0.3275 - accuracy: 0.8810\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 11s 95ms/step - loss: 0.2917 - accuracy: 0.8936\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.2728 - accuracy: 0.8994\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.2570 - accuracy: 0.9047\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.2446 - accuracy: 0.9101\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.2332 - accuracy: 0.9134\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.2232 - accuracy: 0.9179\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.2156 - accuracy: 0.9197\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.2054 - accuracy: 0.9235\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.1956 - accuracy: 0.9276\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 11s 95ms/step - loss: 0.1926 - accuracy: 0.9287\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 12s 97ms/step - loss: 0.1854 - accuracy: 0.9300\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 11s 95ms/step - loss: 0.1790 - accuracy: 0.9335\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 11s 95ms/step - loss: 0.1760 - accuracy: 0.9338\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.1691 - accuracy: 0.9356\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.1663 - accuracy: 0.9369\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.1593 - accuracy: 0.9394\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.1546 - accuracy: 0.9420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('best_MLP',\n",
       "                                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x7fc7d4db6df0>)]),\n",
       "                   param_distributions={'best_MLP__dropout_conv': [0.1, 0.25,\n",
       "                                                                   0.5],\n",
       "                                        'best_MLP__dropout_dense': [0.1, 0.25,\n",
       "                                                                    0.5],\n",
       "                                        'best_MLP__n_layers': [1, 2, 3],\n",
       "                                        'best_MLP__nn1': [64, 128, 256],\n",
       "                                        'best_MLP__nn2': [64, 128, 256]},\n",
       "                   random_state=28, scoring=make_scorer(my_custom_loss_func),\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_joined_train.reshape(-1, 28, 28, 1), y_joined_train, best_MLP__callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_CV\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Dropout_conv_0.5 (Dropout)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "Capa_Oculta_0 (Dense)        (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "Dropout_dense_0.1 (Dropout)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Capa_Salida (Dense)          (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 804,554\n",
      "Trainable params: 804,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model_mlp = grid.best_estimator_\n",
    "best_model_mlp['best_MLP'].model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La accuracy del mejor modelo para MLP es:  0.9192\n"
     ]
    }
   ],
   "source": [
    "best_score_mlp = grid.best_score_\n",
    "print('La accuracy del mejor modelo para MLP es: ', best_score_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO: Comentar el modelo. Curiosamente, el mejor modelo fue con una sola capa de 256 neuronas, como en el baseline, pero con más regularización en conv que en dense, como habíamos puesto inicialmente. De todas formas, si revisamos bien, el desempeño de todos fue bastante aproximado en todos los casos (en algunos hacía overfitting). Esto quiere decir que, para este caso, todos los hiperparámetros dan un modelo bastante cercano al baseline. Quizá, para aumentar la accuracy, podríamos usar más filtros (y/o) capas convolucionales. No obstante, eso se sale del enfoque de este laboratorio. De hecho, cabe aclarar que encontré un ejemplo en el que usaban más capas convolucionales y les daba aprox la misma accuracy [9].__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9136    , 0.9192    , 0.90365   , 0.91561667, 0.91398333,\n",
       "       0.91456667, 0.91621667, 0.90936667, 0.91911667, 0.91563333])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos ver que los 10 modelos probados arrojaron scores similares.\n",
    "grid.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, el último modelo que queremos estudiar es una de las arquitecturas vistas en clase: LeNet. A esta no le haremos ajuste de hiperparámetros. Solamente queremos ver su comportamiento en comparación con los otros dos modelos que ya construimos, pues nos pareció interesante ahora que lo estudiamos. De esta forma, siguiendo la arquitectura sugerida por [10],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = Sequential(name='LeNet')\n",
    "\n",
    "lenet.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "lenet.add(AveragePooling2D())\n",
    "lenet.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "lenet.add(AveragePooling2D())\n",
    "lenet.add(Flatten())\n",
    "lenet.add(Dense(units=120, activation='relu'))\n",
    "lenet.add(Dense(units=84, activation='relu'))\n",
    "lenet.add(Dense(units=10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que este modelo no contempla el uso de capas de Dropout. Asimismo, no usa MaxPooling sino que AveragePooling. Cuenta con dos capas convolucionales (en lugar de una, como en nuestro modelo anterior), así como con dos capas de Average Pooling. Tenemos dos capas densas, en lugar de una, pero de 120 y 84 neuronas, que son más poquitas que las que consideramos previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LeNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               192120    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 221,950\n",
      "Trainable params: 221,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lenet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el mismo optimizador, función de pérdida y métrica de siempre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el fit, usando los callbacks que definimos anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.7237 - accuracy: 0.7341 - val_loss: 0.5164 - val_accuracy: 0.8033\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.4612 - accuracy: 0.8311 - val_loss: 0.4490 - val_accuracy: 0.8283\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.3949 - accuracy: 0.8566 - val_loss: 0.3726 - val_accuracy: 0.8615\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.3594 - accuracy: 0.8704 - val_loss: 0.3569 - val_accuracy: 0.8694\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.3284 - accuracy: 0.8817 - val_loss: 0.3403 - val_accuracy: 0.8711\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.3123 - accuracy: 0.8849 - val_loss: 0.3132 - val_accuracy: 0.8865\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.2935 - accuracy: 0.8921 - val_loss: 0.3048 - val_accuracy: 0.8896\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.2766 - accuracy: 0.8985 - val_loss: 0.3057 - val_accuracy: 0.8904\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.2647 - accuracy: 0.9017 - val_loss: 0.2898 - val_accuracy: 0.8967\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.2521 - accuracy: 0.9064 - val_loss: 0.2831 - val_accuracy: 0.8982\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.2421 - accuracy: 0.9100 - val_loss: 0.2791 - val_accuracy: 0.9013\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.2307 - accuracy: 0.9141 - val_loss: 0.2680 - val_accuracy: 0.9044\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.2245 - accuracy: 0.9176 - val_loss: 0.2856 - val_accuracy: 0.8973\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.2161 - accuracy: 0.9189 - val_loss: 0.2620 - val_accuracy: 0.9062\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.2051 - accuracy: 0.9234 - val_loss: 0.2920 - val_accuracy: 0.8951\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.1980 - accuracy: 0.9267 - val_loss: 0.2603 - val_accuracy: 0.9083\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.1892 - accuracy: 0.9291 - val_loss: 0.2655 - val_accuracy: 0.9039\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.1831 - accuracy: 0.9310 - val_loss: 0.2879 - val_accuracy: 0.8972\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.1795 - accuracy: 0.9323 - val_loss: 0.2676 - val_accuracy: 0.9076\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.1697 - accuracy: 0.9358 - val_loss: 0.2476 - val_accuracy: 0.9159\n"
     ]
    }
   ],
   "source": [
    "history_lenet = lenet.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=20, batch_size=200, callbacks=callbacks,\n",
    "                    validation_data=(\n",
    "                    X_val.reshape(-1, 28, 28, 1), \n",
    "                    y_val\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='lenet.png'/>\n",
    "\n",
    "__TODO: COMENTAR DE ESTE MODELO__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Autoencoder para reducción de dimensionalidad y MLP\n",
    "\n",
    "Los codificadores automáticos o autoencoders se utilizan para el preentrenamiento de otras redes, reducción de la dimensionalidad, aprendizaje de espacios latentes, entre otros.\n",
    "\n",
    "Los autoencoders, por otro lado, pueden ser entrenados sin supervisión. Su estructura generalmente se caracteriza por:\n",
    "\n",
    "1. La cantidad de neuronas ocultas es menor que la cantidad de celdas de entrada.\n",
    "2. La cantidad de celdas de salida es igual a la cantidad de celdas de entrada.\n",
    "3. El autoencoder se entrena de manera en que la salida está lo más cerca posible de la entrada, obligando a los autoencoders a generalizar datos y realizar búsqueda de patrones comunes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2.1 Modelo autoencoder\n",
    "Empezamos con el modelo de autoencoder que usamos en el laboratorio. Note que todo está compuesto de capas convolucionales. En realidad, estas capas no han sido del todo cubiertas en el curso, por lo que hay muchos hiperparámetros que todavía no sabemos ajustar bien. Por lo tanto, en este caso (si logramos ver que el autoencoder, con este modelo, reconstruye adecuadamente las imágenes) nos quedaremos únicamente con este, sin realizar validación cruzada ni búsqueda de hiperparámetros. Para el que sí haremos será el MLP que haremos más adelante.\n",
    "\n",
    "Para las capas convolucionales, note lo siguiente:\n",
    "\n",
    "El tamaño del kernel es el mismo del MLP diseñado previamente. Asimismo, por buenas prácticas, dejamos <code>padding='same'</code>. El encoder se compone de dos capas: una convolucional de 16 filtros y, la segunda, de 8 filtros. La capa que le sigue es hasta la que usaremos como input del MLP. En esta, en lugar de tener <code>strides=2</code>, tenemos <code>strides=1</code>. Finalmente, el decoder usa dos capas convolucionales transpuestas (i.e. las que se usan para decodificar). La última tiene función de activación sigmoide pues queremos los valores de los pixeles entre 0 y 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Sequential(name=\"Autoencoder\")\n",
    "\n",
    "# Encoder\n",
    "autoencoder.add(Conv2D(filters=16, kernel_size=3, strides=2, padding=\"same\", input_shape=(28, 28, 1)))\n",
    "autoencoder.add(Conv2D(filters=8, kernel_size=3, strides=2, padding=\"same\"))\n",
    "\n",
    "#Encoded image\n",
    "autoencoder.add(Conv2D(filters=8, kernel_size=3, strides=1, padding=\"same\"))\n",
    "\n",
    "#Decoder\n",
    "autoencoder.add(Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding=\"same\"))\n",
    "autoencoder.add(Conv2DTranspose(filters=1, kernel_size=3, strides=2, activation='sigmoid', padding=\"same\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que tenemos un encoder, usamos como función de pérdida el error cuadrático medio y, como optimizador, usamos Adam, el mejor de todos usualmente, según la literatura que hemos estudiado [8]. Note que el _learning rate_ por defecto de Adam es 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 8)           1160      \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 3,217\n",
      "Trainable params: 3,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(loss='mean_squared_error', optimizer='adam')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, hacemos fit al autoencoder, usando los callbacks que definimos previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 5s 20ms/step - loss: 0.0491 - val_loss: 0.0185\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0041 - val_loss: 0.0040\n"
     ]
    }
   ],
   "source": [
    "history_autoencoder = autoencoder.fit(X_train.reshape(-1, 28, 28, 1),          \n",
    "                X_train.reshape(-1, 28, 28, 1), \n",
    "                epochs=20, \n",
    "                batch_size=200, \n",
    "                callbacks = [callbacks],\n",
    "                validation_data=(\n",
    "                    X_val.reshape(-1, 28, 28, 1), \n",
    "                    X_val.reshape(-1, 28, 28, 1)\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='second.png'/>\n",
    "\n",
    "**TODO: COMENTAR RESULTADOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este autoencoder, podemos hacer la predicción de nuestras imágenes. En este caso, tomaremos únicamente las 10 primeras con el fin de revisar que ellas estén bien reconstruidas (por lo menos en validación, como hicimos en clase). Si está bien, podemos justificar el uso de la capa intermedia que previamente mencionamos como el input de la MLP. Entonces,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predichas_autoencoder = autoencoder.predict(X_val[:10].reshape(-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0040\n",
      "Validation Loss : 0.004\n"
     ]
    }
   ],
   "source": [
    "evaluation_autoencoder = autoencoder.evaluate(X_val.reshape(-1, 28, 28, 1), X_val.reshape(-1, 28, 28, 1))\n",
    "print('Validation Loss : {:.3f}'.format(evaluation_autoencoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la pérdida en validación es realmente baja, lo cual da buenos indicios de nuestro modelo. Veamos si las imágenes están bien reconstruidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "\n",
    "for images, row in zip([X_val[:10], predichas_autoencoder], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que, en efecto, ¡el autoencoder ha hecho un gran trabajo reconstruyendo las imágenes! Usemos entonces hasta la capa de la mitad para crear nuestro MLP. Lo que haremos es algo así como coger hasta la mitad del autoencoder (en compressed data) y construir un MLP a partir de allí. En teoría, deberíamos tener mejores resultados que con el MLP solito.\n",
    "<img src='autoencoders.png'/>\n",
    "\n",
    "Imagen tomada de: https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii-20e0c85301bd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2.2 Modelo MLP baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este, debemos definir la cantidad de capas densas que tendrá, pero antes agregamos una capa para aplanar la imagen. Como este es un modelo baseline, podemos tomar una única capa. Como tomamos menos del doble de las de la capa de entrada, y para evitar hacer overfitting, escogemos únicamente 256 neuronas en esta capa. Por las razones expuestas para el primer MLP, usamos la misma función de activación, ReLu. Tanto el número de capas como la cantidad de neuronas en cada una, será un hiperparámetro que ajustaremos despuñes.\n",
    "\n",
    "Seguido de esto, añadimos una capa de Dropout por la regularización. Consideramos p=0.5 que es la máxima, pero este es un hiperparámetro que debemos ajustar.\n",
    "\n",
    "Finalmente, ponemos una capa de salida con 10 neuronas, pues tenemos 10 clases. Como dijimos atrás, la función de activación de esta capa es softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_autoencoder = Sequential(name='MLP_post_autoencoder')\n",
    "# Agregamos hasta la tercera capa del autoencoder a nuestro MLP\n",
    "mlp_autoencoder.add(autoencoder.layers[0])\n",
    "mlp_autoencoder.add(autoencoder.layers[1])\n",
    "mlp_autoencoder.add(autoencoder.layers[2])\n",
    "# Agregamos una capa para aplanar la imagen y dársela al MLP.\n",
    "mlp_autoencoder.add(Flatten())\n",
    "# Agregamos una capa densa de 256 neuronas con función de activación relu\n",
    "mlp_autoencoder.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "# Agregamos una capa de regularización con p=0.5 (i.e. máxima regularización)\n",
    "mlp_autoencoder.add(Dropout(0.5))\n",
    "# Agregamos la capa de salida\n",
    "mlp_autoencoder.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo va nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_post_autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 8)           1160      \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               100608    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 105,082\n",
      "Trainable params: 105,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, debemos elegir una métrica, una función de pérdida y un optimizador. En cuanto a la función de pérdida, la que se usa con frecuencia en problemas de clasificación es la de entropía cruzada. De hecho, se recomienda no cambiarla, a menos de que se tenga una razón lo suficientemente fuerte para hacerlo, pues es la función de pérdida preferida en el marco de la máxima verosimilitud. Para problemas multiclase, donde se tiene OneHotEncoding, se utiliza entropía cruzada categórica: categorical_crossentropy [7].\n",
    "\n",
    "En el caso del optimizador, elegimos adam. Por lo general, este es el que mejores resultados presenta, de acuerdo con la literatura, con el valor por defecto de tasa de aprendizaje de 0.001. Asimismo, nos quitamos de encima el ajustar un hiperparámetro extra (la tasa de aprendizaje), pues los algoritmos adaptativos como Adam van ajustando esta tasa a medida que entrenan [8]. Últimamente se ha visto que SGD, acompañado de un buen learning rate, puede arrojar resultados excelentes también. No obstante, esto implica el ajuste de un hiperparámetro que, dada la complejidad del problema, puede ser muy costosa computacionalmente.\n",
    "\n",
    "Asimismo, debemos definir la métrica que informa el éxito del modelo. En este caso elegimos la exactitud (accuracy) como métrica, pues el usuario aspira poder diagnosticar de forma amplia sobre las diez categorías. En consecuencia, tiene más sentido utilizar una métrica que reporte el éxito general del modelo sin privilegiar una categoría sobre otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_autoencoder.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando los mismos callbacks de siempre, obtenemos que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 0.7152 - accuracy: 0.7549 - val_loss: 0.4230 - val_accuracy: 0.8485\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 0.4505 - accuracy: 0.8397 - val_loss: 0.3784 - val_accuracy: 0.8658\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 0.3998 - accuracy: 0.8576 - val_loss: 0.3573 - val_accuracy: 0.8721\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 0.3719 - accuracy: 0.8652 - val_loss: 0.3450 - val_accuracy: 0.8779\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 0.3541 - accuracy: 0.8711 - val_loss: 0.3363 - val_accuracy: 0.8790\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 0.3377 - accuracy: 0.8780 - val_loss: 0.3263 - val_accuracy: 0.8832\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 3s 10ms/step - loss: 0.3224 - accuracy: 0.8837 - val_loss: 0.3138 - val_accuracy: 0.8890\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 0.3085 - accuracy: 0.8878 - val_loss: 0.3174 - val_accuracy: 0.8897\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 0.3004 - accuracy: 0.8915 - val_loss: 0.3118 - val_accuracy: 0.8889\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 0.2890 - accuracy: 0.8941 - val_loss: 0.3086 - val_accuracy: 0.8883\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 3s 10ms/step - loss: 0.2832 - accuracy: 0.8957 - val_loss: 0.3109 - val_accuracy: 0.8892\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 0.2749 - accuracy: 0.8985 - val_loss: 0.3025 - val_accuracy: 0.8915\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 0.2683 - accuracy: 0.9008 - val_loss: 0.3053 - val_accuracy: 0.8923\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 3s 10ms/step - loss: 0.2588 - accuracy: 0.9037 - val_loss: 0.3061 - val_accuracy: 0.8892\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 0.2492 - accuracy: 0.9078 - val_loss: 0.3084 - val_accuracy: 0.8950\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 3s 10ms/step - loss: 0.2423 - accuracy: 0.9116 - val_loss: 0.3159 - val_accuracy: 0.8905\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 0.2394 - accuracy: 0.9117 - val_loss: 0.3097 - val_accuracy: 0.8937\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 0.2306 - accuracy: 0.9126 - val_loss: 0.3122 - val_accuracy: 0.8963\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 3s 10ms/step - loss: 0.2285 - accuracy: 0.9154 - val_loss: 0.3115 - val_accuracy: 0.8948\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 3s 10ms/step - loss: 0.2236 - accuracy: 0.9156 - val_loss: 0.3136 - val_accuracy: 0.8942\n"
     ]
    }
   ],
   "source": [
    "history_mlp_autoencoder = mlp_autoencoder.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=20, batch_size=200, callbacks=callbacks,\n",
    "                    validation_data=(\n",
    "                    X_val.reshape(-1, 28, 28, 1), \n",
    "                    y_val\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='third.png'/>\n",
    "\n",
    "**TODO: Comentar resultados: En particular, comentar en comparación con el primer modelo.**\n",
    "\n",
    "----\n",
    "Intentamos ahora ajustar hiperparámetros a ver si logramos una mejor exactitud.\n",
    "\n",
    "Hay muchos hiperparámetros por afinar en el modelo que en principio podríamos seguir buscando mediante la función de GridSearch. Sin embargo, no es recomendable pues nos encontramos en un universo enorme de hiperparámetros si deseamos hacer una búsqueda exhaustiva.\n",
    "\n",
    "Por ello construimos una función que nos permita especificar la Red Neuronal esperada y utilizamos la función RandomizedSearchCV, que no hace una búsqueda exhaustiva sino aleatoria sobre algunas configuraciones del espacio de hiperparámetros, lo que es mucho más eficiente en términos de tiempo y poder computacional demandado.\n",
    "\n",
    "Claramente, lo ideal sería ajustar también los hiperparámetros del autoencoder. No obstante, como este se compone casi en su totalidad de capas convolucionales (las cuales no han sido del todo cubiertas en el curso) y, por tanto, estos hiperparámetros no serán ajustados en esta ocasión. Entonces, ajustamos los mismos hiperparámetros que para el MLP de la sección anterior.\n",
    "\n",
    "Los parámetros que son más importantes de ajustar son el número de neuronas por capa, el número total de capas y la tasa de dropout. Definimos entonces una función que nos permita hacer esto a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_red(nn1=256, nn2=256, n_layers= 3, dropout_dense=0.5):\n",
    "    output = 10 # Tenemos 10 neuronas pues son las 10 clases de salida\n",
    "    clf = Sequential(name='MLP_autoencoder_CV')\n",
    "    # Agregamos las 3 primeras capas del autoencoder\n",
    "    clf.add(autoencoder.layers[0])\n",
    "    clf.add(autoencoder.layers[1])\n",
    "    clf.add(autoencoder.layers[2])\n",
    "    # Agregamos una capa para aplanar la imagen y dársela al MLP.\n",
    "    clf.add(Flatten())\n",
    "    first = True\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            clf.add(Dense(nn1, activation='relu', name='Capa_Oculta_{0}'.format(i))) # num neuronas capa 1\n",
    "            first = False\n",
    "        else:\n",
    "            clf.add(Dense(nn2, activation='relu', name = 'Capa_Oculta_{0}'.format(i))) # num neuronas capa 2 y 3\n",
    "    \n",
    "    clf.add(Dropout(dropout_dense,name='Dropout_dense_{0}'.format(dropout_dense))) # Dropout (parecido a regularizacion)\n",
    "    clf.add(Dense(output, activation='softmax', name= 'Capa_Salida')) # Capa de salidad\n",
    "\n",
    "    clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # Valores por defecto\n",
    "    \n",
    "    return clf\n",
    "\n",
    "# Modelo que utiliza el GridSearch\n",
    "modelCV_mlp_autoencoder = KerasClassifier(build_fn=entrenar_red, epochs=20, batch_size=500,verbose=1) # Modelo esqueleto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con nuestro código, la segunda y la tercera capa (cuando haya) siempre tendrán nn2 neuronas. Hacemos esto para que no aumentar el espacio de búsqueda de hiperparámetros.\n",
    "\n",
    "Debido a que no ajustamos dropout para capas convolucionales, consideremos qué sucede si tenemos un número mayor de neuronas (por ejemplo, 512)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_2 = Pipeline([('best_MLP_autoencoder', modelCV_mlp_autoencoder)]) # Creamos la pipeline\n",
    "\n",
    "# Tomamos la grilla de hiperparametros \n",
    "param_grid = dict(\n",
    "                  best_MLP_autoencoder__nn1 = [64,128,256,512],\n",
    "                  best_MLP_autoencoder__nn2 = [64,128,256,512],\n",
    "                  best_MLP_autoencoder__n_layers = [1,2,3],\n",
    "                  best_MLP_autoencoder__dropout_dense = [0.1,0.25,0.5]\n",
    "                  )\n",
    "\n",
    "# Definimos la metrica \n",
    "score = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "# Creamos la grilla\n",
    "# Podriamos usar mas iteraciones en el CV, pero lo intentamos correr y se murio el kernel.\n",
    "# Por eso lo redujimos\n",
    "grid_2 = RandomizedSearchCV(pipe_2, param_grid, verbose=3, cv=3, n_iter=10, random_state=8, scoring=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_joined_train = np.array(list(X_train) + list(X_val))\n",
    "y_joined_train = np.array(list(y_train) + list(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.7962 - accuracy: 0.7352\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4362 - accuracy: 0.8461\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3781 - accuracy: 0.8661\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3402 - accuracy: 0.8790\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3178 - accuracy: 0.8855\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2955 - accuracy: 0.8941\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2788 - accuracy: 0.8980\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2631 - accuracy: 0.9045\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2496 - accuracy: 0.9083\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2383 - accuracy: 0.9127\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2224 - accuracy: 0.9186\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2139 - accuracy: 0.9207\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2063 - accuracy: 0.9264\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1974 - accuracy: 0.9269\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1871 - accuracy: 0.9312\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1798 - accuracy: 0.9339\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1732 - accuracy: 0.9362\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1644 - accuracy: 0.9393\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1568 - accuracy: 0.9408\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1495 - accuracy: 0.9454\n",
      "[CV 1/3] END best_MLP_autoencoder__dropout_dense=0.1, best_MLP_autoencoder__n_layers=1, best_MLP_autoencoder__nn1=128, best_MLP_autoencoder__nn2=64;, score=0.893 total time=  36.5s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.9473 - accuracy: 0.7316\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.4551 - accuracy: 0.8429\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3845 - accuracy: 0.8632\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3468 - accuracy: 0.8770\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3210 - accuracy: 0.8840\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2998 - accuracy: 0.8917\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2819 - accuracy: 0.8973\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2692 - accuracy: 0.9027\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2532 - accuracy: 0.9075\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2406 - accuracy: 0.9121\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2292 - accuracy: 0.9165\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2179 - accuracy: 0.9212\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2112 - accuracy: 0.9233\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1996 - accuracy: 0.9266\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1887 - accuracy: 0.9307\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1842 - accuracy: 0.9314\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1764 - accuracy: 0.9354\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1721 - accuracy: 0.9367\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1664 - accuracy: 0.9384\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1573 - accuracy: 0.9432\n",
      "[CV 2/3] END best_MLP_autoencoder__dropout_dense=0.1, best_MLP_autoencoder__n_layers=1, best_MLP_autoencoder__nn1=128, best_MLP_autoencoder__nn2=64;, score=0.889 total time=  35.7s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.1430 - accuracy: 0.7178\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4848 - accuracy: 0.8351\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4030 - accuracy: 0.8600\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3538 - accuracy: 0.8750\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3245 - accuracy: 0.8849\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3031 - accuracy: 0.8921\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2834 - accuracy: 0.8985\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2648 - accuracy: 0.9035\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2539 - accuracy: 0.9081\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2401 - accuracy: 0.9136\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2321 - accuracy: 0.9160\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2188 - accuracy: 0.9194\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2051 - accuracy: 0.9247\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1997 - accuracy: 0.9255\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1885 - accuracy: 0.9317\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1811 - accuracy: 0.9341\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1744 - accuracy: 0.9360\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1664 - accuracy: 0.9393\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1617 - accuracy: 0.9393\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.1548 - accuracy: 0.9427\n",
      "[CV 3/3] END best_MLP_autoencoder__dropout_dense=0.1, best_MLP_autoencoder__n_layers=1, best_MLP_autoencoder__nn1=128, best_MLP_autoencoder__nn2=64;, score=0.886 total time=  35.8s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 1.3863 - accuracy: 0.5866\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.6146 - accuracy: 0.7939\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.5027 - accuracy: 0.8303\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4405 - accuracy: 0.8462\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4010 - accuracy: 0.8634\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3689 - accuracy: 0.8715 0s - loss:\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3521 - accuracy: 0.8767\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3349 - accuracy: 0.8811\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3110 - accuracy: 0.8885\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2977 - accuracy: 0.8927\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2844 - accuracy: 0.8984\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2749 - accuracy: 0.9007\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2634 - accuracy: 0.9031\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2477 - accuracy: 0.9087\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2359 - accuracy: 0.9130\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2279 - accuracy: 0.9165\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2170 - accuracy: 0.9188\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2087 - accuracy: 0.9234\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2024 - accuracy: 0.9244\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.1939 - accuracy: 0.9287\n",
      "[CV 1/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=3, best_MLP_autoencoder__nn1=128, best_MLP_autoencoder__nn2=64;, score=0.887 total time=  39.2s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 1.3525 - accuracy: 0.5972\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.6186 - accuracy: 0.7999\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4961 - accuracy: 0.8336\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.4343 - accuracy: 0.8532\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3951 - accuracy: 0.8664\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3673 - accuracy: 0.8739\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3466 - accuracy: 0.8794\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3204 - accuracy: 0.8899\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3054 - accuracy: 0.8914\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2924 - accuracy: 0.8972\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2792 - accuracy: 0.9009\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2671 - accuracy: 0.9046\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2504 - accuracy: 0.9108\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2372 - accuracy: 0.9158\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2357 - accuracy: 0.9133\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2213 - accuracy: 0.9201\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2064 - accuracy: 0.9256\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2043 - accuracy: 0.9266\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.1967 - accuracy: 0.9290\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.1842 - accuracy: 0.9338\n",
      "[CV 2/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=3, best_MLP_autoencoder__nn1=128, best_MLP_autoencoder__nn2=64;, score=0.888 total time=  39.4s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 1.4107 - accuracy: 0.5738\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.6352 - accuracy: 0.7863\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5133 - accuracy: 0.8232\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.4542 - accuracy: 0.8446\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4134 - accuracy: 0.8568\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3837 - accuracy: 0.8658\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3570 - accuracy: 0.8741\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3370 - accuracy: 0.8821\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3218 - accuracy: 0.8851\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3084 - accuracy: 0.8914\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2882 - accuracy: 0.8954\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2801 - accuracy: 0.8992\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2682 - accuracy: 0.9032\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2565 - accuracy: 0.9076\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2478 - accuracy: 0.9097\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2373 - accuracy: 0.9135\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2267 - accuracy: 0.9157\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2156 - accuracy: 0.9197\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2048 - accuracy: 0.9233\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2010 - accuracy: 0.9258\n",
      "[CV 3/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=3, best_MLP_autoencoder__nn1=128, best_MLP_autoencoder__nn2=64;, score=0.887 total time=  39.5s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 1.7588 - accuracy: 0.5424 1s - l\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.7454 - accuracy: 0.7519\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.6064 - accuracy: 0.7960\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.5365 - accuracy: 0.8158\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4959 - accuracy: 0.8291\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4644 - accuracy: 0.8398\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4432 - accuracy: 0.8449\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4185 - accuracy: 0.8534\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4009 - accuracy: 0.8581\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3926 - accuracy: 0.8612\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3760 - accuracy: 0.8655\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3687 - accuracy: 0.8687\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3562 - accuracy: 0.8728\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3483 - accuracy: 0.8747\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3407 - accuracy: 0.8787\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3333 - accuracy: 0.8785\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3236 - accuracy: 0.8811\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3189 - accuracy: 0.8844\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3125 - accuracy: 0.8855\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3090 - accuracy: 0.8876\n",
      "[CV 1/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=64, best_MLP_autoencoder__nn2=64;, score=0.883 total time=  38.5s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 1.6498 - accuracy: 0.5612\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.7342 - accuracy: 0.7525\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.6016 - accuracy: 0.7930\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.5400 - accuracy: 0.8133\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4988 - accuracy: 0.8276\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4651 - accuracy: 0.8382\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4461 - accuracy: 0.8463\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4270 - accuracy: 0.8499\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4145 - accuracy: 0.8560\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3988 - accuracy: 0.8603\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3867 - accuracy: 0.8637\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3785 - accuracy: 0.8674\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3700 - accuracy: 0.8687\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3629 - accuracy: 0.8710\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3461 - accuracy: 0.8758\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3434 - accuracy: 0.8748\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3382 - accuracy: 0.8779\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3325 - accuracy: 0.8808\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3213 - accuracy: 0.8836\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3168 - accuracy: 0.8842\n",
      "[CV 2/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=64, best_MLP_autoencoder__nn2=64;, score=0.879 total time=  38.7s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 1.8017 - accuracy: 0.5418\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.7503 - accuracy: 0.7487\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.6054 - accuracy: 0.7918\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.5296 - accuracy: 0.8179\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4846 - accuracy: 0.8316\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4546 - accuracy: 0.8407\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4317 - accuracy: 0.8510\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4116 - accuracy: 0.8540\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3939 - accuracy: 0.8624\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3817 - accuracy: 0.8653\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3693 - accuracy: 0.8698\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3603 - accuracy: 0.8695\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3504 - accuracy: 0.8738\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3431 - accuracy: 0.8787\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3357 - accuracy: 0.8798\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3285 - accuracy: 0.8825\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3186 - accuracy: 0.8844\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3139 - accuracy: 0.8852\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3081 - accuracy: 0.8885\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3008 - accuracy: 0.8878\n",
      "[CV 3/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=64, best_MLP_autoencoder__nn2=64;, score=0.884 total time=  38.6s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 3s 29ms/step - loss: 0.6552 - accuracy: 0.7808\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.3662 - accuracy: 0.8672\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.3061 - accuracy: 0.8879\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2680 - accuracy: 0.9007\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2405 - accuracy: 0.9108\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.2161 - accuracy: 0.9180\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1906 - accuracy: 0.9284\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1730 - accuracy: 0.9361\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1544 - accuracy: 0.9430\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1420 - accuracy: 0.9474\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.1263 - accuracy: 0.9543\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1110 - accuracy: 0.9582\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.1088 - accuracy: 0.9593\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0931 - accuracy: 0.9655\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0861 - accuracy: 0.9684\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0772 - accuracy: 0.9724\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0707 - accuracy: 0.9744\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0628 - accuracy: 0.9775\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0561 - accuracy: 0.9794\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0567 - accuracy: 0.9796\n",
      "[CV 1/3] END best_MLP_autoencoder__dropout_dense=0.1, best_MLP_autoencoder__n_layers=3, best_MLP_autoencoder__nn1=256, best_MLP_autoencoder__nn2=128;, score=0.890 total time=  45.4s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 3s 29ms/step - loss: 0.7587 - accuracy: 0.7632\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.3723 - accuracy: 0.8662\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2989 - accuracy: 0.8909\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2599 - accuracy: 0.9040\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2262 - accuracy: 0.9162\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1965 - accuracy: 0.9273\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1767 - accuracy: 0.9345\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.1560 - accuracy: 0.9425\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1394 - accuracy: 0.9496\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.1230 - accuracy: 0.9566\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1081 - accuracy: 0.9613\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0928 - accuracy: 0.9666\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0868 - accuracy: 0.9692\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0764 - accuracy: 0.9725\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0678 - accuracy: 0.9755\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0615 - accuracy: 0.9775\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0606 - accuracy: 0.9780\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0507 - accuracy: 0.9818\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0481 - accuracy: 0.9826\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0454 - accuracy: 0.9840\n",
      "[CV 2/3] END best_MLP_autoencoder__dropout_dense=0.1, best_MLP_autoencoder__n_layers=3, best_MLP_autoencoder__nn1=256, best_MLP_autoencoder__nn2=128;, score=0.883 total time=  45.7s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 3s 29ms/step - loss: 0.7286 - accuracy: 0.7678\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.3734 - accuracy: 0.8662\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2941 - accuracy: 0.8935\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2485 - accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2145 - accuracy: 0.9224\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1864 - accuracy: 0.9312\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1606 - accuracy: 0.9415\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1336 - accuracy: 0.9515\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1233 - accuracy: 0.9560\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.1038 - accuracy: 0.9630\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0867 - accuracy: 0.9692\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0795 - accuracy: 0.9718\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0678 - accuracy: 0.9766\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0613 - accuracy: 0.9778\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0591 - accuracy: 0.9787\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0536 - accuracy: 0.9802\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0506 - accuracy: 0.9823\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0472 - accuracy: 0.9835\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0409 - accuracy: 0.9853\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0384 - accuracy: 0.9865\n",
      "[CV 3/3] END best_MLP_autoencoder__dropout_dense=0.1, best_MLP_autoencoder__n_layers=3, best_MLP_autoencoder__nn1=256, best_MLP_autoencoder__nn2=128;, score=0.876 total time=  45.9s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 3s 23ms/step - loss: 2.6423 - accuracy: 0.6072\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.7966 - accuracy: 0.7575\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6197 - accuracy: 0.7954\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5426 - accuracy: 0.8161\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5014 - accuracy: 0.8260\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4612 - accuracy: 0.8371\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.4299 - accuracy: 0.8464\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4117 - accuracy: 0.8508\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3933 - accuracy: 0.8574 0s - loss: 0.3928 - accuracy: 0.\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3794 - accuracy: 0.8604\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3702 - accuracy: 0.8659\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3572 - accuracy: 0.8689\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3516 - accuracy: 0.8709\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3411 - accuracy: 0.8731\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3358 - accuracy: 0.8757\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3243 - accuracy: 0.8795\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3197 - accuracy: 0.8794\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3165 - accuracy: 0.8799\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3057 - accuracy: 0.8863\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3030 - accuracy: 0.8863\n",
      "[CV 1/3] END best_MLP_autoencoder__dropout_dense=0.25, best_MLP_autoencoder__n_layers=1, best_MLP_autoencoder__nn1=64, best_MLP_autoencoder__nn2=256;, score=0.875 total time=  37.4s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 2.0522 - accuracy: 0.6330\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.7022 - accuracy: 0.7786\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5688 - accuracy: 0.8110\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5039 - accuracy: 0.8276\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4645 - accuracy: 0.8375\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4372 - accuracy: 0.8462\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4165 - accuracy: 0.8512\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3958 - accuracy: 0.8567\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3849 - accuracy: 0.8617\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3743 - accuracy: 0.8645\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3634 - accuracy: 0.8685\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3566 - accuracy: 0.8698\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3461 - accuracy: 0.8736\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3385 - accuracy: 0.8771\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3324 - accuracy: 0.8782\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3228 - accuracy: 0.8805\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3224 - accuracy: 0.8795\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3148 - accuracy: 0.8832\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3112 - accuracy: 0.8842\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3045 - accuracy: 0.8858\n",
      "[CV 2/3] END best_MLP_autoencoder__dropout_dense=0.25, best_MLP_autoencoder__n_layers=1, best_MLP_autoencoder__nn1=64, best_MLP_autoencoder__nn2=256;, score=0.877 total time=  36.9s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.9372 - accuracy: 0.6417\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6905 - accuracy: 0.7738\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5739 - accuracy: 0.8049\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5147 - accuracy: 0.8223\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4733 - accuracy: 0.8351\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4463 - accuracy: 0.8413\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.4237 - accuracy: 0.8486\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.4103 - accuracy: 0.8529\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3916 - accuracy: 0.8584\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3798 - accuracy: 0.8610\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3699 - accuracy: 0.8645\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3583 - accuracy: 0.8694\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3520 - accuracy: 0.8712\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3409 - accuracy: 0.8753\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3378 - accuracy: 0.8763\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3316 - accuracy: 0.8773\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3235 - accuracy: 0.8802\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3193 - accuracy: 0.8830\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3121 - accuracy: 0.8842\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3099 - accuracy: 0.8826\n",
      "[CV 3/3] END best_MLP_autoencoder__dropout_dense=0.25, best_MLP_autoencoder__n_layers=1, best_MLP_autoencoder__nn1=64, best_MLP_autoencoder__nn2=256;, score=0.874 total time=  37.0s\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 24ms/step - loss: 0.8263 - accuracy: 0.7499\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4306 - accuracy: 0.8490\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3636 - accuracy: 0.8688\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3195 - accuracy: 0.8838\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2948 - accuracy: 0.8924\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2736 - accuracy: 0.8994\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2489 - accuracy: 0.9081\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2328 - accuracy: 0.9140\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2198 - accuracy: 0.9197\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2039 - accuracy: 0.9234\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1913 - accuracy: 0.9288\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1805 - accuracy: 0.9316\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1663 - accuracy: 0.9384\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1552 - accuracy: 0.9431\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.1457 - accuracy: 0.9455\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.1376 - accuracy: 0.9483\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1297 - accuracy: 0.9513\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1224 - accuracy: 0.9551\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1152 - accuracy: 0.9565\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1056 - accuracy: 0.9604\n",
      "[CV 1/3] END best_MLP_autoencoder__dropout_dense=0.25, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=128, best_MLP_autoencoder__nn2=256;, score=0.893 total time=  37.2s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.9703 - accuracy: 0.7333\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4509 - accuracy: 0.8445\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3706 - accuracy: 0.8675\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3246 - accuracy: 0.8838\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2884 - accuracy: 0.8949\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2643 - accuracy: 0.9031\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2419 - accuracy: 0.9114\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2267 - accuracy: 0.9157\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2096 - accuracy: 0.9238\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1932 - accuracy: 0.9284\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1808 - accuracy: 0.9344\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.1679 - accuracy: 0.9368\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1589 - accuracy: 0.9402\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.1490 - accuracy: 0.9449\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.1392 - accuracy: 0.9488\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.1290 - accuracy: 0.9523\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1224 - accuracy: 0.9553\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.1138 - accuracy: 0.9579\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1080 - accuracy: 0.9596\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1002 - accuracy: 0.9636\n",
      "[CV 2/3] END best_MLP_autoencoder__dropout_dense=0.25, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=128, best_MLP_autoencoder__nn2=256;, score=0.886 total time=  37.5s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.9892 - accuracy: 0.7290\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4422 - accuracy: 0.8454\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3636 - accuracy: 0.8697\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.3173 - accuracy: 0.8845\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2840 - accuracy: 0.8949\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2588 - accuracy: 0.9043\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2364 - accuracy: 0.9115\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2198 - accuracy: 0.9184\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2024 - accuracy: 0.9243\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1910 - accuracy: 0.9285\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1792 - accuracy: 0.9332\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1631 - accuracy: 0.9390\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1524 - accuracy: 0.9434\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.1485 - accuracy: 0.9448\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1333 - accuracy: 0.9506\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1279 - accuracy: 0.9535\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1166 - accuracy: 0.9581\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1122 - accuracy: 0.9581\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.1064 - accuracy: 0.9604\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1004 - accuracy: 0.9622\n",
      "[CV 3/3] END best_MLP_autoencoder__dropout_dense=0.25, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=128, best_MLP_autoencoder__nn2=256;, score=0.884 total time=  37.4s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 1.0236 - accuracy: 0.7504\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.4328 - accuracy: 0.8465\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.3580 - accuracy: 0.8699\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.3171 - accuracy: 0.8831\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.2819 - accuracy: 0.8964\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2543 - accuracy: 0.9039\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2313 - accuracy: 0.9130\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2169 - accuracy: 0.9178\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1946 - accuracy: 0.9268\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1806 - accuracy: 0.9301\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1685 - accuracy: 0.9352\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1571 - accuracy: 0.9397\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1450 - accuracy: 0.9448\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1363 - accuracy: 0.9486\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1289 - accuracy: 0.9509\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1165 - accuracy: 0.9557\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1117 - accuracy: 0.9577\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1065 - accuracy: 0.9599\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.0975 - accuracy: 0.9632\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.0968 - accuracy: 0.9633\n",
      "[CV 1/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=512, best_MLP_autoencoder__nn2=256;, score=0.895 total time=  41.2s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.9376 - accuracy: 0.7491\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.4324 - accuracy: 0.8475\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.3537 - accuracy: 0.8727\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.3137 - accuracy: 0.8860\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.2755 - accuracy: 0.8984\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.2466 - accuracy: 0.9076\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2289 - accuracy: 0.9151\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2117 - accuracy: 0.9204\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1916 - accuracy: 0.9270\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1749 - accuracy: 0.9349\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1646 - accuracy: 0.9373\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1530 - accuracy: 0.9413\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1404 - accuracy: 0.9469\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1297 - accuracy: 0.9508\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1203 - accuracy: 0.9536\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1129 - accuracy: 0.9571\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1046 - accuracy: 0.9595\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.0985 - accuracy: 0.9627\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.0929 - accuracy: 0.9656\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.0839 - accuracy: 0.9681\n",
      "[CV 2/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=512, best_MLP_autoencoder__nn2=256;, score=0.889 total time=  41.6s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 1.0020 - accuracy: 0.7448\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.4394 - accuracy: 0.8450\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.3606 - accuracy: 0.8693\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.3084 - accuracy: 0.8879\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.2742 - accuracy: 0.8996\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2485 - accuracy: 0.9086\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2231 - accuracy: 0.9168\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2018 - accuracy: 0.9245\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1846 - accuracy: 0.9294\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1730 - accuracy: 0.9342\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1536 - accuracy: 0.9423\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1411 - accuracy: 0.9463\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1298 - accuracy: 0.9502\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1227 - accuracy: 0.9523\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1116 - accuracy: 0.9570\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1022 - accuracy: 0.9607\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0997 - accuracy: 0.9624\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0916 - accuracy: 0.9654\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0881 - accuracy: 0.9659\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0851 - accuracy: 0.9674\n",
      "[CV 3/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=512, best_MLP_autoencoder__nn2=256;, score=0.890 total time=  42.4s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 1.0516 - accuracy: 0.6767\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.4885 - accuracy: 0.8256\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.4084 - accuracy: 0.8540\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.3643 - accuracy: 0.8664\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.3348 - accuracy: 0.8765\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.3043 - accuracy: 0.8874\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.2859 - accuracy: 0.8925\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2697 - accuracy: 0.8981\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2527 - accuracy: 0.9048\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2358 - accuracy: 0.9107\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2243 - accuracy: 0.9140\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2152 - accuracy: 0.9181\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2022 - accuracy: 0.9222\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1911 - accuracy: 0.9270\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.1862 - accuracy: 0.9289\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1728 - accuracy: 0.9328\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1639 - accuracy: 0.9378\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1538 - accuracy: 0.9408\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1516 - accuracy: 0.9416\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.1439 - accuracy: 0.9437\n",
      "[CV 1/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=3, best_MLP_autoencoder__nn1=64, best_MLP_autoencoder__nn2=256;, score=0.886 total time=  40.7s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 1.0866 - accuracy: 0.6870\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.4983 - accuracy: 0.8245\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.4178 - accuracy: 0.8507\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.3765 - accuracy: 0.8640\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.3430 - accuracy: 0.8764\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.3194 - accuracy: 0.8835\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2997 - accuracy: 0.8901\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2834 - accuracy: 0.8949\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2710 - accuracy: 0.8983\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2550 - accuracy: 0.9046\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2430 - accuracy: 0.9092\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2313 - accuracy: 0.9122\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2248 - accuracy: 0.9143\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2086 - accuracy: 0.9214\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2017 - accuracy: 0.9226 0s - los\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1964 - accuracy: 0.9246\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1851 - accuracy: 0.9301\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1784 - accuracy: 0.9305\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1695 - accuracy: 0.9346\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1643 - accuracy: 0.9367\n",
      "[CV 2/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=3, best_MLP_autoencoder__nn1=64, best_MLP_autoencoder__nn2=256;, score=0.882 total time=  41.2s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 1.0000 - accuracy: 0.6983\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.4814 - accuracy: 0.8306\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.4020 - accuracy: 0.8584\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.3615 - accuracy: 0.8695\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.3322 - accuracy: 0.8790\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.3122 - accuracy: 0.8846\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2944 - accuracy: 0.8913\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2743 - accuracy: 0.8980\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2613 - accuracy: 0.9022\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2494 - accuracy: 0.9063\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2340 - accuracy: 0.9111\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2290 - accuracy: 0.9142\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2173 - accuracy: 0.9166\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2071 - accuracy: 0.9206\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1985 - accuracy: 0.9243\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.1883 - accuracy: 0.9273\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1774 - accuracy: 0.9316\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1707 - accuracy: 0.9348\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1673 - accuracy: 0.9357\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1530 - accuracy: 0.9405\n",
      "[CV 3/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=3, best_MLP_autoencoder__nn1=64, best_MLP_autoencoder__nn2=256;, score=0.882 total time=  41.2s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 3s 27ms/step - loss: 0.8863 - accuracy: 0.7791\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.3582 - accuracy: 0.8729\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.2779 - accuracy: 0.8990\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.2227 - accuracy: 0.9195\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1819 - accuracy: 0.9352\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1528 - accuracy: 0.9448\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1261 - accuracy: 0.9545\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1052 - accuracy: 0.9635\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.0891 - accuracy: 0.9699\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0743 - accuracy: 0.9761\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0640 - accuracy: 0.9780\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0536 - accuracy: 0.9827\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0456 - accuracy: 0.9847\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0446 - accuracy: 0.9850\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0403 - accuracy: 0.9863\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0380 - accuracy: 0.9876\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0382 - accuracy: 0.9868\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0323 - accuracy: 0.9890\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0297 - accuracy: 0.9897\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0283 - accuracy: 0.9906\n",
      "[CV 1/3] END best_MLP_autoencoder__dropout_dense=0.1, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=256, best_MLP_autoencoder__nn2=512;, score=0.888 total time=  43.2s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 3s 28ms/step - loss: 1.1296 - accuracy: 0.7606\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.3811 - accuracy: 0.8681\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.2834 - accuracy: 0.8990\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.2246 - accuracy: 0.9205\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.1836 - accuracy: 0.9351\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1484 - accuracy: 0.9479\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1230 - accuracy: 0.9575\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1070 - accuracy: 0.9625\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0868 - accuracy: 0.9702\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0710 - accuracy: 0.9761\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0614 - accuracy: 0.9804\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0509 - accuracy: 0.9842\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0448 - accuracy: 0.9854\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0380 - accuracy: 0.9882\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0314 - accuracy: 0.9906\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0336 - accuracy: 0.9885\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0333 - accuracy: 0.9895\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0324 - accuracy: 0.9891\n",
      "Epoch 00018: early stopping\n",
      "[CV 2/3] END best_MLP_autoencoder__dropout_dense=0.1, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=256, best_MLP_autoencoder__nn2=512;, score=0.880 total time=  38.9s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 3s 28ms/step - loss: 1.1671 - accuracy: 0.7571\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3841 - accuracy: 0.8669\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.2832 - accuracy: 0.8999\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.2238 - accuracy: 0.9199\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.1787 - accuracy: 0.9360\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1440 - accuracy: 0.9497\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.1156 - accuracy: 0.9600\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0955 - accuracy: 0.9687\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0757 - accuracy: 0.9762\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0632 - accuracy: 0.9796\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0531 - accuracy: 0.9834\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0496 - accuracy: 0.9831\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0404 - accuracy: 0.9873\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0374 - accuracy: 0.9883\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0339 - accuracy: 0.9895\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0313 - accuracy: 0.9898\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0315 - accuracy: 0.9891\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0309 - accuracy: 0.9901\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0333 - accuracy: 0.9886\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.0315 - accuracy: 0.9893\n",
      "[CV 3/3] END best_MLP_autoencoder__dropout_dense=0.1, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=256, best_MLP_autoencoder__nn2=512;, score=0.876 total time=  42.9s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 3s 28ms/step - loss: 2.0979 - accuracy: 0.5895\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.7537 - accuracy: 0.7448\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.6017 - accuracy: 0.7861\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5213 - accuracy: 0.8104\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.4710 - accuracy: 0.8254\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.4371 - accuracy: 0.8385\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.4067 - accuracy: 0.8469\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3881 - accuracy: 0.8542\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3610 - accuracy: 0.8603\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3440 - accuracy: 0.8661\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3316 - accuracy: 0.8691\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3156 - accuracy: 0.8770\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3056 - accuracy: 0.8806\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.2920 - accuracy: 0.8849\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.2784 - accuracy: 0.8899\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2743 - accuracy: 0.8917\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2603 - accuracy: 0.8956\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2541 - accuracy: 0.8992\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2475 - accuracy: 0.9016\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2396 - accuracy: 0.9031\n",
      "[CV 1/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=256, best_MLP_autoencoder__nn2=64;, score=0.887 total time=  44.8s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 3s 29ms/step - loss: 2.0315 - accuracy: 0.5936\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.7346 - accuracy: 0.7546\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.6001 - accuracy: 0.7932\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5234 - accuracy: 0.8134\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.4739 - accuracy: 0.8291\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.4344 - accuracy: 0.8400\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.4064 - accuracy: 0.8487\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3815 - accuracy: 0.8548\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3587 - accuracy: 0.8643\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3468 - accuracy: 0.8670\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3331 - accuracy: 0.8715\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3157 - accuracy: 0.8773\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.3032 - accuracy: 0.8826\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2864 - accuracy: 0.8885\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2755 - accuracy: 0.8947\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2628 - accuracy: 0.8971\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2555 - accuracy: 0.8996\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2498 - accuracy: 0.9014\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2396 - accuracy: 0.9042\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.2315 - accuracy: 0.9082\n",
      "[CV 2/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=256, best_MLP_autoencoder__nn2=64;, score=0.886 total time=  45.1s\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 3s 28ms/step - loss: 1.8450 - accuracy: 0.5841\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.7400 - accuracy: 0.7427\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.6225 - accuracy: 0.7792\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5523 - accuracy: 0.8029\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.4954 - accuracy: 0.8181\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.4556 - accuracy: 0.8309\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.4262 - accuracy: 0.8407\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3990 - accuracy: 0.8511\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3714 - accuracy: 0.8607\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3596 - accuracy: 0.8641\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3392 - accuracy: 0.8701\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3276 - accuracy: 0.8738\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3133 - accuracy: 0.8800\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.3010 - accuracy: 0.8860\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.2889 - accuracy: 0.8894\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.2749 - accuracy: 0.8931\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.2675 - accuracy: 0.8957\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.2555 - accuracy: 0.8990\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2528 - accuracy: 0.8985\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.2409 - accuracy: 0.9050\n",
      "[CV 3/3] END best_MLP_autoencoder__dropout_dense=0.5, best_MLP_autoencoder__n_layers=2, best_MLP_autoencoder__nn1=256, best_MLP_autoencoder__nn2=64;, score=0.884 total time=  44.8s\n",
      "Epoch 1/20\n",
      "120/120 [==============================] - 4s 26ms/step - loss: 0.8892 - accuracy: 0.7750\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.4055 - accuracy: 0.8549\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 3s 26ms/step - loss: 0.3469 - accuracy: 0.8740\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.3031 - accuracy: 0.8876\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2764 - accuracy: 0.8963\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.2507 - accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.2323 - accuracy: 0.9115\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.2135 - accuracy: 0.9198\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1949 - accuracy: 0.9256\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1863 - accuracy: 0.9298\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1723 - accuracy: 0.9345\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1606 - accuracy: 0.9379\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1485 - accuracy: 0.9433\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1419 - accuracy: 0.9451\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1317 - accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1230 - accuracy: 0.9525\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1184 - accuracy: 0.9538\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.1111 - accuracy: 0.9574\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1015 - accuracy: 0.9603\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.0985 - accuracy: 0.9628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('best_MLP_autoencoder',\n",
       "                                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x7fc6e993b3d0>)]),\n",
       "                   param_distributions={'best_MLP_autoencoder__dropout_dense': [0.1,\n",
       "                                                                                0.25,\n",
       "                                                                                0.5],\n",
       "                                        'best_MLP_autoencoder__n_layers': [1, 2,\n",
       "                                                                           3],\n",
       "                                        'best_MLP_autoencoder__nn1': [64, 128,\n",
       "                                                                      256,\n",
       "                                                                      512],\n",
       "                                        'best_MLP_autoencoder__nn2': [64, 128,\n",
       "                                                                      256,\n",
       "                                                                      512]},\n",
       "                   random_state=8, scoring=make_scorer(my_custom_loss_func),\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_2.fit(X_joined_train.reshape(-1, 28, 28, 1), y_joined_train, best_MLP_autoencoder__callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cual fue el mejor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_autoencoder_CV\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 8)           1160      \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "flatten_64 (Flatten)         (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "Capa_Oculta_0 (Dense)        (None, 512)               201216    \n",
      "_________________________________________________________________\n",
      "Capa_Oculta_1 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "Dropout_dense_0.5 (Dropout)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Capa_Salida (Dense)          (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 337,018\n",
      "Trainable params: 337,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model_mlp_autoencoder = grid_2.best_estimator_\n",
    "best_model_mlp_autoencoder['best_MLP_autoencoder'].model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia de nuestro modelo baseline, esta vez la búsqueda de hiperparámetros eligió dos capa, una de 512 neuronas y otra de 256, con la máxima regularización (0.5) en dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La accuracy del mejor modelo para MLP post-autoencoder es:  0.89125\n"
     ]
    }
   ],
   "source": [
    "best_score_mlp_autoencoder = grid_2.best_score_\n",
    "print('La accuracy del mejor modelo para MLP post-autoencoder es: ', best_score_mlp_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88915   , 0.88738333, 0.88198333, 0.88276667, 0.87555   ,\n",
       "       0.88741667, 0.89125   , 0.88323333, 0.88143333, 0.88556667])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos ver que los 10 modelos probados arrojaron scores similares.\n",
    "grid_2.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO: Comentar que el resultado obtenido es muy similar a sin hiperparámetros.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Autoencoder con denoising y MLP\n",
    "Otra forma de entrenamiento de los Autoencoders es a través de un Denoising Autoencoder.\n",
    "\n",
    "Se agrega ruido a los datos, usando la función de ruido que definimos en el laboratorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noising_image(data, noise_factor):\n",
    "    noise_dataset = []\n",
    "    for img in data:\n",
    "        noisy_image = img + noise_factor * np.random.randn(*img.shape)\n",
    "        noisy_image = np.clip(noisy_image, 0., 1.)\n",
    "        noise_dataset.append(noisy_image)\n",
    "  \n",
    "    noise_dataset = np.array(noise_dataset)\n",
    "    return noise_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El factor de ruido es relativamente arbitrario. En este caso, utilizamos 0.2, como en el laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_noise = noising_image(X_train, noise_factor=0.2)\n",
    "X_val_noise = noising_image(X_val, noise_factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28)\n",
      "(12000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_noise.shape)\n",
    "print(X_val_noise.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo se ve la imagen del zapato de arriba con este ruido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_train_noise[i], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, en comparación a la imagen inicial, esta se ve algo más \"borrosa\", como era de esperarse. Procedemos entonces a construir el autoencoder con este dataset con un preentrenamiento adicional.\n",
    "\n",
    "Este autoencoder tiene la misma estructura del anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_autoencoder = Sequential(name=\"Denoising_Autoencoder\")\n",
    "\n",
    "#Encoder\n",
    "denoising_autoencoder.add(Conv2D(filters=16, kernel_size=3, strides=2, padding=\"same\", input_shape=(28, 28, 1)))\n",
    "denoising_autoencoder.add(Conv2D(filters=8, kernel_size=3, strides=2, padding=\"same\"))\n",
    "\n",
    "#Encoded image\n",
    "denoising_autoencoder.add(Conv2D(filters=8, kernel_size=3, strides=1, padding=\"same\", name=\"encoder\"))\n",
    "\n",
    "#Decoder\n",
    "denoising_autoencoder.add(Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding=\"same\"))\n",
    "denoising_autoencoder.add(Conv2DTranspose(filters=1, kernel_size=3, strides=2, activation='sigmoid', padding=\"same\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la misma función de pérdida y optimizador que en el paso 1.2 para el autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Denoising_Autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 7, 7, 8)           1160      \n",
      "_________________________________________________________________\n",
      "encoder (Conv2D)             (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 3,217\n",
      "Trainable params: 3,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "denoising_autoencoder.compile(loss='mean_squared_error', optimizer='adam')\n",
    "denoising_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, entrenamos, teniendo en cuenta los callbacks del inicio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0514 - val_loss: 0.0222\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0192 - val_loss: 0.0173\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0164 - val_loss: 0.0152\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0144 - val_loss: 0.0136\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 4s 19ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 5s 19ms/step - loss: 0.0103 - val_loss: 0.0102\n"
     ]
    }
   ],
   "source": [
    "history_denoising = denoising_autoencoder.fit(X_train_noise.reshape(-1, 28, 28, 1),          \n",
    "                X_train.reshape(-1, 28, 28, 1), \n",
    "                epochs=20, \n",
    "                batch_size=200, \n",
    "                callbacks=[callbacks],\n",
    "                validation_data=(\n",
    "                    X_val_noise.reshape(-1, 28, 28, 1), \n",
    "                    X_val.reshape(-1, 28, 28, 1)\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto, podemos revisar qué tan bien reconstruidas fueron las imágenes por el autoencoder con ruido. Tomamos sólo las 10 primeras imágenes, como hicimos en el laboratorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predichas_denoising = denoising_autoencoder.predict(X_val_noise[:10].reshape(-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0102\n",
      "Validation Loss : 0.010\n"
     ]
    }
   ],
   "source": [
    "evaluation_denoising = denoising_autoencoder.evaluate(X_val_noise.reshape(-1, 28, 28, 1), X_val.reshape(-1, 28, 28, 1))\n",
    "print('Validation Loss : {:.3f}'.format(evaluation_denoising))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisemos ahora que las imágenes hayan quedado bien reconstruidas. La primera fila representa las imágenes originales. La segunda, corresponde a las imágenes con el ruido impuesto. La última fila corresponde a las imágenes predichas por el denoising autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "\n",
    "for images, row in zip([X_val[:10], X_val_noise[:10], predichas_denoising], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que, para el ruido agregado, el modelo reconstruye bastante bien las imágenes (claro está, con un poco de ruido) pero la \"silueta\" de la figura se conserva. Incluso con el ruido, un humano puede reconocer la prenda de vestir en cuestión. Note que con este denoising autoencoder, lo que estamos evitando es que el output de la red sea exactamente el input (i.e. que el autoencoder sea la identidad y no esté haciendo nada). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, podemos construir un MLP (baseline, primero) a partir de la tercera capa del denoising autoencoder, con _casi_ los mismos parámetros del que hicimos tras el primer autoencoder, en la sección anterior. Lo único diferente será que, para la primera capa densa, bajamos el número de neuronas a 128 y agregaremos una capa profunda adicional (de 64 neuronas), pues se nos está pidiendo específicamente una red profunda. Agregamos consecuentemente una capa de dropout de 0.5, para la regularización. Esta se vuelve especialmente importante porque reduciremos la cantidad de datos. Por esta misma razón, redujimos el número de neuronas. Entonces,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_denoising_autoencoder = Sequential(name='MLP_post_denoising_autoencoder')\n",
    "# Agregamos hasta la tercera capa del denoising autoencoder a nuestro MLP\n",
    "mlp_denoising_autoencoder.add(denoising_autoencoder.layers[0])\n",
    "mlp_denoising_autoencoder.add(denoising_autoencoder.layers[1])\n",
    "mlp_denoising_autoencoder.add(denoising_autoencoder.layers[2])\n",
    "# Agregamos una capa para aplanar la imagen y dársela al MLP.\n",
    "mlp_denoising_autoencoder.add(Flatten())\n",
    "# Agregamos una capa densa de 128 neuronas con función de activación relu\n",
    "mlp_denoising_autoencoder.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "# Agregamos una capa de regularización con p=0.5 (i.e. máxima regularización)\n",
    "mlp_denoising_autoencoder.add(Dropout(0.5))\n",
    "# Agregamos una capa densa de 64 neuronas con función de activación relu\n",
    "mlp_denoising_autoencoder.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "# Agregamos una capa de regularización con p=0.5 (i.e. máxima regularización)\n",
    "mlp_denoising_autoencoder.add(Dropout(0.5))\n",
    "# Agregamos la capa de salida\n",
    "mlp_denoising_autoencoder.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_post_denoising_autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 7, 7, 8)           1160      \n",
      "_________________________________________________________________\n",
      "encoder (Conv2D)             (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "flatten_65 (Flatten)         (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               50304     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 61,114\n",
      "Trainable params: 61,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_denoising_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la misma función de pérdida, optimizador y métrica que para los otros MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_denoising_autoencoder.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, como sugiere el enunciado, recortamos los datos con los que alimentamos el perceptrón al 10%. Por simplicidad, tomamos el 10% inicial de los datos. Así, como"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño conjunto entrenamiento: 48000\n",
      "Tamaño conjunto validación: 12000\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño conjunto entrenamiento:\", len(X_train))\n",
    "print(\"Tamaño conjunto validación:\", len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debemos tomar 4800 datos en entrenamiento y 1200 en test. De esta forma,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_noise_reduced, y_train_reduced = X_train_noise[:4800], y_train[:4800]\n",
    "X_val_noise_reduced, y_val_reduced = X_val_noise[:1200], y_val[:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si lo hacemos aleatorio:\n",
    "# indices_train = random.sample(list(range(len(X_train_noise))), int(0.1*len(X_train_noise)))\n",
    "# indices_val = random.sample(list(range(len(X_val_noise))), int(0.1*len(X_val_noise)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando los callbacks de siempre, obtenemos que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 4.3745 - accuracy: 0.7058 - val_loss: 1.4058 - val_accuracy: 0.7700\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.9474 - accuracy: 0.7569 - val_loss: 1.0080 - val_accuracy: 0.7858\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6602 - accuracy: 0.7833 - val_loss: 0.9347 - val_accuracy: 0.7875\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5312 - accuracy: 0.8075 - val_loss: 0.9418 - val_accuracy: 0.7967\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4493 - accuracy: 0.8352 - val_loss: 0.9516 - val_accuracy: 0.8017\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4237 - accuracy: 0.8435 - val_loss: 0.9698 - val_accuracy: 0.7967\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3968 - accuracy: 0.8517 - val_loss: 0.9697 - val_accuracy: 0.8042\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3314 - accuracy: 0.8665 - val_loss: 1.0124 - val_accuracy: 0.8117\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3215 - accuracy: 0.8710 - val_loss: 0.9913 - val_accuracy: 0.8167\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3137 - accuracy: 0.8777 - val_loss: 1.0222 - val_accuracy: 0.8150\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3016 - accuracy: 0.8769 - val_loss: 1.0376 - val_accuracy: 0.8083\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2864 - accuracy: 0.8879 - val_loss: 1.0406 - val_accuracy: 0.8075\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2654 - accuracy: 0.8913 - val_loss: 1.0386 - val_accuracy: 0.8142\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2355 - accuracy: 0.9004 - val_loss: 1.0720 - val_accuracy: 0.8192\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2381 - accuracy: 0.9006 - val_loss: 1.0564 - val_accuracy: 0.8242\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2311 - accuracy: 0.9062 - val_loss: 1.0842 - val_accuracy: 0.8158\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2191 - accuracy: 0.9077 - val_loss: 1.0973 - val_accuracy: 0.8183\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2149 - accuracy: 0.9117 - val_loss: 1.1197 - val_accuracy: 0.8150\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2106 - accuracy: 0.9150 - val_loss: 1.1338 - val_accuracy: 0.8167\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1898 - accuracy: 0.9227 - val_loss: 1.1158 - val_accuracy: 0.8208\n"
     ]
    }
   ],
   "source": [
    "history_mlp_denoising_autoencoder = mlp_autoencoder.fit(\n",
    "                    X_train_noise_reduced.reshape(-1, 28, 28, 1), \n",
    "                    y_train_reduced, epochs=20, batch_size=200, callbacks=callbacks,\n",
    "                    validation_data=(\n",
    "                    X_val_noise_reduced.reshape(-1, 28, 28, 1), \n",
    "                    y_val_reduced\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fourth.png'/>\n",
    "\n",
    "**TODO: COMENTAR. EN ESPECIAL CON RESPECTO A LOS DOS ANTERIORES MODELOS Y DECIR QUE PUES ESTE TIENE MUCHOS MENOS DATOS.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, hacemos la búsqueda de hiperparámetros. Por las mismas razones de siempre, únicamente ajustamos el número de neuronas, el número de capas y la tasa de Dropout al final de la capa densa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_red(nn1=256, nn2=256, n_layers= 3, dropout_dense=0.5):\n",
    "    output = 10 # Tenemos 10 neuronas en la capa oculta pues son las 10 clases de salida\n",
    "    clf = Sequential(name='MLP_denoising_autoencoder_CV')\n",
    "    # Agregamos las 3 primeras capas del autoencoder\n",
    "    clf.add(denoising_autoencoder.layers[0])\n",
    "    clf.add(denoising_autoencoder.layers[1])\n",
    "    clf.add(denoising_autoencoder.layers[2])\n",
    "    # Agregamos una capa para aplanar la imagen y dársela al MLP.\n",
    "    clf.add(Flatten())\n",
    "    first = True\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            clf.add(Dense(nn1, activation='relu', name='Capa_Oculta_{0}'.format(i))) # num neuronas capa 1\n",
    "            first = False\n",
    "        else:\n",
    "            clf.add(Dense(nn2, activation='relu', name = 'Capa_Oculta_{0}'.format(i))) # num neuronas capa 2, 3 y 4\n",
    "    # Unicamente antes de que el modelo termine agregamos el dropout.\n",
    "    clf.add(Dropout(dropout_dense,name='Dropout_dense_{0}'.format(dropout_dense))) # Dropout (parecido a regularizacion)\n",
    "    clf.add(Dense(output, activation='softmax', name= 'Capa_Salida')) # Capa de salidad\n",
    "\n",
    "    clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # Valores por defecto\n",
    "    \n",
    "    return clf\n",
    "\n",
    "# Modelo que utiliza el GridSearch\n",
    "modelCV_mlp_autoencoder_denoising = KerasClassifier(build_fn=entrenar_red, epochs=20, batch_size=500,verbose=1) # Modelo esqueleto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo \"de esqueleto\" de hiperparámetros es prácticamente equivalente a la anterior, lo único que cambia son las capas iniciales (le pasamos las del denoising autoencoder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta búsqueda de hiperparámetros, consideramos un menor número de capas y de neuronas. Sospechamos que el modelo baseline está haciendo overfitting, por las diferencias en las métricas entre entrenamiento y validación. Entonces, disminuimos el número de neuronas y de capas a evaluar.\n",
    "\n",
    "Consideramos 16, 32 y 64 neuronas entre únicamente 2, 3 o 4 capas (no consideramos una sola pues, según entendemos del enunciado, se quiere una red más profunda - más de una capa).\n",
    "\n",
    "Como tenemos tan poquitos datos aquí, podemos considerar GridSearch (no Randomized) ya que corre muy rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_3 = Pipeline([('best_MLP_denoising_autoencoder', modelCV_mlp_autoencoder_denoising)]) # Creamos la pipeline\n",
    "\n",
    "# Tomamos la grilla de hiperparametros \n",
    "param_grid = dict(\n",
    "                  best_MLP_denoising_autoencoder__nn1 = [16,32,64],\n",
    "                  best_MLP_denoising_autoencoder__nn2 = [16,32,64],\n",
    "                  best_MLP_denoising_autoencoder__n_layers = [2,3,4],\n",
    "                  best_MLP_denoising_autoencoder__dropout_dense = [0.1,0.25,0.5]\n",
    "                  )\n",
    "\n",
    "# Definimos la metrica \n",
    "score = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "# Creamos la grilla\n",
    "# Podriamos usar mas iteraciones en el CV, pero lo intentamos correr y se murio el kernel.\n",
    "# Por eso lo redujimos\n",
    "# grid_3 = RandomizedSearchCV(pipe_3, param_grid, verbose=3, cv=3, n_iter=20, random_state=28)\n",
    "grid_3 = GridSearchCV(pipe_3, param_grid=param_grid,scoring=score,cv=3,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_joined_train_reduced = np.array(list(X_train_noise_reduced) + list(X_val_noise_reduced))\n",
    "y_joined_train_reduced = np.array(list(y_train_reduced) + list(y_val_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.3579 - accuracy: 0.1562\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0555 - accuracy: 0.3100\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8919 - accuracy: 0.3900\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7414 - accuracy: 0.4380\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6102 - accuracy: 0.4805\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4557 - accuracy: 0.5397\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3565 - accuracy: 0.5617\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2522 - accuracy: 0.5870\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1760 - accuracy: 0.6075\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0778 - accuracy: 0.6373\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0302 - accuracy: 0.6463\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0039 - accuracy: 0.6593\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9507 - accuracy: 0.6660\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9385 - accuracy: 0.6777\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8756 - accuracy: 0.6973\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8679 - accuracy: 0.7005\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8502 - accuracy: 0.7055\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8190 - accuracy: 0.7180\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8111 - accuracy: 0.7157\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7850 - accuracy: 0.7295\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.738 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 2.4375 - accuracy: 0.2030\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8714 - accuracy: 0.3370\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6490 - accuracy: 0.4225\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4784 - accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3442 - accuracy: 0.5475\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2442 - accuracy: 0.5855\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1515 - accuracy: 0.6058\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0835 - accuracy: 0.6215\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0092 - accuracy: 0.6405\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9648 - accuracy: 0.6463\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9022 - accuracy: 0.6685\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8749 - accuracy: 0.6758\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8734 - accuracy: 0.6735\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8382 - accuracy: 0.6867\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8114 - accuracy: 0.6935\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7963 - accuracy: 0.6915\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7668 - accuracy: 0.7055\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7683 - accuracy: 0.7032\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7584 - accuracy: 0.7105\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7402 - accuracy: 0.7132\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.753 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 3.2536 - accuracy: 0.1235\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0991 - accuracy: 0.2225\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9091 - accuracy: 0.3113\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7849 - accuracy: 0.3585\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6783 - accuracy: 0.3713\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.5630 - accuracy: 0.3995\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.4570 - accuracy: 0.4412\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3261 - accuracy: 0.4860\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2504 - accuracy: 0.5140\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1821 - accuracy: 0.5530\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1293 - accuracy: 0.5853\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0712 - accuracy: 0.6105\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0114 - accuracy: 0.6270\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9806 - accuracy: 0.6323\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9269 - accuracy: 0.6600\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8821 - accuracy: 0.6790\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8513 - accuracy: 0.6955\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8051 - accuracy: 0.7122\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7998 - accuracy: 0.7205\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7727 - accuracy: 0.7280\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.757 total time=   3.9s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 2.6842 - accuracy: 0.1530\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9896 - accuracy: 0.2718\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7182 - accuracy: 0.4070\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4381 - accuracy: 0.5077\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2108 - accuracy: 0.5782\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0668 - accuracy: 0.6237\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9739 - accuracy: 0.6570\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9084 - accuracy: 0.6722\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8787 - accuracy: 0.6835\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8344 - accuracy: 0.6990\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7963 - accuracy: 0.7190\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7715 - accuracy: 0.7247\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7378 - accuracy: 0.7325\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7272 - accuracy: 0.7433\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7076 - accuracy: 0.7475\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6791 - accuracy: 0.7573\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6728 - accuracy: 0.7510\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6573 - accuracy: 0.7642\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6394 - accuracy: 0.7697\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6236 - accuracy: 0.7715\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.757 total time=   4.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 3.3382 - accuracy: 0.1382\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0731 - accuracy: 0.2348\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9189 - accuracy: 0.3000\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7732 - accuracy: 0.3515\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6048 - accuracy: 0.4257\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4633 - accuracy: 0.4735\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3203 - accuracy: 0.5255\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2031 - accuracy: 0.5623\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1224 - accuracy: 0.5895\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0546 - accuracy: 0.6267\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9774 - accuracy: 0.6600\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9282 - accuracy: 0.6668\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8825 - accuracy: 0.6827\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8533 - accuracy: 0.6845\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8292 - accuracy: 0.6975\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8059 - accuracy: 0.7085\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7724 - accuracy: 0.7230\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7616 - accuracy: 0.7253\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7298 - accuracy: 0.7312\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7155 - accuracy: 0.7405\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.760 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 2.3390 - accuracy: 0.2257\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8017 - accuracy: 0.3600\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5873 - accuracy: 0.4300\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3165 - accuracy: 0.5370\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1107 - accuracy: 0.6108\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9886 - accuracy: 0.6572\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9098 - accuracy: 0.6747\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8539 - accuracy: 0.6948\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8008 - accuracy: 0.7125\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7803 - accuracy: 0.7185\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7422 - accuracy: 0.7402\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7109 - accuracy: 0.7437\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7067 - accuracy: 0.7405\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6754 - accuracy: 0.7502\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6580 - accuracy: 0.7632\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6580 - accuracy: 0.7567\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6435 - accuracy: 0.7665\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6360 - accuracy: 0.7675\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6155 - accuracy: 0.7763\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5994 - accuracy: 0.7878\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.774 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.4055 - accuracy: 0.2090\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6954 - accuracy: 0.3848\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3565 - accuracy: 0.5135\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1153 - accuracy: 0.5953\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0018 - accuracy: 0.6275\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9017 - accuracy: 0.6643\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8589 - accuracy: 0.6805\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8082 - accuracy: 0.7023\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7790 - accuracy: 0.7028\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7292 - accuracy: 0.7265\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7210 - accuracy: 0.7210\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6955 - accuracy: 0.7295\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6784 - accuracy: 0.7430\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6525 - accuracy: 0.7502\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6308 - accuracy: 0.7648\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6155 - accuracy: 0.7697\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6017 - accuracy: 0.7818\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5929 - accuracy: 0.7788\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5759 - accuracy: 0.7895\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5608 - accuracy: 0.7955\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.782 total time=   4.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 3.1670 - accuracy: 0.1343\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9691 - accuracy: 0.3410\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5766 - accuracy: 0.4760\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3061 - accuracy: 0.5565\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1411 - accuracy: 0.6070\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0139 - accuracy: 0.6568\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9382 - accuracy: 0.6747\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8564 - accuracy: 0.7035\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7974 - accuracy: 0.7222\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7569 - accuracy: 0.7410\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7317 - accuracy: 0.7372\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7138 - accuracy: 0.7465\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6808 - accuracy: 0.7560\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6633 - accuracy: 0.7645\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6446 - accuracy: 0.7715\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6217 - accuracy: 0.7830\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6154 - accuracy: 0.7835\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5893 - accuracy: 0.7818\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.5803 - accuracy: 0.7890\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5737 - accuracy: 0.7937\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.808 total time=   4.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5472 - accuracy: 0.1885\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6530 - accuracy: 0.4185\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3213 - accuracy: 0.5278\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1196 - accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9797 - accuracy: 0.6445\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8980 - accuracy: 0.6708\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8434 - accuracy: 0.6905\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7902 - accuracy: 0.7178\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7543 - accuracy: 0.7287\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7355 - accuracy: 0.7370\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7118 - accuracy: 0.7405\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6860 - accuracy: 0.7533\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6658 - accuracy: 0.7588\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6526 - accuracy: 0.7625\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6361 - accuracy: 0.7695\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6197 - accuracy: 0.7715\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6013 - accuracy: 0.7788\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5969 - accuracy: 0.7837\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5769 - accuracy: 0.7918\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5766 - accuracy: 0.7878\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.778 total time=   4.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.2932 - accuracy: 0.1678\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8982 - accuracy: 0.3450\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6565 - accuracy: 0.4380\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4923 - accuracy: 0.5002\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3681 - accuracy: 0.5515\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2831 - accuracy: 0.5767\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2143 - accuracy: 0.6025\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1697 - accuracy: 0.6175\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1159 - accuracy: 0.6370\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0731 - accuracy: 0.6420\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0177 - accuracy: 0.6530\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9978 - accuracy: 0.6572\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9671 - accuracy: 0.6690\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9315 - accuracy: 0.6695\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8958 - accuracy: 0.6798\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8433 - accuracy: 0.6940\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8305 - accuracy: 0.7007\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8018 - accuracy: 0.7297\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7571 - accuracy: 0.7460\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7066 - accuracy: 0.7690\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.774 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 3.4396 - accuracy: 0.2275\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9115 - accuracy: 0.3775\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5973 - accuracy: 0.4810\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3997 - accuracy: 0.5477\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2981 - accuracy: 0.5675\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1865 - accuracy: 0.5950\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1146 - accuracy: 0.6245\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0476 - accuracy: 0.6515\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9855 - accuracy: 0.6737\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9159 - accuracy: 0.6935\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8697 - accuracy: 0.7135\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8356 - accuracy: 0.7115\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8008 - accuracy: 0.7275\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7642 - accuracy: 0.7343\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7459 - accuracy: 0.7427\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7125 - accuracy: 0.7560\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6996 - accuracy: 0.7585\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6761 - accuracy: 0.7660\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6624 - accuracy: 0.7710\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6473 - accuracy: 0.7753\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.802 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.4643 - accuracy: 0.1210\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0579 - accuracy: 0.2418\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8036 - accuracy: 0.3470\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5697 - accuracy: 0.4518\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3929 - accuracy: 0.5135\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2626 - accuracy: 0.5505\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1518 - accuracy: 0.5903\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0948 - accuracy: 0.6018\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0102 - accuracy: 0.6313\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9506 - accuracy: 0.6553\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9098 - accuracy: 0.6680\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8618 - accuracy: 0.6950\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8407 - accuracy: 0.6892\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7997 - accuracy: 0.7057\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7872 - accuracy: 0.7128\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7547 - accuracy: 0.7287\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7492 - accuracy: 0.7243\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7164 - accuracy: 0.7483\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7058 - accuracy: 0.7430\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6944 - accuracy: 0.7473\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.773 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.9713 - accuracy: 0.1950\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6007 - accuracy: 0.4530\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2856 - accuracy: 0.5580\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1051 - accuracy: 0.6192\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9662 - accuracy: 0.6595\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8829 - accuracy: 0.6957\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8235 - accuracy: 0.7122\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7826 - accuracy: 0.7310\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7254 - accuracy: 0.7483\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7003 - accuracy: 0.7610\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6904 - accuracy: 0.7577\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6739 - accuracy: 0.7645\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6380 - accuracy: 0.7750\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6249 - accuracy: 0.7807\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6118 - accuracy: 0.7832\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5863 - accuracy: 0.7928\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5796 - accuracy: 0.7920\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5644 - accuracy: 0.8043\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5570 - accuracy: 0.7980\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5425 - accuracy: 0.8105\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.790 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.4909 - accuracy: 0.2377\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4539 - accuracy: 0.4967\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1964 - accuracy: 0.5895\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0512 - accuracy: 0.6288\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9582 - accuracy: 0.6633\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8880 - accuracy: 0.6852\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8222 - accuracy: 0.7013\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7772 - accuracy: 0.7258\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7609 - accuracy: 0.7260\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7241 - accuracy: 0.7398\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6930 - accuracy: 0.7470\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6832 - accuracy: 0.7542\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6568 - accuracy: 0.7620\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6299 - accuracy: 0.7742\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6165 - accuracy: 0.7790\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6080 - accuracy: 0.7795\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5936 - accuracy: 0.7880\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5802 - accuracy: 0.7928\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5742 - accuracy: 0.7980\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5495 - accuracy: 0.8033\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.816 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.9125 - accuracy: 0.2185\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5858 - accuracy: 0.4527\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2733 - accuracy: 0.5650\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0849 - accuracy: 0.6435\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9626 - accuracy: 0.6862\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8726 - accuracy: 0.7075\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8032 - accuracy: 0.7157\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7572 - accuracy: 0.7260\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7090 - accuracy: 0.7492\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6896 - accuracy: 0.7527\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6719 - accuracy: 0.7590\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6384 - accuracy: 0.7695\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6187 - accuracy: 0.7872\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6069 - accuracy: 0.7828\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5843 - accuracy: 0.7912\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5784 - accuracy: 0.7883\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5543 - accuracy: 0.8037\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5498 - accuracy: 0.7990\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5435 - accuracy: 0.8070\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5287 - accuracy: 0.8070\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.804 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.4211 - accuracy: 0.2725\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 27ms/step - loss: 1.4434 - accuracy: 0.5075\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1068 - accuracy: 0.6160\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9291 - accuracy: 0.6575\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8156 - accuracy: 0.7085\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7564 - accuracy: 0.7310\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6994 - accuracy: 0.7505\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6708 - accuracy: 0.7598\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6424 - accuracy: 0.7730\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6167 - accuracy: 0.7760\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6027 - accuracy: 0.7840\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5816 - accuracy: 0.7862\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5731 - accuracy: 0.7985\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5553 - accuracy: 0.7985\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5454 - accuracy: 0.8037\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5258 - accuracy: 0.8112\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5128 - accuracy: 0.8108\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4972 - accuracy: 0.8190\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4989 - accuracy: 0.8235\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4855 - accuracy: 0.8250\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.799 total time=   4.8s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.6433 - accuracy: 0.1905\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5288 - accuracy: 0.4803\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1.1651 - accuracy: 0.5997\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9568 - accuracy: 0.6633\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8668 - accuracy: 0.6902\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7867 - accuracy: 0.7130\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7265 - accuracy: 0.7293\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6853 - accuracy: 0.7485\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6478 - accuracy: 0.7590\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6190 - accuracy: 0.7772\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5998 - accuracy: 0.7772\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6006 - accuracy: 0.7825\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5668 - accuracy: 0.7897\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5563 - accuracy: 0.7940\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5285 - accuracy: 0.8083\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5217 - accuracy: 0.8108\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5134 - accuracy: 0.8125\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5065 - accuracy: 0.8177\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5023 - accuracy: 0.8142\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4798 - accuracy: 0.8278\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.816 total time=   4.7s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.4855 - accuracy: 0.2400\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.5211 - accuracy: 0.4830\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1466 - accuracy: 0.5993\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9583 - accuracy: 0.6650\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8733 - accuracy: 0.6980\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7983 - accuracy: 0.7185\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7346 - accuracy: 0.7312\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6833 - accuracy: 0.7520\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6637 - accuracy: 0.7555\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6331 - accuracy: 0.7730\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6114 - accuracy: 0.7797\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5915 - accuracy: 0.7872\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5673 - accuracy: 0.7895\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5541 - accuracy: 0.7962\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5431 - accuracy: 0.7995\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5337 - accuracy: 0.8050\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5223 - accuracy: 0.8125\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5059 - accuracy: 0.8150\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4967 - accuracy: 0.8160\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4813 - accuracy: 0.8220\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.807 total time=   4.7s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.2958 - accuracy: 0.2333\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5107 - accuracy: 0.4442\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2825 - accuracy: 0.5475\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1674 - accuracy: 0.6115\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0793 - accuracy: 0.6520\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0038 - accuracy: 0.6790\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9408 - accuracy: 0.6935\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8987 - accuracy: 0.7040\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8504 - accuracy: 0.7143\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8162 - accuracy: 0.7222\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7720 - accuracy: 0.7377\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7504 - accuracy: 0.7375\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7220 - accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6895 - accuracy: 0.7577\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6988 - accuracy: 0.7525\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6682 - accuracy: 0.7563\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6530 - accuracy: 0.7613\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6435 - accuracy: 0.7665\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6221 - accuracy: 0.7738\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6147 - accuracy: 0.7780\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.786 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.4594 - accuracy: 0.2387\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6046 - accuracy: 0.4403\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3473 - accuracy: 0.5268\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2058 - accuracy: 0.5817\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0990 - accuracy: 0.6292\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9863 - accuracy: 0.6670\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9143 - accuracy: 0.6940\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8312 - accuracy: 0.7182\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7788 - accuracy: 0.7355\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7571 - accuracy: 0.7398\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7113 - accuracy: 0.7555\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6923 - accuracy: 0.7600\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6485 - accuracy: 0.7680\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6412 - accuracy: 0.7695\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6302 - accuracy: 0.7747\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6089 - accuracy: 0.7815\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5886 - accuracy: 0.7930\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5792 - accuracy: 0.7883\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5661 - accuracy: 0.7950\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5539 - accuracy: 0.7997\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.801 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.9122 - accuracy: 0.1787\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7212 - accuracy: 0.4367\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4518 - accuracy: 0.5247\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2696 - accuracy: 0.5778\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1238 - accuracy: 0.6248\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0362 - accuracy: 0.6507\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9405 - accuracy: 0.6697\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8791 - accuracy: 0.6877\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8336 - accuracy: 0.7165\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7712 - accuracy: 0.7385\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7286 - accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7040 - accuracy: 0.7638\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6735 - accuracy: 0.7663\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6499 - accuracy: 0.7753\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6249 - accuracy: 0.7822\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6120 - accuracy: 0.7870\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5971 - accuracy: 0.7920\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5832 - accuracy: 0.7940\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5723 - accuracy: 0.7943\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5508 - accuracy: 0.8037\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.810 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.5376 - accuracy: 0.3088\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2071 - accuracy: 0.5640\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9758 - accuracy: 0.6540\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8399 - accuracy: 0.6975\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7568 - accuracy: 0.7308\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6999 - accuracy: 0.7510\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6420 - accuracy: 0.7678\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6279 - accuracy: 0.7720\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6111 - accuracy: 0.7847\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5783 - accuracy: 0.7950\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5561 - accuracy: 0.7958\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5321 - accuracy: 0.8152\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5343 - accuracy: 0.8065\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5169 - accuracy: 0.8145\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4976 - accuracy: 0.8273\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4881 - accuracy: 0.8230\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4739 - accuracy: 0.8245\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4704 - accuracy: 0.8257\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4502 - accuracy: 0.8430\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4455 - accuracy: 0.8415\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.805 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.8688 - accuracy: 0.2545\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3746 - accuracy: 0.5130\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0514 - accuracy: 0.6407\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8818 - accuracy: 0.6862\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8057 - accuracy: 0.7045\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7452 - accuracy: 0.7320\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6876 - accuracy: 0.7580\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6467 - accuracy: 0.7665\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6212 - accuracy: 0.7753\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6005 - accuracy: 0.7832\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5755 - accuracy: 0.7862\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5428 - accuracy: 0.8010\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5280 - accuracy: 0.8108\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5162 - accuracy: 0.8245\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5013 - accuracy: 0.8190\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4921 - accuracy: 0.8235\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4658 - accuracy: 0.8347\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4724 - accuracy: 0.8275\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4525 - accuracy: 0.8418\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4370 - accuracy: 0.8490\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.825 total time=   4.6s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.3902 - accuracy: 0.3015\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1913 - accuracy: 0.5910\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9489 - accuracy: 0.6710\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8178 - accuracy: 0.7225\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7516 - accuracy: 0.7390\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6904 - accuracy: 0.7555\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6774 - accuracy: 0.7630\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6304 - accuracy: 0.7778\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6044 - accuracy: 0.7785\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5776 - accuracy: 0.7905\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5541 - accuracy: 0.8020\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5347 - accuracy: 0.8092\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5294 - accuracy: 0.8073\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5184 - accuracy: 0.8077\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4934 - accuracy: 0.8227\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4781 - accuracy: 0.8278\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4678 - accuracy: 0.8338\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4591 - accuracy: 0.8328\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4534 - accuracy: 0.8355\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4410 - accuracy: 0.8485\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.813 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.1407 - accuracy: 0.3517\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0657 - accuracy: 0.6185\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8557 - accuracy: 0.6992\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7354 - accuracy: 0.7358\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6606 - accuracy: 0.7607\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6146 - accuracy: 0.7765\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5704 - accuracy: 0.7968\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5469 - accuracy: 0.8040\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5241 - accuracy: 0.8087\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4895 - accuracy: 0.8235\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4805 - accuracy: 0.8292\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4647 - accuracy: 0.8330\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4517 - accuracy: 0.8388\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4350 - accuracy: 0.8420\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4201 - accuracy: 0.8515\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4057 - accuracy: 0.8550\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4046 - accuracy: 0.8583\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3862 - accuracy: 0.8565\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3825 - accuracy: 0.8668\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3641 - accuracy: 0.8658\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.820 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.2067 - accuracy: 0.3220\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1137 - accuracy: 0.6200\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8658 - accuracy: 0.7035\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7441 - accuracy: 0.7437\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6834 - accuracy: 0.7515\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6418 - accuracy: 0.7732\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5959 - accuracy: 0.7895\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5561 - accuracy: 0.7958\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5364 - accuracy: 0.8065\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5190 - accuracy: 0.8185\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4956 - accuracy: 0.8227\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4863 - accuracy: 0.8210\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4622 - accuracy: 0.8328\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4499 - accuracy: 0.8385\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4361 - accuracy: 0.8432\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4260 - accuracy: 0.8468\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4088 - accuracy: 0.8520\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3914 - accuracy: 0.8612\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3789 - accuracy: 0.8637\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3802 - accuracy: 0.8590\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.823 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 2.4264 - accuracy: 0.2885\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1521 - accuracy: 0.5838\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8706 - accuracy: 0.6855\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7575 - accuracy: 0.7180\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6727 - accuracy: 0.7523\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6419 - accuracy: 0.7675\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5900 - accuracy: 0.7857\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5516 - accuracy: 0.7962\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5296 - accuracy: 0.8048\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5047 - accuracy: 0.8140\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4932 - accuracy: 0.8170\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4676 - accuracy: 0.8282\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4480 - accuracy: 0.8365\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4331 - accuracy: 0.8438\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4297 - accuracy: 0.8413\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4099 - accuracy: 0.8518\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4007 - accuracy: 0.8487\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3964 - accuracy: 0.8572\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3866 - accuracy: 0.8565\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3735 - accuracy: 0.8640\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.815 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 2.6130 - accuracy: 0.1410\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0977 - accuracy: 0.2350\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8892 - accuracy: 0.3625\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7160 - accuracy: 0.4047\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5720 - accuracy: 0.4552\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4475 - accuracy: 0.5002\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3388 - accuracy: 0.5270\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2560 - accuracy: 0.5533\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1802 - accuracy: 0.5735\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1203 - accuracy: 0.6000\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0451 - accuracy: 0.6315\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9650 - accuracy: 0.6750\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9092 - accuracy: 0.6855\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8678 - accuracy: 0.7025\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8287 - accuracy: 0.7168\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8041 - accuracy: 0.7240\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7761 - accuracy: 0.7322\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7605 - accuracy: 0.7360\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7457 - accuracy: 0.7390\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7247 - accuracy: 0.7440\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.775 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 3.0679 - accuracy: 0.1530\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1661 - accuracy: 0.2075\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9384 - accuracy: 0.2735\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8106 - accuracy: 0.3260\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7159 - accuracy: 0.3507\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6317 - accuracy: 0.3868\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5603 - accuracy: 0.4252\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4816 - accuracy: 0.4658\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4036 - accuracy: 0.5052\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3422 - accuracy: 0.5345\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2927 - accuracy: 0.5527\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2037 - accuracy: 0.5920\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1782 - accuracy: 0.6012\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1091 - accuracy: 0.6330\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0831 - accuracy: 0.6355\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0365 - accuracy: 0.6607\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9947 - accuracy: 0.6712\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9704 - accuracy: 0.6800\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9270 - accuracy: 0.6930\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9103 - accuracy: 0.6925\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.731 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.9777 - accuracy: 0.1120\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1624 - accuracy: 0.2062\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.0359 - accuracy: 0.2853\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9208 - accuracy: 0.3545\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.8196 - accuracy: 0.3910\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7140 - accuracy: 0.4268\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6236 - accuracy: 0.4430\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5110 - accuracy: 0.4757\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4203 - accuracy: 0.5063\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3370 - accuracy: 0.5355\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2586 - accuracy: 0.5698\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1893 - accuracy: 0.5915\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1307 - accuracy: 0.6130\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0819 - accuracy: 0.6363\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0439 - accuracy: 0.6425\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0103 - accuracy: 0.6518\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9933 - accuracy: 0.6578\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9406 - accuracy: 0.6622\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9165 - accuracy: 0.6710\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8896 - accuracy: 0.6693\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.689 total time=   3.9s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 3.2044 - accuracy: 0.1695\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.1606 - accuracy: 0.2060\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9188 - accuracy: 0.2940\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6986 - accuracy: 0.3795\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4491 - accuracy: 0.5052\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2185 - accuracy: 0.5972\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0457 - accuracy: 0.6442\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9356 - accuracy: 0.6685\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8652 - accuracy: 0.7007\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8206 - accuracy: 0.7025\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7618 - accuracy: 0.7243\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7359 - accuracy: 0.7380\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7143 - accuracy: 0.7412\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6780 - accuracy: 0.7550\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6564 - accuracy: 0.7610\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6401 - accuracy: 0.7673\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6275 - accuracy: 0.7785\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6119 - accuracy: 0.7782\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5982 - accuracy: 0.7900\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5952 - accuracy: 0.7872\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.785 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 2.1681 - accuracy: 0.2445\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6594 - accuracy: 0.4087\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3464 - accuracy: 0.5073\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1502 - accuracy: 0.5838\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0200 - accuracy: 0.6455\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9238 - accuracy: 0.6697\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8464 - accuracy: 0.7078\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7927 - accuracy: 0.7190\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7383 - accuracy: 0.7440\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7050 - accuracy: 0.7525\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6848 - accuracy: 0.7495\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6647 - accuracy: 0.7607\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6453 - accuracy: 0.7690\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6091 - accuracy: 0.7828\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5945 - accuracy: 0.7865\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5866 - accuracy: 0.7908\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5768 - accuracy: 0.7940\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5652 - accuracy: 0.7895\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5499 - accuracy: 0.8037\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5369 - accuracy: 0.8062\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.802 total time=   4.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 3.3867 - accuracy: 0.1182\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1190 - accuracy: 0.2305\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8849 - accuracy: 0.3383\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6991 - accuracy: 0.4135\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5355 - accuracy: 0.4762\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3781 - accuracy: 0.5422\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2744 - accuracy: 0.5698\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1958 - accuracy: 0.5960\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1092 - accuracy: 0.6100\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0194 - accuracy: 0.6453\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9683 - accuracy: 0.6645\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8967 - accuracy: 0.6870\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8529 - accuracy: 0.6998\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8097 - accuracy: 0.7045\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7688 - accuracy: 0.7180\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7483 - accuracy: 0.7237\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7235 - accuracy: 0.7347\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6936 - accuracy: 0.7477\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6741 - accuracy: 0.7510\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6632 - accuracy: 0.7555\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.760 total time=   4.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 2.3069 - accuracy: 0.2635\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5644 - accuracy: 0.4333\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2254 - accuracy: 0.5518\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0331 - accuracy: 0.6208\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8963 - accuracy: 0.6740\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8037 - accuracy: 0.7150\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7412 - accuracy: 0.7270\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7010 - accuracy: 0.7448\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6637 - accuracy: 0.7502\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6352 - accuracy: 0.7667\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6145 - accuracy: 0.7735\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5982 - accuracy: 0.7822\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5839 - accuracy: 0.7847\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5583 - accuracy: 0.7908\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.5396 - accuracy: 0.8010\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5240 - accuracy: 0.8105\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5225 - accuracy: 0.8083\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5139 - accuracy: 0.8102\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4985 - accuracy: 0.8165\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4932 - accuracy: 0.8175\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.802 total time=   4.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 3.1530 - accuracy: 0.1875\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.9374 - accuracy: 0.3710\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5982 - accuracy: 0.4798\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2748 - accuracy: 0.5602\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0665 - accuracy: 0.6120\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9729 - accuracy: 0.6302\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9045 - accuracy: 0.6495\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8543 - accuracy: 0.6697\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8093 - accuracy: 0.6923\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7800 - accuracy: 0.7040\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7392 - accuracy: 0.7188\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7207 - accuracy: 0.7237\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6979 - accuracy: 0.7320\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6840 - accuracy: 0.7393\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6635 - accuracy: 0.7560\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6527 - accuracy: 0.7582\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6318 - accuracy: 0.7570\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6188 - accuracy: 0.7673\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6024 - accuracy: 0.7765\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5885 - accuracy: 0.7805\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.775 total time=   4.6s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 2.0796 - accuracy: 0.2812\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4590 - accuracy: 0.4725\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1170 - accuracy: 0.6175\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9234 - accuracy: 0.6735\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8240 - accuracy: 0.6960\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7671 - accuracy: 0.7222\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6928 - accuracy: 0.7483\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6522 - accuracy: 0.7540\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6268 - accuracy: 0.7675\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6021 - accuracy: 0.7820\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5818 - accuracy: 0.7937\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5705 - accuracy: 0.7943\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5603 - accuracy: 0.7945\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5380 - accuracy: 0.8020\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5276 - accuracy: 0.8058\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5186 - accuracy: 0.8135\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5022 - accuracy: 0.8213\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4907 - accuracy: 0.8223\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4875 - accuracy: 0.8220\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5023 - accuracy: 0.8142\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.792 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 3.1531 - accuracy: 0.1173\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9917 - accuracy: 0.2580\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6704 - accuracy: 0.3780\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4365 - accuracy: 0.4807\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2694 - accuracy: 0.5500\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1384 - accuracy: 0.5878\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0350 - accuracy: 0.6283\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9525 - accuracy: 0.6518\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9090 - accuracy: 0.6755\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8674 - accuracy: 0.6787\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8144 - accuracy: 0.7028\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7714 - accuracy: 0.7170\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7593 - accuracy: 0.7207\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7252 - accuracy: 0.7333\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7133 - accuracy: 0.7343\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6887 - accuracy: 0.7455\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6632 - accuracy: 0.7607\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6421 - accuracy: 0.7670\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6336 - accuracy: 0.7695\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6201 - accuracy: 0.7722\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.783 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.6829 - accuracy: 0.1528\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0048 - accuracy: 0.2627\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7851 - accuracy: 0.3695\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6402 - accuracy: 0.4363\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5249 - accuracy: 0.4697\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4020 - accuracy: 0.5067\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2907 - accuracy: 0.5627\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1583 - accuracy: 0.6310\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0600 - accuracy: 0.6658\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9668 - accuracy: 0.6895\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9057 - accuracy: 0.7040\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8662 - accuracy: 0.7178\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8308 - accuracy: 0.7258\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7953 - accuracy: 0.7310\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7724 - accuracy: 0.7430\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7378 - accuracy: 0.7452\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7157 - accuracy: 0.7523\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6941 - accuracy: 0.7582\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6727 - accuracy: 0.7740\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6577 - accuracy: 0.7832\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.788 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.1810 - accuracy: 0.1157\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.9454 - accuracy: 0.2727\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6310 - accuracy: 0.4042\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4384 - accuracy: 0.4785\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2800 - accuracy: 0.5483\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1709 - accuracy: 0.5842\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0826 - accuracy: 0.6100\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9987 - accuracy: 0.6482\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9553 - accuracy: 0.6618\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8993 - accuracy: 0.6840\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8687 - accuracy: 0.6883\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8378 - accuracy: 0.6940\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8167 - accuracy: 0.7063\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7872 - accuracy: 0.7135\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7566 - accuracy: 0.7278\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7362 - accuracy: 0.7377\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7166 - accuracy: 0.7450\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6954 - accuracy: 0.7490\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6818 - accuracy: 0.7508\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6702 - accuracy: 0.7505\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.782 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.8788 - accuracy: 0.2132\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7774 - accuracy: 0.3555\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4636 - accuracy: 0.4933\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2301 - accuracy: 0.5950\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0543 - accuracy: 0.6505\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9450 - accuracy: 0.6867\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8706 - accuracy: 0.7065\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7854 - accuracy: 0.7297\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7576 - accuracy: 0.7410\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7183 - accuracy: 0.7480\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6810 - accuracy: 0.7640\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6460 - accuracy: 0.7742\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6303 - accuracy: 0.7735\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6024 - accuracy: 0.7843\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5699 - accuracy: 0.7940\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5613 - accuracy: 0.7977\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5391 - accuracy: 0.8065\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5262 - accuracy: 0.8142\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5335 - accuracy: 0.8083\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5062 - accuracy: 0.8173\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.789 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.1322 - accuracy: 0.1528\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8547 - accuracy: 0.3288\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6041 - accuracy: 0.4380\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3855 - accuracy: 0.4980\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1860 - accuracy: 0.5530\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0584 - accuracy: 0.6087\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9541 - accuracy: 0.6570\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8645 - accuracy: 0.6927\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7866 - accuracy: 0.7175\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7478 - accuracy: 0.7345\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7146 - accuracy: 0.7410\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6799 - accuracy: 0.7548\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6671 - accuracy: 0.7642\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6424 - accuracy: 0.7625\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6285 - accuracy: 0.7837\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6109 - accuracy: 0.7810\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6071 - accuracy: 0.7883\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5819 - accuracy: 0.7937\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5718 - accuracy: 0.7950\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5602 - accuracy: 0.7977\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.800 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.9584 - accuracy: 0.1665\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7861 - accuracy: 0.3627\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5089 - accuracy: 0.4633\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2681 - accuracy: 0.5740\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0646 - accuracy: 0.6507\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9364 - accuracy: 0.6877\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8540 - accuracy: 0.7088\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7788 - accuracy: 0.7320\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7282 - accuracy: 0.7475\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6907 - accuracy: 0.7530\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6582 - accuracy: 0.7650\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6244 - accuracy: 0.7805\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6087 - accuracy: 0.7820\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5848 - accuracy: 0.7897\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5669 - accuracy: 0.8008\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5575 - accuracy: 0.8005\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5482 - accuracy: 0.8015\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5318 - accuracy: 0.8105\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5091 - accuracy: 0.8123\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5134 - accuracy: 0.8142\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.789 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 2.2308 - accuracy: 0.3043\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.3176 - accuracy: 0.5460\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9889 - accuracy: 0.6453\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8110 - accuracy: 0.7100\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7316 - accuracy: 0.7320\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6510 - accuracy: 0.7620\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6176 - accuracy: 0.7720\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5857 - accuracy: 0.7883\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5623 - accuracy: 0.7912\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5418 - accuracy: 0.7985\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5214 - accuracy: 0.8052\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5013 - accuracy: 0.8133\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4883 - accuracy: 0.8180\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4783 - accuracy: 0.8285\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4599 - accuracy: 0.8250\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4507 - accuracy: 0.8322\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4449 - accuracy: 0.8350\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4315 - accuracy: 0.8435\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4268 - accuracy: 0.8445\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4187 - accuracy: 0.8447\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.807 total time=   4.9s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 34ms/step - loss: 2.4434 - accuracy: 0.2442\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.4973 - accuracy: 0.5315\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 1.1481 - accuracy: 0.6212\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9415 - accuracy: 0.6798\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.8339 - accuracy: 0.7113\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7462 - accuracy: 0.7343\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6995 - accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6498 - accuracy: 0.7665\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6174 - accuracy: 0.7757\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5870 - accuracy: 0.7905\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5735 - accuracy: 0.7972\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5512 - accuracy: 0.8023\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5332 - accuracy: 0.8110\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5141 - accuracy: 0.8167\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4917 - accuracy: 0.8232\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4868 - accuracy: 0.8253\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4814 - accuracy: 0.8248\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4568 - accuracy: 0.8328\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4494 - accuracy: 0.8363\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4366 - accuracy: 0.8413\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.817 total time=   5.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 2.9703 - accuracy: 0.1678\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.7376 - accuracy: 0.3925\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.3412 - accuracy: 0.5353\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.0602 - accuracy: 0.6115\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9101 - accuracy: 0.6710\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7976 - accuracy: 0.7095\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7355 - accuracy: 0.7375\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6835 - accuracy: 0.7492\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6412 - accuracy: 0.7635\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6129 - accuracy: 0.7692\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5851 - accuracy: 0.7830\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5707 - accuracy: 0.7908\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5499 - accuracy: 0.7895\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5307 - accuracy: 0.8070\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5051 - accuracy: 0.8073\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4952 - accuracy: 0.8160\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4851 - accuracy: 0.8163\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4755 - accuracy: 0.8242\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4648 - accuracy: 0.8275\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4479 - accuracy: 0.8295\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.804 total time=   4.9s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.8186 - accuracy: 0.1660\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8120 - accuracy: 0.3345\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6211 - accuracy: 0.4215\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5170 - accuracy: 0.4685\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4618 - accuracy: 0.4830\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4134 - accuracy: 0.5010\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3560 - accuracy: 0.5483\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3250 - accuracy: 0.5555\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2823 - accuracy: 0.5750\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2501 - accuracy: 0.5773\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2262 - accuracy: 0.5955\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1899 - accuracy: 0.6037\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1637 - accuracy: 0.6227\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1529 - accuracy: 0.6292\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1165 - accuracy: 0.6435\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0846 - accuracy: 0.6580\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0706 - accuracy: 0.6618\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0293 - accuracy: 0.6615\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9657 - accuracy: 0.6743\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9077 - accuracy: 0.6977\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.713 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.6241 - accuracy: 0.1395\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0684 - accuracy: 0.2298\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8061 - accuracy: 0.2873\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6349 - accuracy: 0.3778\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5215 - accuracy: 0.4728\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4093 - accuracy: 0.5088\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2927 - accuracy: 0.5480\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1730 - accuracy: 0.6058\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0884 - accuracy: 0.6423\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9698 - accuracy: 0.6795\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9083 - accuracy: 0.7007\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8513 - accuracy: 0.7132\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8072 - accuracy: 0.7160\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7710 - accuracy: 0.7260\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7435 - accuracy: 0.7327\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7146 - accuracy: 0.7430\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6828 - accuracy: 0.7533\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6616 - accuracy: 0.7653\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6392 - accuracy: 0.7710\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6369 - accuracy: 0.7703\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.794 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 2.6669 - accuracy: 0.2062\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7190 - accuracy: 0.3970\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4760 - accuracy: 0.4810\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3239 - accuracy: 0.5290\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2036 - accuracy: 0.5705\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1075 - accuracy: 0.5893\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0419 - accuracy: 0.6288\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9544 - accuracy: 0.6653\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8871 - accuracy: 0.6880\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8398 - accuracy: 0.6967\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7944 - accuracy: 0.7103\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7675 - accuracy: 0.7172\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7284 - accuracy: 0.7347\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7246 - accuracy: 0.7390\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6841 - accuracy: 0.7433\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6763 - accuracy: 0.7548\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6603 - accuracy: 0.7640\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6302 - accuracy: 0.7722\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6072 - accuracy: 0.7780\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5967 - accuracy: 0.7828\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.785 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.1414 - accuracy: 0.1713\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6516 - accuracy: 0.4085\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2909 - accuracy: 0.5497\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0484 - accuracy: 0.6413\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9046 - accuracy: 0.6877\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8157 - accuracy: 0.7050\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7548 - accuracy: 0.7278\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7125 - accuracy: 0.7508\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6713 - accuracy: 0.7653\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6408 - accuracy: 0.7645\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6104 - accuracy: 0.7855\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5866 - accuracy: 0.7958\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5616 - accuracy: 0.7990\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5464 - accuracy: 0.7968\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5359 - accuracy: 0.8117\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5318 - accuracy: 0.8060\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5005 - accuracy: 0.8202\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4867 - accuracy: 0.8248\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4662 - accuracy: 0.8363\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4767 - accuracy: 0.8270\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.817 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.7997 - accuracy: 0.2288\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6509 - accuracy: 0.4588\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3326 - accuracy: 0.5635\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1440 - accuracy: 0.6185\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0242 - accuracy: 0.6532\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8933 - accuracy: 0.6888\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7969 - accuracy: 0.7153\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7158 - accuracy: 0.7475\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6697 - accuracy: 0.7558\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6341 - accuracy: 0.7700\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6035 - accuracy: 0.7840\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5614 - accuracy: 0.7962\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5400 - accuracy: 0.8152\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5303 - accuracy: 0.8087\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4964 - accuracy: 0.8155\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4916 - accuracy: 0.8225\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4854 - accuracy: 0.8253\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4645 - accuracy: 0.8385\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4530 - accuracy: 0.8428\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4394 - accuracy: 0.8487\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.807 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.4540 - accuracy: 0.1885\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6551 - accuracy: 0.4265\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2836 - accuracy: 0.5520\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1203 - accuracy: 0.6060\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9734 - accuracy: 0.6603\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8894 - accuracy: 0.6980\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8374 - accuracy: 0.7175\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7725 - accuracy: 0.7343\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7339 - accuracy: 0.7502\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6899 - accuracy: 0.7617\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6677 - accuracy: 0.7722\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6440 - accuracy: 0.7732\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6128 - accuracy: 0.7835\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5919 - accuracy: 0.7943\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5767 - accuracy: 0.7928\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5538 - accuracy: 0.8073\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5293 - accuracy: 0.8083\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5253 - accuracy: 0.8130\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4979 - accuracy: 0.8285\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4807 - accuracy: 0.8338\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.806 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.6774 - accuracy: 0.2335\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2774 - accuracy: 0.5785\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9512 - accuracy: 0.6747\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8017 - accuracy: 0.7078\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7253 - accuracy: 0.7427\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6568 - accuracy: 0.7635\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6123 - accuracy: 0.7775\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5773 - accuracy: 0.7935\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5399 - accuracy: 0.8048\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5110 - accuracy: 0.8190\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4938 - accuracy: 0.8188\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4788 - accuracy: 0.8310\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4606 - accuracy: 0.8347\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4433 - accuracy: 0.8422\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4295 - accuracy: 0.8457\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4059 - accuracy: 0.8508\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3988 - accuracy: 0.8535\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3953 - accuracy: 0.8550\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3714 - accuracy: 0.8692\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3586 - accuracy: 0.8660\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.817 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.5378 - accuracy: 0.2215\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2922 - accuracy: 0.5468\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9373 - accuracy: 0.6695\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7990 - accuracy: 0.7168\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7323 - accuracy: 0.7340\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6574 - accuracy: 0.7670\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6019 - accuracy: 0.7822\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5657 - accuracy: 0.8002\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5407 - accuracy: 0.8062\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5110 - accuracy: 0.8210\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4857 - accuracy: 0.8245\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4661 - accuracy: 0.8328\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4466 - accuracy: 0.8400\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4162 - accuracy: 0.8597\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4066 - accuracy: 0.8562\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3887 - accuracy: 0.8635\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3866 - accuracy: 0.8597\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3661 - accuracy: 0.8673\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3544 - accuracy: 0.8715\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 27ms/step - loss: 0.3371 - accuracy: 0.8817\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.822 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.8946 - accuracy: 0.2533\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3450 - accuracy: 0.5370\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0310 - accuracy: 0.6488\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8298 - accuracy: 0.7143\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7128 - accuracy: 0.7533\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6689 - accuracy: 0.7653\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6055 - accuracy: 0.7832\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5845 - accuracy: 0.7930\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5383 - accuracy: 0.8058\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5241 - accuracy: 0.8210\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4808 - accuracy: 0.8275\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4728 - accuracy: 0.8340\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4506 - accuracy: 0.8422\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4362 - accuracy: 0.8438\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4301 - accuracy: 0.8420\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4182 - accuracy: 0.8550\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3972 - accuracy: 0.8508\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3897 - accuracy: 0.8577\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3816 - accuracy: 0.8618\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3743 - accuracy: 0.8622\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.825 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 2.4925 - accuracy: 0.1112\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0744 - accuracy: 0.1945\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9033 - accuracy: 0.2515\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7586 - accuracy: 0.3275\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6411 - accuracy: 0.3835\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5327 - accuracy: 0.4202\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4153 - accuracy: 0.4605\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2875 - accuracy: 0.5132\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1908 - accuracy: 0.5282\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1001 - accuracy: 0.5545\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0214 - accuracy: 0.6008\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9530 - accuracy: 0.6550\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8914 - accuracy: 0.6798\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8419 - accuracy: 0.7013\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7813 - accuracy: 0.7160\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7568 - accuracy: 0.7290\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7376 - accuracy: 0.7303\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6946 - accuracy: 0.7470\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.6903 - accuracy: 0.7555\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6725 - accuracy: 0.7467\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.772 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 3.0142 - accuracy: 0.0865\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.1998 - accuracy: 0.1285\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0251 - accuracy: 0.1895\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8832 - accuracy: 0.2853\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7401 - accuracy: 0.3705\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6254 - accuracy: 0.4475\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5223 - accuracy: 0.4880\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4302 - accuracy: 0.5328\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3354 - accuracy: 0.5600\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2523 - accuracy: 0.5972\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1849 - accuracy: 0.6102\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1485 - accuracy: 0.6160\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1146 - accuracy: 0.6165\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0652 - accuracy: 0.6355\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0337 - accuracy: 0.6455\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9987 - accuracy: 0.6503\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9682 - accuracy: 0.6578\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9310 - accuracy: 0.6720\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8668 - accuracy: 0.7013\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8104 - accuracy: 0.7303\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.747 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 2.5145 - accuracy: 0.1293\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1282 - accuracy: 0.1922\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9448 - accuracy: 0.2955\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7967 - accuracy: 0.3512\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6827 - accuracy: 0.3932\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5896 - accuracy: 0.4168\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5076 - accuracy: 0.4440\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4343 - accuracy: 0.4725\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3692 - accuracy: 0.5130\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2931 - accuracy: 0.5615\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2398 - accuracy: 0.5855\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1837 - accuracy: 0.5947\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1138 - accuracy: 0.6112\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0756 - accuracy: 0.6175\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0417 - accuracy: 0.6215\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0073 - accuracy: 0.6350\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9540 - accuracy: 0.6478\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9387 - accuracy: 0.6532\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9270 - accuracy: 0.6522\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8802 - accuracy: 0.6630\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.665 total time=   4.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.9006 - accuracy: 0.1570\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9060 - accuracy: 0.3105\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6047 - accuracy: 0.4400\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3877 - accuracy: 0.5310\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2354 - accuracy: 0.5698\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1121 - accuracy: 0.6100\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0062 - accuracy: 0.6525\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9542 - accuracy: 0.6665\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9087 - accuracy: 0.6800\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8418 - accuracy: 0.7097\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8145 - accuracy: 0.7130\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7745 - accuracy: 0.7285\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7475 - accuracy: 0.7402\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7213 - accuracy: 0.7452\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6919 - accuracy: 0.7582\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6808 - accuracy: 0.7615\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6497 - accuracy: 0.7722\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6352 - accuracy: 0.7707\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6184 - accuracy: 0.7822\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6023 - accuracy: 0.7860\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.773 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.8104 - accuracy: 0.1273\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0069 - accuracy: 0.2510\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7045 - accuracy: 0.4185\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4432 - accuracy: 0.4882\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2469 - accuracy: 0.5433\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1271 - accuracy: 0.5935\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0212 - accuracy: 0.6385\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9424 - accuracy: 0.6620\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8872 - accuracy: 0.6780\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8288 - accuracy: 0.6985\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7974 - accuracy: 0.7065\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7712 - accuracy: 0.7170\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7450 - accuracy: 0.7287\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7115 - accuracy: 0.7425\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7035 - accuracy: 0.7515\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6747 - accuracy: 0.7613\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6523 - accuracy: 0.7602\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6448 - accuracy: 0.7685\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6417 - accuracy: 0.7735\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6277 - accuracy: 0.7757\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.784 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 3.9146 - accuracy: 0.1103\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1061 - accuracy: 0.2065\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8061 - accuracy: 0.3660\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5163 - accuracy: 0.4710\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3143 - accuracy: 0.5260\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1936 - accuracy: 0.5713\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0731 - accuracy: 0.6125\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9934 - accuracy: 0.6490\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9497 - accuracy: 0.6522\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8909 - accuracy: 0.6865\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8452 - accuracy: 0.6960\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8030 - accuracy: 0.7105\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7783 - accuracy: 0.7215\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7480 - accuracy: 0.7250\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7163 - accuracy: 0.7480\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6980 - accuracy: 0.7395\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6815 - accuracy: 0.7502\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6579 - accuracy: 0.7530\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6457 - accuracy: 0.7613\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.6171 - accuracy: 0.7705\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.763 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 2.2697 - accuracy: 0.2175\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4557 - accuracy: 0.5017\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0308 - accuracy: 0.6043\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8713 - accuracy: 0.6710\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7910 - accuracy: 0.7017\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7330 - accuracy: 0.7197\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6922 - accuracy: 0.7410\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6707 - accuracy: 0.7480\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6296 - accuracy: 0.7628\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6246 - accuracy: 0.7602\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5927 - accuracy: 0.7797\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5837 - accuracy: 0.7830\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5725 - accuracy: 0.7850\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5555 - accuracy: 0.7912\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5382 - accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5295 - accuracy: 0.8058\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5286 - accuracy: 0.8062\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5198 - accuracy: 0.8085\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4995 - accuracy: 0.8215\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4918 - accuracy: 0.8192\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.776 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.5531 - accuracy: 0.1630\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7497 - accuracy: 0.3905\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2872 - accuracy: 0.5500\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9968 - accuracy: 0.6453\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8572 - accuracy: 0.6915\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7719 - accuracy: 0.7160\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7214 - accuracy: 0.7300\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6929 - accuracy: 0.7513\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6581 - accuracy: 0.7598\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6303 - accuracy: 0.7667\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6149 - accuracy: 0.7692\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5959 - accuracy: 0.7822\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5854 - accuracy: 0.7857\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5549 - accuracy: 0.7935\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5536 - accuracy: 0.7972\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5338 - accuracy: 0.7985\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5207 - accuracy: 0.8110\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5104 - accuracy: 0.8127\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5000 - accuracy: 0.8175\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4888 - accuracy: 0.8220\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.802 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.2259 - accuracy: 0.2480\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6150 - accuracy: 0.4378\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2953 - accuracy: 0.5205\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0844 - accuracy: 0.5860\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8982 - accuracy: 0.6798\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7658 - accuracy: 0.7230\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6986 - accuracy: 0.7487\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6581 - accuracy: 0.7538\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6310 - accuracy: 0.7673\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6123 - accuracy: 0.7745\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5933 - accuracy: 0.7790\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5615 - accuracy: 0.7872\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5348 - accuracy: 0.8027\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5273 - accuracy: 0.7977\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5073 - accuracy: 0.8117\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4974 - accuracy: 0.8148\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4944 - accuracy: 0.8145\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4716 - accuracy: 0.8310\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4686 - accuracy: 0.8305\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4645 - accuracy: 0.8278\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.798 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 3.0729 - accuracy: 0.1123\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2108 - accuracy: 0.1963\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0206 - accuracy: 0.2612\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8475 - accuracy: 0.3110\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1.6868 - accuracy: 0.3570\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5353 - accuracy: 0.4120\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4162 - accuracy: 0.4647\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2906 - accuracy: 0.5092\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1841 - accuracy: 0.5372\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0800 - accuracy: 0.6093\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9627 - accuracy: 0.6505\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9035 - accuracy: 0.6665\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8397 - accuracy: 0.6915\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8142 - accuracy: 0.7015\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7904 - accuracy: 0.7107\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7741 - accuracy: 0.7155\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7357 - accuracy: 0.7278\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7301 - accuracy: 0.7295\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7017 - accuracy: 0.7458\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7053 - accuracy: 0.7383\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.749 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.7863 - accuracy: 0.0983\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0797 - accuracy: 0.1922\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8862 - accuracy: 0.2937\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6810 - accuracy: 0.3848\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5102 - accuracy: 0.4720\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3755 - accuracy: 0.5403\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2829 - accuracy: 0.5748\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1473 - accuracy: 0.6200\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0726 - accuracy: 0.6465\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9988 - accuracy: 0.6665\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9507 - accuracy: 0.6810\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9207 - accuracy: 0.6895\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8770 - accuracy: 0.7028\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8290 - accuracy: 0.7240\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7785 - accuracy: 0.7412\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7660 - accuracy: 0.7408\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7306 - accuracy: 0.7467\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7266 - accuracy: 0.7515\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6788 - accuracy: 0.7615\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6754 - accuracy: 0.7690\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.795 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 5.2871 - accuracy: 0.1215\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.5035 - accuracy: 0.1495\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.1127 - accuracy: 0.1838\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.9306 - accuracy: 0.2630\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8153 - accuracy: 0.3410\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7030 - accuracy: 0.4190\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6003 - accuracy: 0.4620\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4706 - accuracy: 0.5157\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3763 - accuracy: 0.5497\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2782 - accuracy: 0.5890\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2020 - accuracy: 0.6112\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1237 - accuracy: 0.6423\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0763 - accuracy: 0.6565\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0197 - accuracy: 0.6793\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9429 - accuracy: 0.7003\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9302 - accuracy: 0.7023\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8725 - accuracy: 0.7215\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8490 - accuracy: 0.7253\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8308 - accuracy: 0.7260\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7791 - accuracy: 0.7383\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.755 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 3.8096 - accuracy: 0.0950\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.1200 - accuracy: 0.2342\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.8084 - accuracy: 0.3338\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5751 - accuracy: 0.4160\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3613 - accuracy: 0.5242\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1932 - accuracy: 0.6060\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0264 - accuracy: 0.6565\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9248 - accuracy: 0.6805\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8593 - accuracy: 0.6930\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7941 - accuracy: 0.7210\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7342 - accuracy: 0.7340\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6964 - accuracy: 0.7505\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6719 - accuracy: 0.7538\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6463 - accuracy: 0.7607\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6162 - accuracy: 0.7715\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5987 - accuracy: 0.7800\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5953 - accuracy: 0.7815\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5768 - accuracy: 0.7880\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5603 - accuracy: 0.7897\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5462 - accuracy: 0.7950\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.788 total time=   4.6s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.8785 - accuracy: 0.1713\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0583 - accuracy: 0.3070\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7265 - accuracy: 0.3963\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5101 - accuracy: 0.5027\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3161 - accuracy: 0.5815\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.1500 - accuracy: 0.6323\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0093 - accuracy: 0.6710\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9165 - accuracy: 0.6950\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8403 - accuracy: 0.7107\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7825 - accuracy: 0.7303\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7417 - accuracy: 0.7398\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6972 - accuracy: 0.7570\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6895 - accuracy: 0.7560\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6561 - accuracy: 0.7710\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6320 - accuracy: 0.7763\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6136 - accuracy: 0.7805\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5924 - accuracy: 0.7857\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5724 - accuracy: 0.7935\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5691 - accuracy: 0.7937\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5547 - accuracy: 0.8000\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.802 total time=   4.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.9429 - accuracy: 0.1893\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.7868 - accuracy: 0.3350\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4547 - accuracy: 0.4725\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2101 - accuracy: 0.5850\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0525 - accuracy: 0.6323\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9239 - accuracy: 0.6773\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8337 - accuracy: 0.7023\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7803 - accuracy: 0.7210\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7201 - accuracy: 0.7458\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6883 - accuracy: 0.7505\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6607 - accuracy: 0.7600\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6328 - accuracy: 0.7740\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6079 - accuracy: 0.7805\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5830 - accuracy: 0.7850\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5666 - accuracy: 0.7975\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5516 - accuracy: 0.8023\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5369 - accuracy: 0.8077\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5284 - accuracy: 0.8075\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5081 - accuracy: 0.8152\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5064 - accuracy: 0.8120\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.795 total time=   4.6s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 34ms/step - loss: 2.2479 - accuracy: 0.2892\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.3622 - accuracy: 0.5465\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1.0262 - accuracy: 0.6633\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.8611 - accuracy: 0.6963\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7694 - accuracy: 0.7190\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6898 - accuracy: 0.7410\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6311 - accuracy: 0.7670\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5949 - accuracy: 0.7747\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5664 - accuracy: 0.7880\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5405 - accuracy: 0.7908\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5226 - accuracy: 0.8092\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4924 - accuracy: 0.8115\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4775 - accuracy: 0.8217\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4584 - accuracy: 0.8303\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4484 - accuracy: 0.8307\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4288 - accuracy: 0.8440\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4256 - accuracy: 0.8363\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4131 - accuracy: 0.8482\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3927 - accuracy: 0.8522\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.3903 - accuracy: 0.8575\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.798 total time=   5.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 34ms/step - loss: 3.9533 - accuracy: 0.1437\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.9615 - accuracy: 0.2850\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.5722 - accuracy: 0.4647\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.2548 - accuracy: 0.5763\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0414 - accuracy: 0.6360\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.9226 - accuracy: 0.6823\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.8262 - accuracy: 0.7060\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7646 - accuracy: 0.7293\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7052 - accuracy: 0.7462\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6662 - accuracy: 0.7555\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6283 - accuracy: 0.7660\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6043 - accuracy: 0.7810\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5818 - accuracy: 0.7868\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5614 - accuracy: 0.7928\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5394 - accuracy: 0.7997\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5215 - accuracy: 0.8083\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5073 - accuracy: 0.8170\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4950 - accuracy: 0.8232\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4885 - accuracy: 0.8207\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4708 - accuracy: 0.8310\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.807 total time=   5.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 34ms/step - loss: 2.7593 - accuracy: 0.1965\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.5817 - accuracy: 0.4593\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.1757 - accuracy: 0.6070\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9592 - accuracy: 0.6595\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8469 - accuracy: 0.6975\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7669 - accuracy: 0.7243\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7007 - accuracy: 0.7460\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6508 - accuracy: 0.7642\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6149 - accuracy: 0.7780\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5713 - accuracy: 0.7922\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5472 - accuracy: 0.8008\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5312 - accuracy: 0.8052\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5132 - accuracy: 0.8105\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4836 - accuracy: 0.8242\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4774 - accuracy: 0.8298\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4629 - accuracy: 0.8345\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4510 - accuracy: 0.8328\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4391 - accuracy: 0.8380\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4199 - accuracy: 0.8445\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4157 - accuracy: 0.8450\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.812 total time=   5.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 2.3101 - accuracy: 0.1828\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7805 - accuracy: 0.3265\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5798 - accuracy: 0.4185\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3827 - accuracy: 0.5055\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2384 - accuracy: 0.5663\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1312 - accuracy: 0.6102\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0490 - accuracy: 0.6440\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9581 - accuracy: 0.6760\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9034 - accuracy: 0.6995\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8479 - accuracy: 0.7225\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8127 - accuracy: 0.7377\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7678 - accuracy: 0.7483\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7353 - accuracy: 0.7665\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6809 - accuracy: 0.7803\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6672 - accuracy: 0.7878\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6282 - accuracy: 0.7968\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6142 - accuracy: 0.8005\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5973 - accuracy: 0.8037\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5793 - accuracy: 0.8130\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.5500 - accuracy: 0.8188\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.790 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.5606 - accuracy: 0.1450\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9377 - accuracy: 0.2585\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6994 - accuracy: 0.3372\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5337 - accuracy: 0.4235\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3684 - accuracy: 0.5280\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2215 - accuracy: 0.5918\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1055 - accuracy: 0.6375\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0061 - accuracy: 0.6737\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9576 - accuracy: 0.6833\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8900 - accuracy: 0.7097\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8441 - accuracy: 0.7172\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8024 - accuracy: 0.7390\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7555 - accuracy: 0.7450\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7269 - accuracy: 0.7638\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6912 - accuracy: 0.7710\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6595 - accuracy: 0.7797\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6465 - accuracy: 0.7905\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6150 - accuracy: 0.7905\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5803 - accuracy: 0.8027\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5674 - accuracy: 0.8102\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.797 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.9731 - accuracy: 0.2192\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9089 - accuracy: 0.3543\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6650 - accuracy: 0.4597\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5476 - accuracy: 0.4775\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4706 - accuracy: 0.4900\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3674 - accuracy: 0.5278\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2922 - accuracy: 0.5415\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2163 - accuracy: 0.5695\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1715 - accuracy: 0.5945\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1271 - accuracy: 0.6168\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0630 - accuracy: 0.6220\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0115 - accuracy: 0.6378\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9489 - accuracy: 0.6582\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8984 - accuracy: 0.6752\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8281 - accuracy: 0.7000\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7932 - accuracy: 0.7308\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7377 - accuracy: 0.7530\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7029 - accuracy: 0.7675\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6608 - accuracy: 0.7750\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6311 - accuracy: 0.7840\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.792 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.9981 - accuracy: 0.1947\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5481 - accuracy: 0.4480\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1781 - accuracy: 0.5905\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0123 - accuracy: 0.6490\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8948 - accuracy: 0.6827\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8233 - accuracy: 0.7040\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7602 - accuracy: 0.7222\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7196 - accuracy: 0.7423\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6816 - accuracy: 0.7542\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6294 - accuracy: 0.7705\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6127 - accuracy: 0.7832\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5916 - accuracy: 0.7872\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5590 - accuracy: 0.7912\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5435 - accuracy: 0.8012\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5213 - accuracy: 0.8092\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5112 - accuracy: 0.8175\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4769 - accuracy: 0.8257\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4632 - accuracy: 0.8310\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4560 - accuracy: 0.8347\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4439 - accuracy: 0.8345\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.815 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.8243 - accuracy: 0.2460\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5715 - accuracy: 0.4543\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2390 - accuracy: 0.5825\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0185 - accuracy: 0.6490\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8934 - accuracy: 0.6842\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8076 - accuracy: 0.7157\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7590 - accuracy: 0.7358\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6946 - accuracy: 0.7617\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6713 - accuracy: 0.7707\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6251 - accuracy: 0.7780\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6105 - accuracy: 0.7857\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5791 - accuracy: 0.8015\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5537 - accuracy: 0.8110\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5430 - accuracy: 0.8090\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5275 - accuracy: 0.8152\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5150 - accuracy: 0.8142\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4970 - accuracy: 0.8215\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4895 - accuracy: 0.8253\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4877 - accuracy: 0.8290\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4549 - accuracy: 0.8407\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.805 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.1238 - accuracy: 0.2083\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7835 - accuracy: 0.4110\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4591 - accuracy: 0.5312\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1818 - accuracy: 0.6357\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9932 - accuracy: 0.6762\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8749 - accuracy: 0.7000\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7982 - accuracy: 0.7308\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7442 - accuracy: 0.7368\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7002 - accuracy: 0.7660\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6611 - accuracy: 0.7673\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6271 - accuracy: 0.7815\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5985 - accuracy: 0.7870\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5753 - accuracy: 0.7972\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5453 - accuracy: 0.8110\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5343 - accuracy: 0.8117\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5048 - accuracy: 0.8232\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4920 - accuracy: 0.8255\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4912 - accuracy: 0.8313\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4695 - accuracy: 0.8335\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4574 - accuracy: 0.8415\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.809 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.2676 - accuracy: 0.2985\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2062 - accuracy: 0.5825\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8969 - accuracy: 0.6855\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7487 - accuracy: 0.7390\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6747 - accuracy: 0.7598\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6047 - accuracy: 0.7810\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5633 - accuracy: 0.7920\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5187 - accuracy: 0.8125\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4983 - accuracy: 0.8210\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4705 - accuracy: 0.8315\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4475 - accuracy: 0.8393\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4302 - accuracy: 0.8515\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4179 - accuracy: 0.8440\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3912 - accuracy: 0.8610\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3751 - accuracy: 0.8625\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3557 - accuracy: 0.8727\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3563 - accuracy: 0.8692\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3347 - accuracy: 0.8783\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3240 - accuracy: 0.8832\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3118 - accuracy: 0.8875\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.809 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.8472 - accuracy: 0.2177\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4843 - accuracy: 0.4950\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0948 - accuracy: 0.6340\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8795 - accuracy: 0.6995\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7532 - accuracy: 0.7333\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6675 - accuracy: 0.7625\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6302 - accuracy: 0.7757\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5858 - accuracy: 0.7905\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5511 - accuracy: 0.8005\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5115 - accuracy: 0.8127\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4972 - accuracy: 0.8255\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4785 - accuracy: 0.8285\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4581 - accuracy: 0.8360\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4296 - accuracy: 0.8462\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4184 - accuracy: 0.8480\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4086 - accuracy: 0.8497\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3959 - accuracy: 0.8533\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3753 - accuracy: 0.8595\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3665 - accuracy: 0.8668\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3588 - accuracy: 0.8687\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.821 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 2.7654 - accuracy: 0.2595\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4150 - accuracy: 0.5038\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0483 - accuracy: 0.6308\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8371 - accuracy: 0.7110\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7143 - accuracy: 0.7487\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6382 - accuracy: 0.7757\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5794 - accuracy: 0.7908\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5545 - accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5173 - accuracy: 0.8110\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5032 - accuracy: 0.8133\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4752 - accuracy: 0.8225\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4495 - accuracy: 0.8353\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4245 - accuracy: 0.8407\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4153 - accuracy: 0.8422\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4020 - accuracy: 0.8493\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3908 - accuracy: 0.8580\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3645 - accuracy: 0.8650\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3567 - accuracy: 0.8700\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3479 - accuracy: 0.8735\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3341 - accuracy: 0.8763\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.1, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.818 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 4.8674 - accuracy: 0.1273\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.4597 - accuracy: 0.2212\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0455 - accuracy: 0.2875\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9101 - accuracy: 0.3225\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7976 - accuracy: 0.3623\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6963 - accuracy: 0.4017\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5761 - accuracy: 0.4355\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4897 - accuracy: 0.4793\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4198 - accuracy: 0.4997\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3529 - accuracy: 0.5263\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2734 - accuracy: 0.5577\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2347 - accuracy: 0.5707\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1501 - accuracy: 0.6045\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1197 - accuracy: 0.6235\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0847 - accuracy: 0.6332\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0344 - accuracy: 0.6557\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9881 - accuracy: 0.6668\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9726 - accuracy: 0.6715\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9606 - accuracy: 0.6760\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9567 - accuracy: 0.6773\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.757 total time=   3.9s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 3.5899 - accuracy: 0.1340\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2651 - accuracy: 0.1880\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0479 - accuracy: 0.2345\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9328 - accuracy: 0.2880\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8269 - accuracy: 0.3230\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7222 - accuracy: 0.3627\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6515 - accuracy: 0.3965\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5784 - accuracy: 0.4305\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5150 - accuracy: 0.4618\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4536 - accuracy: 0.4832\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4063 - accuracy: 0.5125\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3479 - accuracy: 0.5315\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2950 - accuracy: 0.5590\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2500 - accuracy: 0.5798\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1999 - accuracy: 0.6037\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1526 - accuracy: 0.6093\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1037 - accuracy: 0.6148\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0613 - accuracy: 0.6295\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0499 - accuracy: 0.6255\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0186 - accuracy: 0.6420\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.738 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 3.4524 - accuracy: 0.1560\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.1739 - accuracy: 0.1900\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 2.0006 - accuracy: 0.2348\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.8820 - accuracy: 0.2867\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7845 - accuracy: 0.3255\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6688 - accuracy: 0.3638\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5724 - accuracy: 0.4072\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.4804 - accuracy: 0.4618\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.4034 - accuracy: 0.4870\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3271 - accuracy: 0.5185\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2496 - accuracy: 0.5558\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2039 - accuracy: 0.5795\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1137 - accuracy: 0.6108\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0829 - accuracy: 0.6227\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0446 - accuracy: 0.6392\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9985 - accuracy: 0.6560\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9641 - accuracy: 0.6603\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9410 - accuracy: 0.6737\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9126 - accuracy: 0.6858\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8922 - accuracy: 0.6933\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.753 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.6255 - accuracy: 0.1890\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9470 - accuracy: 0.3137\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6815 - accuracy: 0.4078\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4756 - accuracy: 0.4737\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3413 - accuracy: 0.5330\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2182 - accuracy: 0.5645\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1163 - accuracy: 0.6145\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0676 - accuracy: 0.6260\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9847 - accuracy: 0.6575\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9325 - accuracy: 0.6733\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8985 - accuracy: 0.6938\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8502 - accuracy: 0.6998\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8286 - accuracy: 0.7170\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7891 - accuracy: 0.7225\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7674 - accuracy: 0.7337\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7630 - accuracy: 0.7293\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7479 - accuracy: 0.7343\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7222 - accuracy: 0.7450\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7031 - accuracy: 0.7510\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7023 - accuracy: 0.7505\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.763 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 3.1582 - accuracy: 0.1042\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0978 - accuracy: 0.2195\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8461 - accuracy: 0.3210\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6385 - accuracy: 0.4040\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.4772 - accuracy: 0.4652\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3523 - accuracy: 0.5255\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2438 - accuracy: 0.5493\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1548 - accuracy: 0.5910\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0841 - accuracy: 0.6127\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0396 - accuracy: 0.6320\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9800 - accuracy: 0.6465\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9491 - accuracy: 0.6708\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9008 - accuracy: 0.6833\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8736 - accuracy: 0.6883\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8279 - accuracy: 0.7050\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7978 - accuracy: 0.7197\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7914 - accuracy: 0.7247\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7730 - accuracy: 0.7290\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7612 - accuracy: 0.7325\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7281 - accuracy: 0.7480\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.780 total time=   3.9s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.9866 - accuracy: 0.1155\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.1160 - accuracy: 0.2368\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9123 - accuracy: 0.3228\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7479 - accuracy: 0.3810\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5920 - accuracy: 0.4330\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4505 - accuracy: 0.4880\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3303 - accuracy: 0.5295\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2152 - accuracy: 0.5735\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1356 - accuracy: 0.6105\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0527 - accuracy: 0.6423\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0067 - accuracy: 0.6572\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9469 - accuracy: 0.6768\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8885 - accuracy: 0.6957\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8625 - accuracy: 0.6988\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8538 - accuracy: 0.7020\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8067 - accuracy: 0.7215\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7964 - accuracy: 0.7207\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7465 - accuracy: 0.7362\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7411 - accuracy: 0.7402\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7343 - accuracy: 0.7375\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.786 total time=   3.9s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.9756 - accuracy: 0.1375\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9840 - accuracy: 0.3047\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6790 - accuracy: 0.4042\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4383 - accuracy: 0.4978\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2348 - accuracy: 0.5732\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1061 - accuracy: 0.6087\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0093 - accuracy: 0.6432\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9283 - accuracy: 0.6662\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8665 - accuracy: 0.6855\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8200 - accuracy: 0.7070\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8027 - accuracy: 0.7215\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7465 - accuracy: 0.7350\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7194 - accuracy: 0.7418\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7023 - accuracy: 0.7418\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6763 - accuracy: 0.7617\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6498 - accuracy: 0.7657\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6495 - accuracy: 0.7688\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6250 - accuracy: 0.7770\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6172 - accuracy: 0.7810\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6094 - accuracy: 0.7735\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.787 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.7005 - accuracy: 0.1955\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9574 - accuracy: 0.3137\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6785 - accuracy: 0.4130\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4732 - accuracy: 0.4807\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2900 - accuracy: 0.5470\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1496 - accuracy: 0.5985\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0231 - accuracy: 0.6365\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9517 - accuracy: 0.6582\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8937 - accuracy: 0.6780\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8354 - accuracy: 0.6970\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8002 - accuracy: 0.7110\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7610 - accuracy: 0.7330\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7398 - accuracy: 0.7287\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7152 - accuracy: 0.7360\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6955 - accuracy: 0.7508\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6946 - accuracy: 0.7563\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6649 - accuracy: 0.7638\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6569 - accuracy: 0.7573\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6391 - accuracy: 0.7638\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6390 - accuracy: 0.7692\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.785 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.5320 - accuracy: 0.1883\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8894 - accuracy: 0.3315\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6233 - accuracy: 0.4128\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3835 - accuracy: 0.5140\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2345 - accuracy: 0.5595\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1097 - accuracy: 0.6122\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9833 - accuracy: 0.6557\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9189 - accuracy: 0.6743\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8471 - accuracy: 0.7020\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8165 - accuracy: 0.7132\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7718 - accuracy: 0.7303\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7325 - accuracy: 0.7398\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7105 - accuracy: 0.7515\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6805 - accuracy: 0.7520\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6608 - accuracy: 0.7747\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6411 - accuracy: 0.7715\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6129 - accuracy: 0.7800\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6230 - accuracy: 0.7803\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6072 - accuracy: 0.7812\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5923 - accuracy: 0.7890\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.775 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.6920 - accuracy: 0.1772\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8564 - accuracy: 0.2910\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5912 - accuracy: 0.3915\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4716 - accuracy: 0.4555\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3650 - accuracy: 0.5017\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2655 - accuracy: 0.5583\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1959 - accuracy: 0.5880\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1406 - accuracy: 0.6035\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1057 - accuracy: 0.6225\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0490 - accuracy: 0.6415\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0197 - accuracy: 0.6562\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9694 - accuracy: 0.6687\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9249 - accuracy: 0.6885\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8963 - accuracy: 0.6940\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8694 - accuracy: 0.6985\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8577 - accuracy: 0.7107\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8416 - accuracy: 0.7113\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.8275 - accuracy: 0.7063\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7940 - accuracy: 0.7322\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7897 - accuracy: 0.7275\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.785 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.5363 - accuracy: 0.1797\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7643 - accuracy: 0.3923\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.4976 - accuracy: 0.4868\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3424 - accuracy: 0.5240\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2147 - accuracy: 0.5688\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1354 - accuracy: 0.5962\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0711 - accuracy: 0.6227\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0175 - accuracy: 0.6330\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9990 - accuracy: 0.6283\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9454 - accuracy: 0.6485\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8609 - accuracy: 0.6730\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8706 - accuracy: 0.6762\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8439 - accuracy: 0.6965\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8050 - accuracy: 0.7100\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7842 - accuracy: 0.7125\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7725 - accuracy: 0.7105\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7564 - accuracy: 0.7300\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7480 - accuracy: 0.7293\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7300 - accuracy: 0.7262\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7256 - accuracy: 0.7312\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.781 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 3.0866 - accuracy: 0.1395\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9618 - accuracy: 0.3105\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7128 - accuracy: 0.4115\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5917 - accuracy: 0.4518\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4870 - accuracy: 0.4985\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4286 - accuracy: 0.5178\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3550 - accuracy: 0.5433\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2934 - accuracy: 0.5565\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2411 - accuracy: 0.5778\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.1990 - accuracy: 0.5990\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1656 - accuracy: 0.6058\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1229 - accuracy: 0.6300\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0952 - accuracy: 0.6340\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0586 - accuracy: 0.6488\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0345 - accuracy: 0.6460\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0015 - accuracy: 0.6610\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9461 - accuracy: 0.6768\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9399 - accuracy: 0.6755\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9207 - accuracy: 0.6842\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9099 - accuracy: 0.6865\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.770 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 4.2259 - accuracy: 0.1657\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9348 - accuracy: 0.3540\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6199 - accuracy: 0.4245\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4285 - accuracy: 0.4852\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3107 - accuracy: 0.5393\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1977 - accuracy: 0.5920\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.1060 - accuracy: 0.6208\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0235 - accuracy: 0.6453\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9840 - accuracy: 0.6662\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9211 - accuracy: 0.6873\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8744 - accuracy: 0.7085\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8237 - accuracy: 0.7143\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8109 - accuracy: 0.7230\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7810 - accuracy: 0.7347\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7426 - accuracy: 0.7440\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7335 - accuracy: 0.7398\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7073 - accuracy: 0.7540\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6804 - accuracy: 0.7605\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6766 - accuracy: 0.7673\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6495 - accuracy: 0.7747\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.789 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 3.5815 - accuracy: 0.1363\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.1158 - accuracy: 0.2295\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.8414 - accuracy: 0.3063\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6586 - accuracy: 0.3900\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4722 - accuracy: 0.4600\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3370 - accuracy: 0.5180\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2234 - accuracy: 0.5648\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1233 - accuracy: 0.6053\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0625 - accuracy: 0.6198\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9737 - accuracy: 0.6605\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9350 - accuracy: 0.6715\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8867 - accuracy: 0.6973\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8395 - accuracy: 0.7147\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8128 - accuracy: 0.7200\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7827 - accuracy: 0.7337\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7582 - accuracy: 0.7398\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7521 - accuracy: 0.7418\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7111 - accuracy: 0.7525\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6890 - accuracy: 0.7563\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6671 - accuracy: 0.7628\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.803 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.9977 - accuracy: 0.1647\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7947 - accuracy: 0.3722\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5253 - accuracy: 0.4740\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.3280 - accuracy: 0.5397\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2231 - accuracy: 0.5753\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1071 - accuracy: 0.6097\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0461 - accuracy: 0.6255\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9781 - accuracy: 0.6587\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9166 - accuracy: 0.6715\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8793 - accuracy: 0.6833\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8462 - accuracy: 0.6977\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8303 - accuracy: 0.6967\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8058 - accuracy: 0.7078\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7748 - accuracy: 0.7190\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7361 - accuracy: 0.7410\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7300 - accuracy: 0.7350\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7177 - accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7030 - accuracy: 0.7477\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6794 - accuracy: 0.7542\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6732 - accuracy: 0.7615\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.778 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 3.2579 - accuracy: 0.1705\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.7388 - accuracy: 0.4010\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.3276 - accuracy: 0.5545\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.1402 - accuracy: 0.6062\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9958 - accuracy: 0.6615\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8953 - accuracy: 0.6905\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8224 - accuracy: 0.7182\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7687 - accuracy: 0.7290\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7165 - accuracy: 0.7450\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6796 - accuracy: 0.7605\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6485 - accuracy: 0.7732\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6262 - accuracy: 0.7793\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6219 - accuracy: 0.7780\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5934 - accuracy: 0.7872\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5744 - accuracy: 0.7920\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5655 - accuracy: 0.8008\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5580 - accuracy: 0.8008\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5400 - accuracy: 0.8102\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5291 - accuracy: 0.8163\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5198 - accuracy: 0.8185\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.790 total time=   4.7s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.5748 - accuracy: 0.2405\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.4663 - accuracy: 0.5013\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1628 - accuracy: 0.6040\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0362 - accuracy: 0.6360\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9318 - accuracy: 0.6787\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8631 - accuracy: 0.6963\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7928 - accuracy: 0.7165\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7544 - accuracy: 0.7322\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7274 - accuracy: 0.7473\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7108 - accuracy: 0.7420\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6775 - accuracy: 0.7635\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6484 - accuracy: 0.7665\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6271 - accuracy: 0.7732\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6038 - accuracy: 0.7903\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5865 - accuracy: 0.7915\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5813 - accuracy: 0.7875\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5616 - accuracy: 0.7922\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5606 - accuracy: 0.7977\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5436 - accuracy: 0.8023\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5391 - accuracy: 0.8080\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.805 total time=   4.7s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 2.4353 - accuracy: 0.2272\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.5541 - accuracy: 0.4672\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 1.2362 - accuracy: 0.5803\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0423 - accuracy: 0.6270\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9343 - accuracy: 0.6618\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8364 - accuracy: 0.6930\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7868 - accuracy: 0.7212\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7465 - accuracy: 0.7405\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6899 - accuracy: 0.7505\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6676 - accuracy: 0.7598\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6490 - accuracy: 0.7720\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6252 - accuracy: 0.7795\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6130 - accuracy: 0.7760\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5852 - accuracy: 0.7925\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5793 - accuracy: 0.7937\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5523 - accuracy: 0.8008\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5458 - accuracy: 0.8018\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5317 - accuracy: 0.8015\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5248 - accuracy: 0.8105\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5052 - accuracy: 0.8110\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.795 total time=   5.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.9065 - accuracy: 0.1608\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8059 - accuracy: 0.3438\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6390 - accuracy: 0.4067\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5125 - accuracy: 0.4445\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4217 - accuracy: 0.4893\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2946 - accuracy: 0.5537\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1990 - accuracy: 0.5985\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1283 - accuracy: 0.6258\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0596 - accuracy: 0.6490\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0233 - accuracy: 0.6620\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9489 - accuracy: 0.6795\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9191 - accuracy: 0.6950\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8373 - accuracy: 0.7300\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7971 - accuracy: 0.7203\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7681 - accuracy: 0.7340\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7349 - accuracy: 0.7425\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7076 - accuracy: 0.7610\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6997 - accuracy: 0.7520\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6847 - accuracy: 0.7585\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6651 - accuracy: 0.7660\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.783 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 3.0881 - accuracy: 0.2062\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5626 - accuracy: 0.4565\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3527 - accuracy: 0.5125\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2373 - accuracy: 0.5462\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1592 - accuracy: 0.5857\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0784 - accuracy: 0.6135\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0219 - accuracy: 0.6352\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9620 - accuracy: 0.6590\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9351 - accuracy: 0.6645\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8766 - accuracy: 0.6833\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8642 - accuracy: 0.7010\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8390 - accuracy: 0.7015\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7860 - accuracy: 0.7212\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7583 - accuracy: 0.7312\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7542 - accuracy: 0.7337\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7506 - accuracy: 0.7322\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7066 - accuracy: 0.7538\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7053 - accuracy: 0.7480\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7038 - accuracy: 0.7477\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7069 - accuracy: 0.7450\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.792 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 3.2236 - accuracy: 0.1947\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7312 - accuracy: 0.3882\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5163 - accuracy: 0.4865\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3590 - accuracy: 0.5357\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2946 - accuracy: 0.5695\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1922 - accuracy: 0.6068\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1372 - accuracy: 0.6265\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0686 - accuracy: 0.6392\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0194 - accuracy: 0.6630\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0001 - accuracy: 0.6662\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9326 - accuracy: 0.6833\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9275 - accuracy: 0.6827\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9227 - accuracy: 0.6842\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8676 - accuracy: 0.7097\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8689 - accuracy: 0.7105\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8208 - accuracy: 0.7175\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7888 - accuracy: 0.7215\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7751 - accuracy: 0.7327\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7727 - accuracy: 0.7430\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7567 - accuracy: 0.7400\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.810 total time=   4.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 4.0748 - accuracy: 0.1867\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6899 - accuracy: 0.3925\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3921 - accuracy: 0.4920\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1885 - accuracy: 0.5745\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0646 - accuracy: 0.6285\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9663 - accuracy: 0.6540\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9141 - accuracy: 0.6760\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8504 - accuracy: 0.6963\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8185 - accuracy: 0.7155\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7653 - accuracy: 0.7210\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7398 - accuracy: 0.7410\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7031 - accuracy: 0.7462\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6869 - accuracy: 0.7615\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6638 - accuracy: 0.7623\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6452 - accuracy: 0.7673\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6242 - accuracy: 0.7750\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6110 - accuracy: 0.7835\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5920 - accuracy: 0.7912\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5753 - accuracy: 0.7908\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5590 - accuracy: 0.7980\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.806 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.5894 - accuracy: 0.2705\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4062 - accuracy: 0.4890\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1728 - accuracy: 0.5817\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0102 - accuracy: 0.6460\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9176 - accuracy: 0.6760\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8470 - accuracy: 0.7048\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7904 - accuracy: 0.7235\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7361 - accuracy: 0.7387\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7041 - accuracy: 0.7450\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6818 - accuracy: 0.7577\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6613 - accuracy: 0.7605\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6399 - accuracy: 0.7725\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6099 - accuracy: 0.7805\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5966 - accuracy: 0.7883\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5805 - accuracy: 0.7915\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5694 - accuracy: 0.8005\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5563 - accuracy: 0.8050\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5418 - accuracy: 0.8138\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5388 - accuracy: 0.8070\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5130 - accuracy: 0.8125\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.808 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.8340 - accuracy: 0.2600\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4323 - accuracy: 0.4765\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1404 - accuracy: 0.5910\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9840 - accuracy: 0.6403\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8897 - accuracy: 0.6830\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8402 - accuracy: 0.7040\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7756 - accuracy: 0.7237\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7499 - accuracy: 0.7278\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7126 - accuracy: 0.7465\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6759 - accuracy: 0.7542\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6788 - accuracy: 0.7620\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6442 - accuracy: 0.7722\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6263 - accuracy: 0.7732\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6137 - accuracy: 0.7755\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6033 - accuracy: 0.7747\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5797 - accuracy: 0.7878\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5659 - accuracy: 0.7937\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5568 - accuracy: 0.7997\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5434 - accuracy: 0.8025\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5351 - accuracy: 0.8045\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.806 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 2.4935 - accuracy: 0.2960\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2796 - accuracy: 0.5660\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0411 - accuracy: 0.6395\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8928 - accuracy: 0.6920\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8076 - accuracy: 0.7172\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7418 - accuracy: 0.7470\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6930 - accuracy: 0.7582\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6678 - accuracy: 0.7558\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6268 - accuracy: 0.7782\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5976 - accuracy: 0.7928\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5727 - accuracy: 0.7908\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5497 - accuracy: 0.8080\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5472 - accuracy: 0.8023\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5125 - accuracy: 0.8198\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4925 - accuracy: 0.8215\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4776 - accuracy: 0.8280\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4636 - accuracy: 0.8370\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4484 - accuracy: 0.8378\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4455 - accuracy: 0.8382\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4332 - accuracy: 0.8470\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.821 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 2.4754 - accuracy: 0.2817\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3430 - accuracy: 0.5430\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0586 - accuracy: 0.6327\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9080 - accuracy: 0.6877\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8320 - accuracy: 0.7075\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7637 - accuracy: 0.7340\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6989 - accuracy: 0.7555\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6591 - accuracy: 0.7640\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6297 - accuracy: 0.7735\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5977 - accuracy: 0.7915\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5758 - accuracy: 0.7933\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5702 - accuracy: 0.7968\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5382 - accuracy: 0.8010\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5304 - accuracy: 0.8117\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5148 - accuracy: 0.8108\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5000 - accuracy: 0.8255\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4757 - accuracy: 0.8303\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4622 - accuracy: 0.8342\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4473 - accuracy: 0.8360\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4454 - accuracy: 0.8385\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.823 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.5743 - accuracy: 0.2840\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4130 - accuracy: 0.5310\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0818 - accuracy: 0.6355\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9358 - accuracy: 0.6810\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8245 - accuracy: 0.7218\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7537 - accuracy: 0.7452\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7010 - accuracy: 0.7550\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6541 - accuracy: 0.7705\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6175 - accuracy: 0.7912\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6006 - accuracy: 0.7830\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5639 - accuracy: 0.7970\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5419 - accuracy: 0.8065\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5206 - accuracy: 0.8125\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4969 - accuracy: 0.8298\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4928 - accuracy: 0.8232\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4691 - accuracy: 0.8315\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4643 - accuracy: 0.8307\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4462 - accuracy: 0.8425\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4399 - accuracy: 0.8418\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4167 - accuracy: 0.8478\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.829 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 2.5616 - accuracy: 0.1305\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0239 - accuracy: 0.2460\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8391 - accuracy: 0.3083\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7072 - accuracy: 0.3632\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5723 - accuracy: 0.4338\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4821 - accuracy: 0.4652\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3853 - accuracy: 0.5163\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3125 - accuracy: 0.5518\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2278 - accuracy: 0.5750\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1765 - accuracy: 0.5817\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1520 - accuracy: 0.5922\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0890 - accuracy: 0.6137\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0738 - accuracy: 0.6152\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0406 - accuracy: 0.6327\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9964 - accuracy: 0.6357\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9684 - accuracy: 0.6500\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9348 - accuracy: 0.6600\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9224 - accuracy: 0.6762\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9013 - accuracy: 0.6745\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8602 - accuracy: 0.6905\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.763 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 2.8250 - accuracy: 0.1067\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2064 - accuracy: 0.1680\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0926 - accuracy: 0.2140\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9743 - accuracy: 0.2777\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8228 - accuracy: 0.3557\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6933 - accuracy: 0.3980\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5464 - accuracy: 0.4527\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4125 - accuracy: 0.4995\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3451 - accuracy: 0.5207\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2448 - accuracy: 0.5605\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1912 - accuracy: 0.5785\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1391 - accuracy: 0.6030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0795 - accuracy: 0.6220\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0184 - accuracy: 0.6410\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0000 - accuracy: 0.6470\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9605 - accuracy: 0.6635\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9344 - accuracy: 0.6647\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9192 - accuracy: 0.6823\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8886 - accuracy: 0.6927\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8953 - accuracy: 0.6873\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.762 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 3.7915 - accuracy: 0.1593\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.3227 - accuracy: 0.2055\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1025 - accuracy: 0.2430\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0164 - accuracy: 0.2812\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9345 - accuracy: 0.3095\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.8742 - accuracy: 0.3330\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7934 - accuracy: 0.3675\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7081 - accuracy: 0.4198\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6302 - accuracy: 0.4322\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5643 - accuracy: 0.4482\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5059 - accuracy: 0.4678\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4662 - accuracy: 0.4730\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4160 - accuracy: 0.5010\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3739 - accuracy: 0.5082\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3451 - accuracy: 0.5255\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2899 - accuracy: 0.5458\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2763 - accuracy: 0.5465\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2405 - accuracy: 0.5655\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2104 - accuracy: 0.5702\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1941 - accuracy: 0.5717\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.650 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 2.6946 - accuracy: 0.1163\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0565 - accuracy: 0.2352\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7808 - accuracy: 0.3557\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5454 - accuracy: 0.4678\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3639 - accuracy: 0.5370\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2209 - accuracy: 0.5853\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1033 - accuracy: 0.6200\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0109 - accuracy: 0.6450\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9747 - accuracy: 0.6630\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9074 - accuracy: 0.6833\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8523 - accuracy: 0.7007\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8136 - accuracy: 0.7078\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7827 - accuracy: 0.7195\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7446 - accuracy: 0.7405\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7320 - accuracy: 0.7467\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7112 - accuracy: 0.7510\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7054 - accuracy: 0.7575\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6770 - accuracy: 0.7607\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6672 - accuracy: 0.7567\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6460 - accuracy: 0.7667\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.791 total time=   4.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 3.4716 - accuracy: 0.1315\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1748 - accuracy: 0.2160\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9639 - accuracy: 0.2982\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8494 - accuracy: 0.3830\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7425 - accuracy: 0.4330\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6237 - accuracy: 0.4708\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5180 - accuracy: 0.5080\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4263 - accuracy: 0.5480\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3594 - accuracy: 0.5850\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2816 - accuracy: 0.6020\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2167 - accuracy: 0.6288\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1639 - accuracy: 0.6425\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1084 - accuracy: 0.6672\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0612 - accuracy: 0.6685\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0174 - accuracy: 0.6888\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9970 - accuracy: 0.6990\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9737 - accuracy: 0.7088\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9348 - accuracy: 0.7117\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9111 - accuracy: 0.7193\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9006 - accuracy: 0.7245\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.757 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 3.0876 - accuracy: 0.1168\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1650 - accuracy: 0.2077\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0055 - accuracy: 0.2945\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8841 - accuracy: 0.3512\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7992 - accuracy: 0.3955\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7207 - accuracy: 0.4243\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6290 - accuracy: 0.4710\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5285 - accuracy: 0.5058\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4459 - accuracy: 0.5310\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3599 - accuracy: 0.5720\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2797 - accuracy: 0.5960\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2324 - accuracy: 0.6240\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1695 - accuracy: 0.6482\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1581 - accuracy: 0.6503\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1051 - accuracy: 0.6660\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0714 - accuracy: 0.6660\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0383 - accuracy: 0.6812\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0154 - accuracy: 0.6798\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9711 - accuracy: 0.6877\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9214 - accuracy: 0.6980\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.721 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 2.5526 - accuracy: 0.1860\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8515 - accuracy: 0.3580\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4567 - accuracy: 0.4980\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1284 - accuracy: 0.5993\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9390 - accuracy: 0.6585\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8607 - accuracy: 0.6927\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7790 - accuracy: 0.7195\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7334 - accuracy: 0.7350\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7077 - accuracy: 0.7398\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6679 - accuracy: 0.7570\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6455 - accuracy: 0.7623\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6106 - accuracy: 0.7788\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5975 - accuracy: 0.7830\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5835 - accuracy: 0.7912\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5685 - accuracy: 0.7950\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5590 - accuracy: 0.8005\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5331 - accuracy: 0.8085\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5355 - accuracy: 0.8085\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5194 - accuracy: 0.8175\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5085 - accuracy: 0.8152\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.791 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.2531 - accuracy: 0.1373\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0807 - accuracy: 0.2573\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8317 - accuracy: 0.3938\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5968 - accuracy: 0.4740\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3867 - accuracy: 0.5325\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1820 - accuracy: 0.5920\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0280 - accuracy: 0.6405\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9180 - accuracy: 0.6770\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8235 - accuracy: 0.7092\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7833 - accuracy: 0.7163\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7325 - accuracy: 0.7358\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7124 - accuracy: 0.7470\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6807 - accuracy: 0.7498\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6536 - accuracy: 0.7620\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6487 - accuracy: 0.7610\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6337 - accuracy: 0.7705\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6087 - accuracy: 0.7790\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5966 - accuracy: 0.7795\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5885 - accuracy: 0.7847\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5707 - accuracy: 0.7908\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.787 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.2673 - accuracy: 0.2545\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5744 - accuracy: 0.4703\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2764 - accuracy: 0.5663\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1003 - accuracy: 0.6155\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9751 - accuracy: 0.6507\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8927 - accuracy: 0.6875\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7941 - accuracy: 0.7160\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7413 - accuracy: 0.7355\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6978 - accuracy: 0.7525\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6551 - accuracy: 0.7667\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6263 - accuracy: 0.7793\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5955 - accuracy: 0.7885\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5900 - accuracy: 0.7903\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5632 - accuracy: 0.8015\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5483 - accuracy: 0.8033\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5399 - accuracy: 0.8080\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5226 - accuracy: 0.8110\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5111 - accuracy: 0.8200\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5098 - accuracy: 0.8133\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4908 - accuracy: 0.8223\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.810 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 35ms/step - loss: 2.4047 - accuracy: 0.1583\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0177 - accuracy: 0.2915\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8661 - accuracy: 0.3532\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7596 - accuracy: 0.3815\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.6359 - accuracy: 0.4263\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4823 - accuracy: 0.4868\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4163 - accuracy: 0.5080\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3164 - accuracy: 0.5580\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2588 - accuracy: 0.5698\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1996 - accuracy: 0.5857\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1469 - accuracy: 0.6058\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1098 - accuracy: 0.6160\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0713 - accuracy: 0.6310\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0414 - accuracy: 0.6447\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9998 - accuracy: 0.6522\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9738 - accuracy: 0.6715\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9163 - accuracy: 0.6960\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8974 - accuracy: 0.7067\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8579 - accuracy: 0.7295\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8205 - accuracy: 0.7270\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.764 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.5853 - accuracy: 0.1287\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2424 - accuracy: 0.1832\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0339 - accuracy: 0.2375\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8876 - accuracy: 0.2878\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7796 - accuracy: 0.3280\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6818 - accuracy: 0.3747\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5942 - accuracy: 0.4170\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4843 - accuracy: 0.4633\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4182 - accuracy: 0.4980\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3361 - accuracy: 0.5125\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2668 - accuracy: 0.5395\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.1955 - accuracy: 0.5680\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.1256 - accuracy: 0.5880\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0841 - accuracy: 0.6055\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0444 - accuracy: 0.6165\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0269 - accuracy: 0.6143\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9887 - accuracy: 0.6423\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9484 - accuracy: 0.6565\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9308 - accuracy: 0.6543\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9067 - accuracy: 0.6643\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.757 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.6472 - accuracy: 0.1273\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0707 - accuracy: 0.2338\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.9722 - accuracy: 0.2790\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8572 - accuracy: 0.3288\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7401 - accuracy: 0.3713\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6760 - accuracy: 0.3957\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5841 - accuracy: 0.4205\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5064 - accuracy: 0.4498\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4161 - accuracy: 0.4818\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3422 - accuracy: 0.5157\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2825 - accuracy: 0.5385\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2147 - accuracy: 0.5598\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1589 - accuracy: 0.5798\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1016 - accuracy: 0.5960\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0795 - accuracy: 0.6150\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0315 - accuracy: 0.6400\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9984 - accuracy: 0.6447\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9610 - accuracy: 0.6712\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9298 - accuracy: 0.6910\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8866 - accuracy: 0.7113\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.766 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.5715 - accuracy: 0.1610\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8615 - accuracy: 0.3095\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6028 - accuracy: 0.4130\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3989 - accuracy: 0.4835\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2590 - accuracy: 0.5447\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0965 - accuracy: 0.6118\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0186 - accuracy: 0.6410\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9241 - accuracy: 0.6770\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8862 - accuracy: 0.6885\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8211 - accuracy: 0.7103\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7920 - accuracy: 0.7255\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7379 - accuracy: 0.7387\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7090 - accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6935 - accuracy: 0.7538\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6788 - accuracy: 0.7582\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6523 - accuracy: 0.7692\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6325 - accuracy: 0.7782\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6285 - accuracy: 0.7770\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6039 - accuracy: 0.7865\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5705 - accuracy: 0.7995\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.807 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.9047 - accuracy: 0.1510\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.0137 - accuracy: 0.2850\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7115 - accuracy: 0.3875\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4730 - accuracy: 0.4835\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2850 - accuracy: 0.5573\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1174 - accuracy: 0.6143\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0192 - accuracy: 0.6513\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9536 - accuracy: 0.6645\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9071 - accuracy: 0.6842\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8357 - accuracy: 0.7212\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8141 - accuracy: 0.7203\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7844 - accuracy: 0.7305\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7357 - accuracy: 0.7430\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7260 - accuracy: 0.7505\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6980 - accuracy: 0.7565\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6702 - accuracy: 0.7682\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6608 - accuracy: 0.7785\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6439 - accuracy: 0.7790\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6323 - accuracy: 0.7865\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6134 - accuracy: 0.7832\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.809 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.8657 - accuracy: 0.1740\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8805 - accuracy: 0.3505\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5404 - accuracy: 0.4638\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3110 - accuracy: 0.5378\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1649 - accuracy: 0.5882\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0405 - accuracy: 0.6230\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9780 - accuracy: 0.6373\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9014 - accuracy: 0.6693\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8477 - accuracy: 0.6948\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8043 - accuracy: 0.7100\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7846 - accuracy: 0.7080\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7476 - accuracy: 0.7303\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7124 - accuracy: 0.7420\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7054 - accuracy: 0.7513\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6709 - accuracy: 0.7548\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6504 - accuracy: 0.7620\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6545 - accuracy: 0.7742\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6099 - accuracy: 0.7763\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5956 - accuracy: 0.7832\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5879 - accuracy: 0.7887\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.785 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 34ms/step - loss: 2.4793 - accuracy: 0.2828\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.4664 - accuracy: 0.5160\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.1802 - accuracy: 0.6185\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.0061 - accuracy: 0.6643\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8881 - accuracy: 0.6988\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7961 - accuracy: 0.7253\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7051 - accuracy: 0.7505\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6788 - accuracy: 0.7567\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6453 - accuracy: 0.7682\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6159 - accuracy: 0.7837\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5992 - accuracy: 0.7850\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5493 - accuracy: 0.8058\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5435 - accuracy: 0.8060\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5249 - accuracy: 0.8148\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5139 - accuracy: 0.8115\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5038 - accuracy: 0.8195\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4864 - accuracy: 0.8305\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4804 - accuracy: 0.8282\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4590 - accuracy: 0.8378\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4449 - accuracy: 0.8393\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.810 total time=   5.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 34ms/step - loss: 3.0623 - accuracy: 0.1733\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.7214 - accuracy: 0.3977\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.3673 - accuracy: 0.5293\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.1480 - accuracy: 0.6065\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9721 - accuracy: 0.6578\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.8601 - accuracy: 0.7015\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7869 - accuracy: 0.7260\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7415 - accuracy: 0.7458\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7002 - accuracy: 0.7517\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6687 - accuracy: 0.7695\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6429 - accuracy: 0.7690\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6104 - accuracy: 0.7855\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6026 - accuracy: 0.7925\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5800 - accuracy: 0.7955\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5770 - accuracy: 0.7958\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5405 - accuracy: 0.8070\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5291 - accuracy: 0.8102\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5192 - accuracy: 0.8150\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4975 - accuracy: 0.8202\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4965 - accuracy: 0.8235\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.807 total time=   4.9s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 2.7706 - accuracy: 0.1845\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.6083 - accuracy: 0.4440\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.2181 - accuracy: 0.5913\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0178 - accuracy: 0.6467\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9063 - accuracy: 0.6785\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.8300 - accuracy: 0.7040\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7430 - accuracy: 0.7335\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7038 - accuracy: 0.7498\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6698 - accuracy: 0.7598\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6256 - accuracy: 0.7795\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5963 - accuracy: 0.7885\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5850 - accuracy: 0.7947\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5628 - accuracy: 0.8012\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5414 - accuracy: 0.8080\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5253 - accuracy: 0.8140\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5082 - accuracy: 0.8150\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5089 - accuracy: 0.8167\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4934 - accuracy: 0.8267\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4747 - accuracy: 0.8305\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4610 - accuracy: 0.8307\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.812 total time=   5.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.9744 - accuracy: 0.1503\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0435 - accuracy: 0.2295\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8946 - accuracy: 0.2907\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7568 - accuracy: 0.3405\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6042 - accuracy: 0.4150\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4843 - accuracy: 0.4500\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3769 - accuracy: 0.5005\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2831 - accuracy: 0.5268\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1957 - accuracy: 0.5545\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1101 - accuracy: 0.5745\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0219 - accuracy: 0.6097\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9839 - accuracy: 0.6145\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9268 - accuracy: 0.6395\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9021 - accuracy: 0.6550\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8675 - accuracy: 0.6737\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8401 - accuracy: 0.6837\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8211 - accuracy: 0.6915\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8016 - accuracy: 0.6998\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7704 - accuracy: 0.7117\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7575 - accuracy: 0.7232\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.771 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.8907 - accuracy: 0.1905\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9544 - accuracy: 0.2943\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7681 - accuracy: 0.3530\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6550 - accuracy: 0.3865\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5566 - accuracy: 0.4157\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4920 - accuracy: 0.4410\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4243 - accuracy: 0.4650\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3783 - accuracy: 0.4850\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3212 - accuracy: 0.5138\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2597 - accuracy: 0.5272\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2121 - accuracy: 0.5450\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1679 - accuracy: 0.5688\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0910 - accuracy: 0.5878\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0558 - accuracy: 0.6137\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9873 - accuracy: 0.6345\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9474 - accuracy: 0.6460\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8983 - accuracy: 0.6730\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8450 - accuracy: 0.6888\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8593 - accuracy: 0.6805\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8127 - accuracy: 0.6938\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.801 total time=   4.6s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 3.1850 - accuracy: 0.1800\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8418 - accuracy: 0.3257\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6722 - accuracy: 0.3767\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.5584 - accuracy: 0.4142\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4691 - accuracy: 0.4610\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4091 - accuracy: 0.4733\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3266 - accuracy: 0.5055\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2863 - accuracy: 0.5222\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2199 - accuracy: 0.5555\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1954 - accuracy: 0.5600\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1698 - accuracy: 0.5627\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1172 - accuracy: 0.5835\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1058 - accuracy: 0.5882\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0671 - accuracy: 0.6012\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0375 - accuracy: 0.6200\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0206 - accuracy: 0.6255\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0040 - accuracy: 0.6440\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9908 - accuracy: 0.6515\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9552 - accuracy: 0.6528\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9272 - accuracy: 0.6680\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.771 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.4639 - accuracy: 0.2128\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5168 - accuracy: 0.4512\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2127 - accuracy: 0.5567\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0255 - accuracy: 0.6295\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8993 - accuracy: 0.6883\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8275 - accuracy: 0.7097\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7618 - accuracy: 0.7333\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7151 - accuracy: 0.7462\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6760 - accuracy: 0.7600\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6270 - accuracy: 0.7778\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6164 - accuracy: 0.7830\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6000 - accuracy: 0.7803\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5830 - accuracy: 0.7925\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5550 - accuracy: 0.8033\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5568 - accuracy: 0.8067\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5236 - accuracy: 0.8100\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5202 - accuracy: 0.8183\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4926 - accuracy: 0.8275\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4814 - accuracy: 0.8313\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4681 - accuracy: 0.8350\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.808 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.5297 - accuracy: 0.1622\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8596 - accuracy: 0.3415\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5603 - accuracy: 0.4620\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3454 - accuracy: 0.5480\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1824 - accuracy: 0.6108\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0707 - accuracy: 0.6528\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9575 - accuracy: 0.6852\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9074 - accuracy: 0.7003\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8376 - accuracy: 0.7147\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7936 - accuracy: 0.7293\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7515 - accuracy: 0.7460\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7340 - accuracy: 0.7450\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6975 - accuracy: 0.7585\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6728 - accuracy: 0.7632\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6591 - accuracy: 0.7703\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6291 - accuracy: 0.7878\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6242 - accuracy: 0.7825\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6072 - accuracy: 0.7878\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5883 - accuracy: 0.8015\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5653 - accuracy: 0.8040\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.813 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.2368 - accuracy: 0.3052\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5418 - accuracy: 0.4730\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3272 - accuracy: 0.5490\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1924 - accuracy: 0.5888\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0704 - accuracy: 0.6275\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9604 - accuracy: 0.6647\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8785 - accuracy: 0.6888\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8116 - accuracy: 0.7092\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7645 - accuracy: 0.7200\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7205 - accuracy: 0.7430\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6877 - accuracy: 0.7510\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6588 - accuracy: 0.7640\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6309 - accuracy: 0.7732\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6013 - accuracy: 0.7753\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5813 - accuracy: 0.7857\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5656 - accuracy: 0.7900\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5612 - accuracy: 0.7900\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5456 - accuracy: 0.8045\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5343 - accuracy: 0.7965\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5004 - accuracy: 0.8127\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.806 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.5002 - accuracy: 0.2830\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2865 - accuracy: 0.5673\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9901 - accuracy: 0.6640\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8613 - accuracy: 0.7050\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7600 - accuracy: 0.7372\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6916 - accuracy: 0.7590\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6413 - accuracy: 0.7692\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6041 - accuracy: 0.7847\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5641 - accuracy: 0.7947\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5445 - accuracy: 0.8035\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5183 - accuracy: 0.8127\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5094 - accuracy: 0.8175\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4779 - accuracy: 0.8278\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4617 - accuracy: 0.8372\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4457 - accuracy: 0.8428\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4317 - accuracy: 0.8403\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4151 - accuracy: 0.8478\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4023 - accuracy: 0.8530\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3863 - accuracy: 0.8572\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3804 - accuracy: 0.8652\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.808 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.7144 - accuracy: 0.1452\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8093 - accuracy: 0.3577\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4488 - accuracy: 0.5080\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1589 - accuracy: 0.6230\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9663 - accuracy: 0.6833\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8896 - accuracy: 0.6998\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7891 - accuracy: 0.7303\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7303 - accuracy: 0.7558\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6856 - accuracy: 0.7667\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6611 - accuracy: 0.7705\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6135 - accuracy: 0.7878\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5986 - accuracy: 0.7952\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5762 - accuracy: 0.8048\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5589 - accuracy: 0.8095\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5238 - accuracy: 0.8230\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5237 - accuracy: 0.8135\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4992 - accuracy: 0.8240\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4955 - accuracy: 0.8322\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4695 - accuracy: 0.8367\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4499 - accuracy: 0.8430\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.822 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.3278 - accuracy: 0.2677\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4088 - accuracy: 0.5242\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.1002 - accuracy: 0.6403\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9164 - accuracy: 0.6938\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7948 - accuracy: 0.7310\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7060 - accuracy: 0.7598\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6688 - accuracy: 0.7703\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6161 - accuracy: 0.7840\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5895 - accuracy: 0.7905\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5606 - accuracy: 0.7958\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5344 - accuracy: 0.8080\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5113 - accuracy: 0.8135\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4812 - accuracy: 0.8235\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4803 - accuracy: 0.8340\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4520 - accuracy: 0.8365\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4376 - accuracy: 0.8435\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4108 - accuracy: 0.8543\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4104 - accuracy: 0.8583\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4039 - accuracy: 0.8508\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3808 - accuracy: 0.8627\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.823 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 2.8449 - accuracy: 0.1182\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2010 - accuracy: 0.1885\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0506 - accuracy: 0.2345\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9414 - accuracy: 0.2735\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8433 - accuracy: 0.3400\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7542 - accuracy: 0.3767\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6673 - accuracy: 0.4053\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.5881 - accuracy: 0.4327\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5185 - accuracy: 0.4625\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4174 - accuracy: 0.5030\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3882 - accuracy: 0.4960\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3242 - accuracy: 0.5182\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2815 - accuracy: 0.5312\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2670 - accuracy: 0.5418\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2209 - accuracy: 0.5525\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2010 - accuracy: 0.5585\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1685 - accuracy: 0.5720\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1574 - accuracy: 0.5817\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1073 - accuracy: 0.5878\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0905 - accuracy: 0.5893\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.650 total time=   4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 2.4426 - accuracy: 0.1007\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0511 - accuracy: 0.2403\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7927 - accuracy: 0.3338\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6299 - accuracy: 0.4040\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4941 - accuracy: 0.4460\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3865 - accuracy: 0.5102\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3137 - accuracy: 0.5360\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2669 - accuracy: 0.5605\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2020 - accuracy: 0.5700\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1128 - accuracy: 0.6105\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0873 - accuracy: 0.6198\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0509 - accuracy: 0.6295\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0210 - accuracy: 0.6373\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9999 - accuracy: 0.6545\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9610 - accuracy: 0.6625\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9414 - accuracy: 0.6610\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9177 - accuracy: 0.6790\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8975 - accuracy: 0.6775\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8792 - accuracy: 0.6855\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8573 - accuracy: 0.6860\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.761 total time=   4.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 3.3638 - accuracy: 0.0760\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.3293 - accuracy: 0.1312\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1359 - accuracy: 0.2055\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9935 - accuracy: 0.2660\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8488 - accuracy: 0.3288\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7555 - accuracy: 0.3660\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6105 - accuracy: 0.4108\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4909 - accuracy: 0.4602\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4016 - accuracy: 0.4857\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3124 - accuracy: 0.5225\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2569 - accuracy: 0.5362\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1622 - accuracy: 0.5675\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1117 - accuracy: 0.5978\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0538 - accuracy: 0.6215\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0195 - accuracy: 0.6417\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9467 - accuracy: 0.6658\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9297 - accuracy: 0.6670\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9107 - accuracy: 0.6678\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8708 - accuracy: 0.6948\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8413 - accuracy: 0.7040\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.758 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 3.1601 - accuracy: 0.1290\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.1506 - accuracy: 0.2300\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9073 - accuracy: 0.3315\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7135 - accuracy: 0.4195\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5145 - accuracy: 0.4850\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3566 - accuracy: 0.5418\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2278 - accuracy: 0.5835\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1330 - accuracy: 0.6090\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0459 - accuracy: 0.6438\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9663 - accuracy: 0.6662\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9180 - accuracy: 0.6880\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8942 - accuracy: 0.6948\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8330 - accuracy: 0.7090\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7926 - accuracy: 0.7222\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7685 - accuracy: 0.7330\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7495 - accuracy: 0.7395\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7137 - accuracy: 0.7510\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7100 - accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6801 - accuracy: 0.7605\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6643 - accuracy: 0.7648\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.783 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 3.0949 - accuracy: 0.1025\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2818 - accuracy: 0.1495\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1566 - accuracy: 0.2180\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0648 - accuracy: 0.2660\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9668 - accuracy: 0.3092\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8728 - accuracy: 0.3470\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7280 - accuracy: 0.4305\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5792 - accuracy: 0.4945\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4328 - accuracy: 0.5410\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3482 - accuracy: 0.5815\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2978 - accuracy: 0.6020\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2408 - accuracy: 0.6230\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1933 - accuracy: 0.6263\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0944 - accuracy: 0.6532\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0208 - accuracy: 0.6635\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9485 - accuracy: 0.6758\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9108 - accuracy: 0.6875\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8714 - accuracy: 0.7015\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8371 - accuracy: 0.7023\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8207 - accuracy: 0.7170\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.735 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 2.8926 - accuracy: 0.1233\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1085 - accuracy: 0.2268\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9006 - accuracy: 0.3063\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7212 - accuracy: 0.3708\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5559 - accuracy: 0.4383\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4025 - accuracy: 0.4900\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2767 - accuracy: 0.5293\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1710 - accuracy: 0.5715\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0800 - accuracy: 0.6077\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9912 - accuracy: 0.6480\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9455 - accuracy: 0.6662\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8899 - accuracy: 0.6905\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8565 - accuracy: 0.6960\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8279 - accuracy: 0.7065\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7908 - accuracy: 0.7163\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7748 - accuracy: 0.7210\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7796 - accuracy: 0.7147\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7379 - accuracy: 0.7345\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7085 - accuracy: 0.7483\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.6888 - accuracy: 0.7452\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.753 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.9016 - accuracy: 0.1583\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9181 - accuracy: 0.3165\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5760 - accuracy: 0.4697\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2542 - accuracy: 0.5782\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0576 - accuracy: 0.6465\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9374 - accuracy: 0.6733\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8551 - accuracy: 0.7015\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8015 - accuracy: 0.7200\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7424 - accuracy: 0.7372\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7113 - accuracy: 0.7430\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6778 - accuracy: 0.7525\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6652 - accuracy: 0.7635\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6380 - accuracy: 0.7710\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6134 - accuracy: 0.7765\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6072 - accuracy: 0.7818\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5891 - accuracy: 0.7890\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5681 - accuracy: 0.7915\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5438 - accuracy: 0.8020\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5462 - accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5396 - accuracy: 0.8030\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.790 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.2562 - accuracy: 0.2220\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7071 - accuracy: 0.4288\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4405 - accuracy: 0.5188\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2608 - accuracy: 0.5610\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1153 - accuracy: 0.6035\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0224 - accuracy: 0.6480\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9328 - accuracy: 0.6790\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8564 - accuracy: 0.7132\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7889 - accuracy: 0.7312\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7005 - accuracy: 0.7565\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6649 - accuracy: 0.7657\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6196 - accuracy: 0.7755\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6001 - accuracy: 0.7885\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5781 - accuracy: 0.7887\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5684 - accuracy: 0.7940\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5450 - accuracy: 0.7990\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5414 - accuracy: 0.8100\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5115 - accuracy: 0.8133\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5117 - accuracy: 0.8163\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5057 - accuracy: 0.8158\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.809 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.2170 - accuracy: 0.2327\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5803 - accuracy: 0.4535\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2909 - accuracy: 0.5485\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1102 - accuracy: 0.6102\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9609 - accuracy: 0.6603\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8736 - accuracy: 0.6860\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8079 - accuracy: 0.7040\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7467 - accuracy: 0.7297\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7185 - accuracy: 0.7272\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6957 - accuracy: 0.7390\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6600 - accuracy: 0.7552\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6313 - accuracy: 0.7592\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6154 - accuracy: 0.7660\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5941 - accuracy: 0.7735\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5758 - accuracy: 0.7760\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5630 - accuracy: 0.7855\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5628 - accuracy: 0.7837\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5378 - accuracy: 0.7928\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5325 - accuracy: 0.7952\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5194 - accuracy: 0.8008\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.792 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.1603 - accuracy: 0.1433\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2438 - accuracy: 0.1398\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0992 - accuracy: 0.1733\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0103 - accuracy: 0.2205\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.9470 - accuracy: 0.2535\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8592 - accuracy: 0.3133\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7706 - accuracy: 0.3632\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.6649 - accuracy: 0.4042\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5961 - accuracy: 0.4263\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5067 - accuracy: 0.4448\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4400 - accuracy: 0.4700\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4003 - accuracy: 0.4893\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3464 - accuracy: 0.5157\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2606 - accuracy: 0.5525\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1865 - accuracy: 0.5663\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1416 - accuracy: 0.5925\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0998 - accuracy: 0.5995\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0479 - accuracy: 0.6308\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9990 - accuracy: 0.6595\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9653 - accuracy: 0.6718\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.745 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.0017 - accuracy: 0.1340\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0448 - accuracy: 0.2235\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8710 - accuracy: 0.2858\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7724 - accuracy: 0.3225\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6394 - accuracy: 0.3803\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5478 - accuracy: 0.4235\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4412 - accuracy: 0.4555\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3635 - accuracy: 0.4825\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2980 - accuracy: 0.5060\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2204 - accuracy: 0.5408\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1650 - accuracy: 0.5590\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1320 - accuracy: 0.5775\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0941 - accuracy: 0.5968\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0396 - accuracy: 0.6108\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9975 - accuracy: 0.6267\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9750 - accuracy: 0.6530\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9390 - accuracy: 0.6582\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9272 - accuracy: 0.6643\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8986 - accuracy: 0.6745\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8655 - accuracy: 0.6858\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.763 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.6715 - accuracy: 0.1338\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0577 - accuracy: 0.2292\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8686 - accuracy: 0.2855\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7046 - accuracy: 0.3555\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5567 - accuracy: 0.4128\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.4189 - accuracy: 0.4890\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.3211 - accuracy: 0.5390\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2239 - accuracy: 0.5630\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1433 - accuracy: 0.5910\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0689 - accuracy: 0.6160\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0329 - accuracy: 0.6308\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9703 - accuracy: 0.6425\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9299 - accuracy: 0.6675\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8739 - accuracy: 0.6833\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8669 - accuracy: 0.6957\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8497 - accuracy: 0.7032\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8012 - accuracy: 0.7247\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7961 - accuracy: 0.7235\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7634 - accuracy: 0.7300\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7641 - accuracy: 0.7318\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.785 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 4.8253 - accuracy: 0.1175\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2368 - accuracy: 0.1950\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.9676 - accuracy: 0.2892\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7636 - accuracy: 0.3645\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5928 - accuracy: 0.4173\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4335 - accuracy: 0.4790\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2727 - accuracy: 0.5408\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1780 - accuracy: 0.5788\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0745 - accuracy: 0.6338\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0094 - accuracy: 0.6605\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9362 - accuracy: 0.6873\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8802 - accuracy: 0.6935\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8431 - accuracy: 0.7113\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7870 - accuracy: 0.7295\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7684 - accuracy: 0.7387\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7561 - accuracy: 0.7347\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7179 - accuracy: 0.7517\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6952 - accuracy: 0.7585\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6743 - accuracy: 0.7617\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6540 - accuracy: 0.7713\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.784 total time=   4.6s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 4.5786 - accuracy: 0.1168\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2074 - accuracy: 0.2368\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.9091 - accuracy: 0.3288\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6934 - accuracy: 0.4112\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5261 - accuracy: 0.4688\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3775 - accuracy: 0.5157\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2868 - accuracy: 0.5493\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1645 - accuracy: 0.6062\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0805 - accuracy: 0.6225\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0138 - accuracy: 0.6510\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9599 - accuracy: 0.6735\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9075 - accuracy: 0.6938\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8670 - accuracy: 0.7050\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8079 - accuracy: 0.7185\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8043 - accuracy: 0.7237\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7642 - accuracy: 0.7408\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7481 - accuracy: 0.7410\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7210 - accuracy: 0.7573\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6971 - accuracy: 0.7720\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6955 - accuracy: 0.7655\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.788 total time=   4.6s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 3.5078 - accuracy: 0.1150\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.1617 - accuracy: 0.2068\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.9076 - accuracy: 0.3290\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6997 - accuracy: 0.4135\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5138 - accuracy: 0.5040\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3567 - accuracy: 0.5460\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2091 - accuracy: 0.5738\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1016 - accuracy: 0.6030\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0234 - accuracy: 0.6250\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9734 - accuracy: 0.6538\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9075 - accuracy: 0.6655\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8653 - accuracy: 0.7020\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8172 - accuracy: 0.7057\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7835 - accuracy: 0.7312\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7537 - accuracy: 0.7335\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7172 - accuracy: 0.7340\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6903 - accuracy: 0.7535\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6691 - accuracy: 0.7577\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6528 - accuracy: 0.7635\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6371 - accuracy: 0.7682\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.791 total time=   4.6s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 34ms/step - loss: 2.7156 - accuracy: 0.1943\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.6962 - accuracy: 0.4268\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.2941 - accuracy: 0.5715\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.0418 - accuracy: 0.6520\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9390 - accuracy: 0.6750\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8264 - accuracy: 0.7030\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7788 - accuracy: 0.7265\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7120 - accuracy: 0.7423\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6719 - accuracy: 0.7530\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6308 - accuracy: 0.7673\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6063 - accuracy: 0.7753\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5939 - accuracy: 0.7785\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5828 - accuracy: 0.7825\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.5484 - accuracy: 0.7975\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5435 - accuracy: 0.7970\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5242 - accuracy: 0.8077\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4956 - accuracy: 0.8192\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4931 - accuracy: 0.8260\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4826 - accuracy: 0.8185\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4620 - accuracy: 0.8315\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.803 total time=   5.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 34ms/step - loss: 3.0960 - accuracy: 0.1622\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.7411 - accuracy: 0.3528\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 28ms/step - loss: 1.3376 - accuracy: 0.5390\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0801 - accuracy: 0.6220\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9412 - accuracy: 0.6605\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.8413 - accuracy: 0.6938\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7773 - accuracy: 0.7215\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7009 - accuracy: 0.7508\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.6737 - accuracy: 0.7605\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6369 - accuracy: 0.7682\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6260 - accuracy: 0.7765\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5981 - accuracy: 0.7843\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5722 - accuracy: 0.7945\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5492 - accuracy: 0.8077\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5394 - accuracy: 0.8015\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5218 - accuracy: 0.8080\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5178 - accuracy: 0.8117\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5007 - accuracy: 0.8105\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4900 - accuracy: 0.8282\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4792 - accuracy: 0.8253\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.807 total time=   5.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 34ms/step - loss: 2.3087 - accuracy: 0.2505\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.4505 - accuracy: 0.5038\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0946 - accuracy: 0.6202\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9226 - accuracy: 0.6793\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.8144 - accuracy: 0.7165\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7339 - accuracy: 0.7352\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6877 - accuracy: 0.7600\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6543 - accuracy: 0.7607\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6164 - accuracy: 0.7760\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5786 - accuracy: 0.7928\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5620 - accuracy: 0.7985\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5279 - accuracy: 0.8108\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5123 - accuracy: 0.8140\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4985 - accuracy: 0.8170\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4889 - accuracy: 0.8270\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4699 - accuracy: 0.8288\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4477 - accuracy: 0.8428\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4436 - accuracy: 0.8375\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4278 - accuracy: 0.8468\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4250 - accuracy: 0.8485\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.811 total time=   5.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.3106 - accuracy: 0.1340\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1205 - accuracy: 0.2050\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8965 - accuracy: 0.2842\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.7187 - accuracy: 0.3523\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5483 - accuracy: 0.4120\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4122 - accuracy: 0.4570\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2961 - accuracy: 0.5067\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2238 - accuracy: 0.5850\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1302 - accuracy: 0.6202\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0881 - accuracy: 0.6430\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0262 - accuracy: 0.6650\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9781 - accuracy: 0.6762\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9539 - accuracy: 0.6888\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9044 - accuracy: 0.6992\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8617 - accuracy: 0.7155\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8430 - accuracy: 0.7210\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8246 - accuracy: 0.7228\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8083 - accuracy: 0.7222\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7956 - accuracy: 0.7237\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7637 - accuracy: 0.7370\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.784 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.6553 - accuracy: 0.1385\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0030 - accuracy: 0.2550\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8122 - accuracy: 0.3450\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6459 - accuracy: 0.4210\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5366 - accuracy: 0.4527\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4635 - accuracy: 0.4810\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3726 - accuracy: 0.5100\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3246 - accuracy: 0.5310\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2785 - accuracy: 0.5458\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2162 - accuracy: 0.5690\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1808 - accuracy: 0.5807\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1329 - accuracy: 0.6000\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0827 - accuracy: 0.6175\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0648 - accuracy: 0.6295\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0388 - accuracy: 0.6342\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9913 - accuracy: 0.6510\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9518 - accuracy: 0.6743\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9225 - accuracy: 0.6775\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8988 - accuracy: 0.6910\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8765 - accuracy: 0.6880\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.777 total time=   4.7s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.4777 - accuracy: 0.1900\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8165 - accuracy: 0.3500\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5994 - accuracy: 0.4313\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4522 - accuracy: 0.4860\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3346 - accuracy: 0.5290\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2507 - accuracy: 0.5335\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1684 - accuracy: 0.5713\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0814 - accuracy: 0.6112\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0073 - accuracy: 0.6225\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9652 - accuracy: 0.6553\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9033 - accuracy: 0.6808\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8589 - accuracy: 0.6910\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8326 - accuracy: 0.7020\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7885 - accuracy: 0.7035\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7754 - accuracy: 0.7178\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7579 - accuracy: 0.7270\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7368 - accuracy: 0.7305\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7155 - accuracy: 0.7420\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6893 - accuracy: 0.7550\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6802 - accuracy: 0.7585\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.793 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.6842 - accuracy: 0.1778\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7419 - accuracy: 0.3975\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.4875 - accuracy: 0.5045\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3092 - accuracy: 0.5780\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1660 - accuracy: 0.6360\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0703 - accuracy: 0.6660\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9870 - accuracy: 0.6777\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9251 - accuracy: 0.7003\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8792 - accuracy: 0.7132\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8355 - accuracy: 0.7310\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7816 - accuracy: 0.7467\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7739 - accuracy: 0.7555\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7475 - accuracy: 0.7495\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7156 - accuracy: 0.7673\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6853 - accuracy: 0.7710\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6649 - accuracy: 0.7885\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6426 - accuracy: 0.7835\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6186 - accuracy: 0.7870\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5871 - accuracy: 0.8108\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5743 - accuracy: 0.8008\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.799 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.9268 - accuracy: 0.1593\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9012 - accuracy: 0.3190\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5707 - accuracy: 0.4563\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.3090 - accuracy: 0.5630\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1766 - accuracy: 0.5955\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0472 - accuracy: 0.6332\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9739 - accuracy: 0.6595\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9267 - accuracy: 0.6820\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8679 - accuracy: 0.6920\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8339 - accuracy: 0.7135\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7832 - accuracy: 0.7247\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7368 - accuracy: 0.7483\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7029 - accuracy: 0.7542\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6978 - accuracy: 0.7595\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6605 - accuracy: 0.7768\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6414 - accuracy: 0.7835\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6131 - accuracy: 0.7847\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6060 - accuracy: 0.7897\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5976 - accuracy: 0.7962\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5735 - accuracy: 0.7965\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.805 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.0255 - accuracy: 0.1723\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9171 - accuracy: 0.2767\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.6142 - accuracy: 0.3963\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.4103 - accuracy: 0.4905\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2637 - accuracy: 0.5545\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1431 - accuracy: 0.5972\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0219 - accuracy: 0.6488\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9587 - accuracy: 0.6630\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8782 - accuracy: 0.6998\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8299 - accuracy: 0.7132\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7804 - accuracy: 0.7290\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7444 - accuracy: 0.7400\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7000 - accuracy: 0.7585\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6770 - accuracy: 0.7665\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6373 - accuracy: 0.7715\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6144 - accuracy: 0.7895\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5862 - accuracy: 0.7922\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5896 - accuracy: 0.7987\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5563 - accuracy: 0.8070\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5391 - accuracy: 0.8127\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.802 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.7847 - accuracy: 0.2772\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3643 - accuracy: 0.5447\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0200 - accuracy: 0.6500\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8593 - accuracy: 0.6973\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7538 - accuracy: 0.7405\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7033 - accuracy: 0.7577\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6505 - accuracy: 0.7667\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6135 - accuracy: 0.7793\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5642 - accuracy: 0.8012\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5519 - accuracy: 0.8055\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5353 - accuracy: 0.8070\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5004 - accuracy: 0.8240\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4949 - accuracy: 0.8260\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4710 - accuracy: 0.8278\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4598 - accuracy: 0.8292\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4455 - accuracy: 0.8428\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4255 - accuracy: 0.8472\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4180 - accuracy: 0.8530\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4126 - accuracy: 0.8553\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3817 - accuracy: 0.8602\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.816 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.1372 - accuracy: 0.3293\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1898 - accuracy: 0.5995\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9431 - accuracy: 0.6817\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8182 - accuracy: 0.7185\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7197 - accuracy: 0.7548\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6604 - accuracy: 0.7697\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5995 - accuracy: 0.7993\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5545 - accuracy: 0.8127\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5265 - accuracy: 0.8213\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5039 - accuracy: 0.8217\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4604 - accuracy: 0.8388\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4524 - accuracy: 0.8460\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4266 - accuracy: 0.8490\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4137 - accuracy: 0.8547\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3959 - accuracy: 0.8625\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3847 - accuracy: 0.8618\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3747 - accuracy: 0.8673\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3527 - accuracy: 0.8767\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3374 - accuracy: 0.8815\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3221 - accuracy: 0.8867\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.830 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.5023 - accuracy: 0.2600\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4237 - accuracy: 0.5065\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1252 - accuracy: 0.6183\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9416 - accuracy: 0.6790\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8229 - accuracy: 0.7182\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7466 - accuracy: 0.7470\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6806 - accuracy: 0.7638\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6311 - accuracy: 0.7763\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5836 - accuracy: 0.7997\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5615 - accuracy: 0.7975\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5422 - accuracy: 0.8083\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5101 - accuracy: 0.8198\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4849 - accuracy: 0.8275\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4605 - accuracy: 0.8370\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4490 - accuracy: 0.8410\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4344 - accuracy: 0.8455\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4221 - accuracy: 0.8535\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4016 - accuracy: 0.8550\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3971 - accuracy: 0.8612\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3798 - accuracy: 0.8677\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.25, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.819 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 7.7497 - accuracy: 0.1028\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 3.0621 - accuracy: 0.1380\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.4256 - accuracy: 0.1650\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2682 - accuracy: 0.1928\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2269 - accuracy: 0.1900\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1479 - accuracy: 0.2175\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1168 - accuracy: 0.1937\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0696 - accuracy: 0.2305\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0461 - accuracy: 0.2620\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0289 - accuracy: 0.2693\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9895 - accuracy: 0.2887\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.9766 - accuracy: 0.2870\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9304 - accuracy: 0.2937\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9137 - accuracy: 0.2962\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8933 - accuracy: 0.3142\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8782 - accuracy: 0.3100\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8383 - accuracy: 0.3200\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.8203 - accuracy: 0.3442\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7972 - accuracy: 0.3577\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7811 - accuracy: 0.3500\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.487 total time=   3.9s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 4.5535 - accuracy: 0.1152\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.5819 - accuracy: 0.1710\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2413 - accuracy: 0.1900\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.1317 - accuracy: 0.2215\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0586 - accuracy: 0.2630\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.9917 - accuracy: 0.2898\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8917 - accuracy: 0.3220\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8619 - accuracy: 0.3220\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8046 - accuracy: 0.3460\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7460 - accuracy: 0.3740\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6975 - accuracy: 0.3755\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6509 - accuracy: 0.4002\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6210 - accuracy: 0.4040\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5654 - accuracy: 0.4202\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5359 - accuracy: 0.4375\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4947 - accuracy: 0.4545\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4757 - accuracy: 0.4622\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4326 - accuracy: 0.4730\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4118 - accuracy: 0.4868\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3872 - accuracy: 0.4925\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.717 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 4.0444 - accuracy: 0.1408\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.3302 - accuracy: 0.1842\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1787 - accuracy: 0.2042\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0566 - accuracy: 0.2350\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9768 - accuracy: 0.2677\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8959 - accuracy: 0.3083\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8448 - accuracy: 0.3220\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7903 - accuracy: 0.3460\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7331 - accuracy: 0.3555\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6784 - accuracy: 0.3918\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6247 - accuracy: 0.4112\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5730 - accuracy: 0.4105\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5418 - accuracy: 0.4257\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4912 - accuracy: 0.4575\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4476 - accuracy: 0.4602\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4217 - accuracy: 0.4820\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3792 - accuracy: 0.5070\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3421 - accuracy: 0.5080\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3329 - accuracy: 0.5207\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2998 - accuracy: 0.5422\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.700 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 4.1122 - accuracy: 0.1275\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2067 - accuracy: 0.2165\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0273 - accuracy: 0.2625\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.9580 - accuracy: 0.2865\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8659 - accuracy: 0.3130\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8145 - accuracy: 0.3302\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7487 - accuracy: 0.3665\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6834 - accuracy: 0.3938\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6615 - accuracy: 0.4000\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5984 - accuracy: 0.4227\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5516 - accuracy: 0.4437\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5025 - accuracy: 0.4575\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4459 - accuracy: 0.4793\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4145 - accuracy: 0.4997\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3840 - accuracy: 0.5092\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3525 - accuracy: 0.5245\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3248 - accuracy: 0.5380\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3075 - accuracy: 0.5452\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2695 - accuracy: 0.5520\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2453 - accuracy: 0.5590\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.609 total time=   4.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.9802 - accuracy: 0.1265\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2804 - accuracy: 0.1472\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.2084 - accuracy: 0.1908\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1524 - accuracy: 0.2192\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0731 - accuracy: 0.2445\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9824 - accuracy: 0.2783\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8975 - accuracy: 0.3065\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8121 - accuracy: 0.3417\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7357 - accuracy: 0.3740\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6784 - accuracy: 0.3930\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5776 - accuracy: 0.4300\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5164 - accuracy: 0.4495\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4023 - accuracy: 0.4860\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3397 - accuracy: 0.5123\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2985 - accuracy: 0.5405\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2247 - accuracy: 0.5650\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1651 - accuracy: 0.5888\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1272 - accuracy: 0.5932\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0748 - accuracy: 0.6115\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0447 - accuracy: 0.6275\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.743 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 3.8685 - accuracy: 0.1045\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.3321 - accuracy: 0.1433\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1435 - accuracy: 0.1978\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0324 - accuracy: 0.2292\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9327 - accuracy: 0.2730\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8258 - accuracy: 0.3085\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7357 - accuracy: 0.3525\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6466 - accuracy: 0.3885\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5600 - accuracy: 0.4387\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4513 - accuracy: 0.4742\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4082 - accuracy: 0.4848\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3340 - accuracy: 0.5195\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2904 - accuracy: 0.5422\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2413 - accuracy: 0.5625\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1973 - accuracy: 0.5723\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1492 - accuracy: 0.5968\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0955 - accuracy: 0.6165\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0658 - accuracy: 0.6323\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0370 - accuracy: 0.6310\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0115 - accuracy: 0.6515\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.740 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 2.6103 - accuracy: 0.1735\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0181 - accuracy: 0.2615\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8144 - accuracy: 0.3372\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6698 - accuracy: 0.3943\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5311 - accuracy: 0.4663\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4041 - accuracy: 0.5175\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3301 - accuracy: 0.5425\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2218 - accuracy: 0.5790\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1209 - accuracy: 0.6230\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0381 - accuracy: 0.6540\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9619 - accuracy: 0.6777\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8975 - accuracy: 0.6990\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8549 - accuracy: 0.7132\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8166 - accuracy: 0.7278\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7727 - accuracy: 0.7410\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7614 - accuracy: 0.7393\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7206 - accuracy: 0.7600\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6983 - accuracy: 0.7595\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6735 - accuracy: 0.7722\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6717 - accuracy: 0.7713\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.789 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 3.0337 - accuracy: 0.1482\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.1197 - accuracy: 0.2550\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9496 - accuracy: 0.2988\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7979 - accuracy: 0.3560\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7071 - accuracy: 0.3832\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5917 - accuracy: 0.4182\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4940 - accuracy: 0.4618\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3894 - accuracy: 0.5075\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2609 - accuracy: 0.5465\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1864 - accuracy: 0.5748\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1060 - accuracy: 0.6010\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0482 - accuracy: 0.6235\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0065 - accuracy: 0.6375\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9454 - accuracy: 0.6530\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9096 - accuracy: 0.6587\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8683 - accuracy: 0.6700\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8501 - accuracy: 0.6705\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8183 - accuracy: 0.6935\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7955 - accuracy: 0.6917\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7855 - accuracy: 0.6957\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.723 total time=   4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.8132 - accuracy: 0.1480\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0433 - accuracy: 0.2570\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8493 - accuracy: 0.3298\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6974 - accuracy: 0.3755\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5746 - accuracy: 0.4297\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4738 - accuracy: 0.4575\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3345 - accuracy: 0.5132\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2649 - accuracy: 0.5477\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1737 - accuracy: 0.5798\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0944 - accuracy: 0.6053\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0327 - accuracy: 0.6310\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0021 - accuracy: 0.6515\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9505 - accuracy: 0.6620\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8985 - accuracy: 0.6727\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8756 - accuracy: 0.6913\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8353 - accuracy: 0.7060\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7873 - accuracy: 0.7157\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7829 - accuracy: 0.7225\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7449 - accuracy: 0.7372\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7412 - accuracy: 0.7343\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.789 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.8641 - accuracy: 0.1740\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9850 - accuracy: 0.2670\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7922 - accuracy: 0.3185\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6832 - accuracy: 0.3478\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5985 - accuracy: 0.3783\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5199 - accuracy: 0.4087\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4425 - accuracy: 0.4285\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4026 - accuracy: 0.4557\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3589 - accuracy: 0.4870\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3347 - accuracy: 0.4860\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2750 - accuracy: 0.5175\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2594 - accuracy: 0.5260\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2239 - accuracy: 0.5523\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1922 - accuracy: 0.5655\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1980 - accuracy: 0.5520\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1819 - accuracy: 0.5608\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1298 - accuracy: 0.5918\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1214 - accuracy: 0.5928\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1105 - accuracy: 0.5838\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0732 - accuracy: 0.5943\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.767 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.9723 - accuracy: 0.1347\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0889 - accuracy: 0.2093\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9376 - accuracy: 0.2812\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8630 - accuracy: 0.3183\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7824 - accuracy: 0.3490\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7507 - accuracy: 0.3647\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7023 - accuracy: 0.3963\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6634 - accuracy: 0.4140\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6143 - accuracy: 0.4430\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5698 - accuracy: 0.4697\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5644 - accuracy: 0.4667\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5236 - accuracy: 0.4947\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4808 - accuracy: 0.5155\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4586 - accuracy: 0.5272\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4409 - accuracy: 0.5132\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4177 - accuracy: 0.5203\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3663 - accuracy: 0.5318\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3682 - accuracy: 0.5335\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3410 - accuracy: 0.5385\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3400 - accuracy: 0.5365\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.739 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.1133 - accuracy: 0.1395\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0799 - accuracy: 0.2170\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.9737 - accuracy: 0.2707\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8664 - accuracy: 0.3288\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.7926 - accuracy: 0.3610\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7336 - accuracy: 0.3880\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6605 - accuracy: 0.4103\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5986 - accuracy: 0.4462\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5887 - accuracy: 0.4387\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5332 - accuracy: 0.4582\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4710 - accuracy: 0.4840\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4983 - accuracy: 0.4712\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4560 - accuracy: 0.4882\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4043 - accuracy: 0.4963\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3699 - accuracy: 0.5067\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3551 - accuracy: 0.5180\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3510 - accuracy: 0.5105\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3332 - accuracy: 0.5195\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2918 - accuracy: 0.5330\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2649 - accuracy: 0.5395\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.740 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.7801 - accuracy: 0.1702\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9355 - accuracy: 0.3250\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7480 - accuracy: 0.3803\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.6088 - accuracy: 0.4315\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5113 - accuracy: 0.4572\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3981 - accuracy: 0.5138\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2992 - accuracy: 0.5470\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2201 - accuracy: 0.5713\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1695 - accuracy: 0.5855\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0994 - accuracy: 0.6100\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0628 - accuracy: 0.6342\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9958 - accuracy: 0.6500\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9667 - accuracy: 0.6618\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9540 - accuracy: 0.6747\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8987 - accuracy: 0.6915\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8879 - accuracy: 0.6910\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8615 - accuracy: 0.6967\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8267 - accuracy: 0.7045\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8156 - accuracy: 0.7095\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7938 - accuracy: 0.7163\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.786 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.5725 - accuracy: 0.1762\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0235 - accuracy: 0.2870\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7968 - accuracy: 0.3598\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6626 - accuracy: 0.3963\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5445 - accuracy: 0.4543\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.4388 - accuracy: 0.4873\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.3760 - accuracy: 0.5150\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2690 - accuracy: 0.5500\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2210 - accuracy: 0.5742\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1556 - accuracy: 0.5895\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1089 - accuracy: 0.6137\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0737 - accuracy: 0.6227\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0449 - accuracy: 0.6323\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0222 - accuracy: 0.6415\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9833 - accuracy: 0.6507\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9730 - accuracy: 0.6463\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9325 - accuracy: 0.6590\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8824 - accuracy: 0.6770\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8880 - accuracy: 0.6755\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8630 - accuracy: 0.6817\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.749 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.0588 - accuracy: 0.1690\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9765 - accuracy: 0.2862\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.7940 - accuracy: 0.3445\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6416 - accuracy: 0.4013\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5060 - accuracy: 0.4600\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4183 - accuracy: 0.4840\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3356 - accuracy: 0.5295\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2547 - accuracy: 0.5587\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1860 - accuracy: 0.5757\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1221 - accuracy: 0.6040\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0940 - accuracy: 0.6062\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0572 - accuracy: 0.6277\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0008 - accuracy: 0.6495\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9712 - accuracy: 0.6492\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9457 - accuracy: 0.6697\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8985 - accuracy: 0.6718\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8977 - accuracy: 0.6888\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8733 - accuracy: 0.6915\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8496 - accuracy: 0.6933\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8239 - accuracy: 0.6973\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.773 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 2.6195 - accuracy: 0.1900\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.8504 - accuracy: 0.3512\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.5838 - accuracy: 0.4470\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.3532 - accuracy: 0.5232\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.2003 - accuracy: 0.5720\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0911 - accuracy: 0.6235\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.0136 - accuracy: 0.6475\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9433 - accuracy: 0.6660\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9114 - accuracy: 0.6888\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8501 - accuracy: 0.7092\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8003 - accuracy: 0.7247\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7782 - accuracy: 0.7370\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7546 - accuracy: 0.7303\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7245 - accuracy: 0.7470\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6955 - accuracy: 0.7580\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6812 - accuracy: 0.7570\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6604 - accuracy: 0.7713\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6513 - accuracy: 0.7753\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6151 - accuracy: 0.7843\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6364 - accuracy: 0.7790\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.809 total time=   4.8s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.8375 - accuracy: 0.1790\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.8862 - accuracy: 0.3298\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.6402 - accuracy: 0.4125\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.4251 - accuracy: 0.4935\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2590 - accuracy: 0.5487\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.1312 - accuracy: 0.6033\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0173 - accuracy: 0.6490\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9579 - accuracy: 0.6612\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8982 - accuracy: 0.6877\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8593 - accuracy: 0.7048\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8079 - accuracy: 0.7153\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7805 - accuracy: 0.7272\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7556 - accuracy: 0.7350\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7146 - accuracy: 0.7530\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7097 - accuracy: 0.7440\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6935 - accuracy: 0.7533\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6520 - accuracy: 0.7678\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6723 - accuracy: 0.7650\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6427 - accuracy: 0.7692\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6228 - accuracy: 0.7812\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.806 total time=   4.8s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 3.2634 - accuracy: 0.1813\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.8993 - accuracy: 0.3368\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.6247 - accuracy: 0.4412\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.4257 - accuracy: 0.5070\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2818 - accuracy: 0.5575\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.1774 - accuracy: 0.5965\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1060 - accuracy: 0.6150\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0362 - accuracy: 0.6528\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9832 - accuracy: 0.6647\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9188 - accuracy: 0.6852\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8688 - accuracy: 0.7135\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8519 - accuracy: 0.7097\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8300 - accuracy: 0.7178\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7814 - accuracy: 0.7325\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7559 - accuracy: 0.7383\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7181 - accuracy: 0.7588\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7152 - accuracy: 0.7492\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6880 - accuracy: 0.7605\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6842 - accuracy: 0.7588\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6604 - accuracy: 0.7738\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.774 total time=   4.8s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 4.0467 - accuracy: 0.1565\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9430 - accuracy: 0.2800\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7795 - accuracy: 0.3160\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6813 - accuracy: 0.3697\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6244 - accuracy: 0.3940\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5275 - accuracy: 0.4365\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4853 - accuracy: 0.4577\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4107 - accuracy: 0.4790\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4051 - accuracy: 0.4820\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.3380 - accuracy: 0.5102\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3055 - accuracy: 0.5167\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2771 - accuracy: 0.5385\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2575 - accuracy: 0.5320\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2376 - accuracy: 0.5375\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2090 - accuracy: 0.5462\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1773 - accuracy: 0.5623\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1606 - accuracy: 0.5727\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1546 - accuracy: 0.5673\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1149 - accuracy: 0.5805\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1031 - accuracy: 0.5950\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.769 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.3773 - accuracy: 0.1290\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0111 - accuracy: 0.2320\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8573 - accuracy: 0.2952\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7584 - accuracy: 0.3327\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6668 - accuracy: 0.3690\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6066 - accuracy: 0.3932\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5448 - accuracy: 0.4173\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4506 - accuracy: 0.4363\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4220 - accuracy: 0.4593\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3610 - accuracy: 0.4940\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3297 - accuracy: 0.5023\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2832 - accuracy: 0.5100\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2574 - accuracy: 0.5357\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2536 - accuracy: 0.5372\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2062 - accuracy: 0.5543\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2038 - accuracy: 0.5577\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1480 - accuracy: 0.5817\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1234 - accuracy: 0.5780\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0694 - accuracy: 0.5975\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0492 - accuracy: 0.6210\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.782 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 3.4603 - accuracy: 0.1245\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0417 - accuracy: 0.2313\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8990 - accuracy: 0.2733\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7718 - accuracy: 0.3273\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6676 - accuracy: 0.3730\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5396 - accuracy: 0.4290\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4814 - accuracy: 0.4510\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4181 - accuracy: 0.4708\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3713 - accuracy: 0.4947\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3257 - accuracy: 0.5077\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2957 - accuracy: 0.5098\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2751 - accuracy: 0.5213\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2628 - accuracy: 0.5080\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2225 - accuracy: 0.5345\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1427 - accuracy: 0.5753\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1428 - accuracy: 0.5835\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1156 - accuracy: 0.5835\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1044 - accuracy: 0.5872\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0842 - accuracy: 0.5870\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0736 - accuracy: 0.5943\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.777 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.7085 - accuracy: 0.2222\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7102 - accuracy: 0.3815\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4471 - accuracy: 0.4843\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2968 - accuracy: 0.5443\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2006 - accuracy: 0.5740\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1179 - accuracy: 0.6070\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0480 - accuracy: 0.6360\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9938 - accuracy: 0.6500\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9451 - accuracy: 0.6727\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9063 - accuracy: 0.6805\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8451 - accuracy: 0.7010\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8205 - accuracy: 0.7107\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8094 - accuracy: 0.7117\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7527 - accuracy: 0.7293\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7597 - accuracy: 0.7372\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7399 - accuracy: 0.7418\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7216 - accuracy: 0.7412\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7014 - accuracy: 0.7415\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6851 - accuracy: 0.7577\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6677 - accuracy: 0.7697\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.796 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.1351 - accuracy: 0.1715\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8846 - accuracy: 0.3260\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.6492 - accuracy: 0.4040\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.5155 - accuracy: 0.4640\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3774 - accuracy: 0.5157\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2721 - accuracy: 0.5460\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1628 - accuracy: 0.5920\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1025 - accuracy: 0.6005\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0506 - accuracy: 0.6225\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9953 - accuracy: 0.6435\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9430 - accuracy: 0.6635\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9399 - accuracy: 0.6587\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8954 - accuracy: 0.6727\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8934 - accuracy: 0.6760\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8712 - accuracy: 0.6830\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8362 - accuracy: 0.6963\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8159 - accuracy: 0.7023\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7875 - accuracy: 0.7200\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7844 - accuracy: 0.7150\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7487 - accuracy: 0.7218\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.792 total time=   4.8s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.9799 - accuracy: 0.2138\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8571 - accuracy: 0.3632\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6485 - accuracy: 0.4428\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5034 - accuracy: 0.4975\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3839 - accuracy: 0.5375\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2743 - accuracy: 0.5727\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1921 - accuracy: 0.5918\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1008 - accuracy: 0.6215\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0640 - accuracy: 0.6283\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0103 - accuracy: 0.6457\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9597 - accuracy: 0.6565\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9243 - accuracy: 0.6745\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9121 - accuracy: 0.6810\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8690 - accuracy: 0.6973\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8518 - accuracy: 0.7007\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8033 - accuracy: 0.7165\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7750 - accuracy: 0.7300\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7677 - accuracy: 0.7245\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7695 - accuracy: 0.7290\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7390 - accuracy: 0.7380\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.807 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.5794 - accuracy: 0.2315\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5200 - accuracy: 0.4667\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2008 - accuracy: 0.5870\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0223 - accuracy: 0.6535\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9177 - accuracy: 0.6910\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8533 - accuracy: 0.7095\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7911 - accuracy: 0.7237\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7361 - accuracy: 0.7502\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6860 - accuracy: 0.7645\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6640 - accuracy: 0.7675\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6437 - accuracy: 0.7775\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6286 - accuracy: 0.7772\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6141 - accuracy: 0.7818\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5840 - accuracy: 0.7947\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5748 - accuracy: 0.7925\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5511 - accuracy: 0.8138\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5420 - accuracy: 0.8045\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5279 - accuracy: 0.8135\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5178 - accuracy: 0.8148\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5090 - accuracy: 0.8215\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.821 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.2365 - accuracy: 0.2210\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7557 - accuracy: 0.4165\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4250 - accuracy: 0.5235\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2607 - accuracy: 0.5807\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1242 - accuracy: 0.6215\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0339 - accuracy: 0.6515\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9518 - accuracy: 0.6747\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9009 - accuracy: 0.6980\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8386 - accuracy: 0.7175\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7765 - accuracy: 0.7372\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7488 - accuracy: 0.7465\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7225 - accuracy: 0.7527\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6942 - accuracy: 0.7600\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6590 - accuracy: 0.7747\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6443 - accuracy: 0.7837\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6407 - accuracy: 0.7810\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6345 - accuracy: 0.7893\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6160 - accuracy: 0.7832\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5850 - accuracy: 0.7983\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5788 - accuracy: 0.8065\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.811 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.7261 - accuracy: 0.2253\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5895 - accuracy: 0.4482\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2932 - accuracy: 0.5580\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1365 - accuracy: 0.6225\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0410 - accuracy: 0.6525\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9348 - accuracy: 0.6858\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8952 - accuracy: 0.6990\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8161 - accuracy: 0.7287\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7935 - accuracy: 0.7272\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7394 - accuracy: 0.7505\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7141 - accuracy: 0.7498\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6935 - accuracy: 0.7588\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6680 - accuracy: 0.7680\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6385 - accuracy: 0.7795\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6329 - accuracy: 0.7795\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6193 - accuracy: 0.7880\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5904 - accuracy: 0.7943\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5876 - accuracy: 0.7965\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5607 - accuracy: 0.8077\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5639 - accuracy: 0.8012\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=2, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.816 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 2.4087 - accuracy: 0.1175\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2247 - accuracy: 0.1573\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.1356 - accuracy: 0.2037\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0655 - accuracy: 0.2360\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.9454 - accuracy: 0.2785\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8460 - accuracy: 0.3067\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7314 - accuracy: 0.3575\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6274 - accuracy: 0.4123\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5393 - accuracy: 0.4482\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4329 - accuracy: 0.4868\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4060 - accuracy: 0.4785\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3507 - accuracy: 0.5077\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3435 - accuracy: 0.5025\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2592 - accuracy: 0.5385\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2636 - accuracy: 0.5325\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2316 - accuracy: 0.5345\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2024 - accuracy: 0.5487\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1871 - accuracy: 0.5508\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1688 - accuracy: 0.5595\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1547 - accuracy: 0.5667\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.746 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 2.9372 - accuracy: 0.1273\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2498 - accuracy: 0.1528\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1988 - accuracy: 0.1597\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1416 - accuracy: 0.1943\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0917 - accuracy: 0.2023\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0437 - accuracy: 0.2138\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9985 - accuracy: 0.2400\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9416 - accuracy: 0.2570\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9138 - accuracy: 0.2578\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8602 - accuracy: 0.2755\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7949 - accuracy: 0.3010\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.7571 - accuracy: 0.3185\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7241 - accuracy: 0.3275\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6891 - accuracy: 0.3350\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6341 - accuracy: 0.3613\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5870 - accuracy: 0.3923\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5345 - accuracy: 0.4055\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4935 - accuracy: 0.4397\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4586 - accuracy: 0.4473\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4246 - accuracy: 0.4630\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.670 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 3.1491 - accuracy: 0.1180\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.3083 - accuracy: 0.1548\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1958 - accuracy: 0.1708\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1586 - accuracy: 0.1960\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0964 - accuracy: 0.2165\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0251 - accuracy: 0.2495\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9607 - accuracy: 0.2627\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9093 - accuracy: 0.2875\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8288 - accuracy: 0.3330\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7750 - accuracy: 0.3492\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6943 - accuracy: 0.3828\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6612 - accuracy: 0.3968\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5939 - accuracy: 0.4180\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5566 - accuracy: 0.4370\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5076 - accuracy: 0.4460\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4377 - accuracy: 0.4760\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3957 - accuracy: 0.4945\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3587 - accuracy: 0.5065\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3185 - accuracy: 0.5282\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3090 - accuracy: 0.5303\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.710 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.1227 - accuracy: 0.1075\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2423 - accuracy: 0.1612\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0744 - accuracy: 0.2300\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9606 - accuracy: 0.3018\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8608 - accuracy: 0.3383\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7943 - accuracy: 0.3717\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7265 - accuracy: 0.3925\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6542 - accuracy: 0.4333\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5721 - accuracy: 0.4728\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5247 - accuracy: 0.4658\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4286 - accuracy: 0.4947\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3542 - accuracy: 0.5107\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2874 - accuracy: 0.5345\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2085 - accuracy: 0.5575\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1303 - accuracy: 0.5865\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0647 - accuracy: 0.6087\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0238 - accuracy: 0.6300\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9810 - accuracy: 0.6455\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9520 - accuracy: 0.6562\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9328 - accuracy: 0.6670\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.760 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.8126 - accuracy: 0.1425\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2878 - accuracy: 0.2015\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0380 - accuracy: 0.2697\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8973 - accuracy: 0.3223\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7907 - accuracy: 0.3485\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6690 - accuracy: 0.4030\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5546 - accuracy: 0.4473\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4800 - accuracy: 0.4667\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3883 - accuracy: 0.4965\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3306 - accuracy: 0.5173\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2377 - accuracy: 0.5485\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1744 - accuracy: 0.5803\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1276 - accuracy: 0.5945\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0926 - accuracy: 0.6112\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0675 - accuracy: 0.6127\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0043 - accuracy: 0.6440\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9899 - accuracy: 0.6543\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9663 - accuracy: 0.6643\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9235 - accuracy: 0.6858\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9153 - accuracy: 0.6815\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.744 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 2.9814 - accuracy: 0.1345\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2233 - accuracy: 0.1908\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0059 - accuracy: 0.2880\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8344 - accuracy: 0.3593\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6812 - accuracy: 0.4175\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5241 - accuracy: 0.4590\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4058 - accuracy: 0.5045\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3271 - accuracy: 0.5260\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2196 - accuracy: 0.5658\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1762 - accuracy: 0.5692\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1122 - accuracy: 0.5940\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0581 - accuracy: 0.6187\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0343 - accuracy: 0.6317\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9981 - accuracy: 0.6478\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9774 - accuracy: 0.6557\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9582 - accuracy: 0.6637\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9266 - accuracy: 0.6830\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9022 - accuracy: 0.6790\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8659 - accuracy: 0.6875\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8480 - accuracy: 0.6977\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.752 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 2.7096 - accuracy: 0.1285\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0496 - accuracy: 0.2535\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8915 - accuracy: 0.3447\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7216 - accuracy: 0.3803\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5440 - accuracy: 0.4523\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3858 - accuracy: 0.5247\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2140 - accuracy: 0.5880\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0770 - accuracy: 0.6338\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9885 - accuracy: 0.6515\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9337 - accuracy: 0.6633\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8916 - accuracy: 0.6740\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8518 - accuracy: 0.6855\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8255 - accuracy: 0.6942\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8005 - accuracy: 0.6970\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7773 - accuracy: 0.7032\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7647 - accuracy: 0.7040\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7372 - accuracy: 0.7170\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7325 - accuracy: 0.7125\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7039 - accuracy: 0.7203\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6996 - accuracy: 0.7245\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.744 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 2.4957 - accuracy: 0.1470\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0266 - accuracy: 0.2470\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8101 - accuracy: 0.3235\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5910 - accuracy: 0.4120\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4351 - accuracy: 0.4563\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2949 - accuracy: 0.5343\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1755 - accuracy: 0.5830\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0626 - accuracy: 0.6277\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9903 - accuracy: 0.6518\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9105 - accuracy: 0.6835\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8673 - accuracy: 0.6955\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8187 - accuracy: 0.7175\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7791 - accuracy: 0.7372\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7554 - accuracy: 0.7408\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7449 - accuracy: 0.7458\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7264 - accuracy: 0.7505\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7215 - accuracy: 0.7470\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6844 - accuracy: 0.7685\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6771 - accuracy: 0.7670\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6535 - accuracy: 0.7745\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.781 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 3.2682 - accuracy: 0.1480\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.1356 - accuracy: 0.2160\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9870 - accuracy: 0.2763\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7918 - accuracy: 0.3483\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5255 - accuracy: 0.4420\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3415 - accuracy: 0.5125\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1822 - accuracy: 0.5810\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0588 - accuracy: 0.6150\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9914 - accuracy: 0.6338\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9513 - accuracy: 0.6497\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9026 - accuracy: 0.6700\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8607 - accuracy: 0.6885\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8230 - accuracy: 0.7072\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7975 - accuracy: 0.7120\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7709 - accuracy: 0.7153\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7278 - accuracy: 0.7393\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7163 - accuracy: 0.7420\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7129 - accuracy: 0.7505\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6720 - accuracy: 0.7582\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6694 - accuracy: 0.7617\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.777 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.9237 - accuracy: 0.1152\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2774 - accuracy: 0.1360\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1252 - accuracy: 0.1692\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0195 - accuracy: 0.2338\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9389 - accuracy: 0.2700\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8283 - accuracy: 0.3178\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7696 - accuracy: 0.3273\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7131 - accuracy: 0.3632\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6560 - accuracy: 0.3853\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5973 - accuracy: 0.4067\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5344 - accuracy: 0.4395\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4597 - accuracy: 0.4502\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4425 - accuracy: 0.4658\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3606 - accuracy: 0.5077\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3134 - accuracy: 0.5150\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2811 - accuracy: 0.5345\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2343 - accuracy: 0.5560\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2087 - accuracy: 0.5617\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1736 - accuracy: 0.5835\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1503 - accuracy: 0.5832\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.739 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.1395 - accuracy: 0.1400\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.0556 - accuracy: 0.2410\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8477 - accuracy: 0.3150\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7619 - accuracy: 0.3360\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6831 - accuracy: 0.3545\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6201 - accuracy: 0.3688\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5620 - accuracy: 0.3870\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5082 - accuracy: 0.4110\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4811 - accuracy: 0.4257\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4286 - accuracy: 0.4423\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4013 - accuracy: 0.4618\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3525 - accuracy: 0.4882\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3217 - accuracy: 0.4950\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2828 - accuracy: 0.5102\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2512 - accuracy: 0.5157\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2204 - accuracy: 0.5452\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1806 - accuracy: 0.5608\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1700 - accuracy: 0.5635\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1622 - accuracy: 0.5692\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1185 - accuracy: 0.5807\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.744 total time=   4.7s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.5999 - accuracy: 0.1517\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1719 - accuracy: 0.1807\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0745 - accuracy: 0.2185\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9933 - accuracy: 0.2495\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9138 - accuracy: 0.2792\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8658 - accuracy: 0.3010\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8086 - accuracy: 0.3313\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7659 - accuracy: 0.3442\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7378 - accuracy: 0.3733\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7051 - accuracy: 0.4045\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6956 - accuracy: 0.4255\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6497 - accuracy: 0.4327\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6058 - accuracy: 0.4570\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5864 - accuracy: 0.4678\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5545 - accuracy: 0.4565\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5560 - accuracy: 0.4638\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5118 - accuracy: 0.4735\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4903 - accuracy: 0.4773\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4710 - accuracy: 0.5042\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4262 - accuracy: 0.5098\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.637 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.9521 - accuracy: 0.1450\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0652 - accuracy: 0.2528\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8632 - accuracy: 0.3325\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6796 - accuracy: 0.4125\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5516 - accuracy: 0.4585\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4241 - accuracy: 0.5008\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3294 - accuracy: 0.5332\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2179 - accuracy: 0.5738\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1540 - accuracy: 0.5968\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0871 - accuracy: 0.6277\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0527 - accuracy: 0.6288\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0021 - accuracy: 0.6538\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9620 - accuracy: 0.6605\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9213 - accuracy: 0.6755\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9062 - accuracy: 0.6777\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8654 - accuracy: 0.6845\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8460 - accuracy: 0.7017\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8230 - accuracy: 0.7145\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8122 - accuracy: 0.7082\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7703 - accuracy: 0.7240\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.773 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 3.8506 - accuracy: 0.1762\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1398 - accuracy: 0.2765\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9016 - accuracy: 0.3363\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7248 - accuracy: 0.3828\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6163 - accuracy: 0.4252\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4954 - accuracy: 0.4590\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3965 - accuracy: 0.4930\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2987 - accuracy: 0.5297\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2412 - accuracy: 0.5592\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1620 - accuracy: 0.5907\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0817 - accuracy: 0.6325\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0424 - accuracy: 0.6388\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0157 - accuracy: 0.6407\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9693 - accuracy: 0.6515\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9187 - accuracy: 0.6805\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8954 - accuracy: 0.6982\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.8797 - accuracy: 0.6917\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8440 - accuracy: 0.7113\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8183 - accuracy: 0.7113\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7943 - accuracy: 0.7287\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.792 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.7628 - accuracy: 0.1468\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1129 - accuracy: 0.2503\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.9644 - accuracy: 0.2860\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8042 - accuracy: 0.3515\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6887 - accuracy: 0.3935\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6092 - accuracy: 0.4175\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.4991 - accuracy: 0.4667\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4150 - accuracy: 0.4985\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3261 - accuracy: 0.5472\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2337 - accuracy: 0.5725\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1702 - accuracy: 0.5907\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1227 - accuracy: 0.6177\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0535 - accuracy: 0.6428\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0231 - accuracy: 0.6490\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9731 - accuracy: 0.6600\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9283 - accuracy: 0.6855\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8853 - accuracy: 0.6925\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8852 - accuracy: 0.6930\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8498 - accuracy: 0.7092\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8128 - accuracy: 0.7203\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.786 total time=   4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 2.7108 - accuracy: 0.1595\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.9868 - accuracy: 0.2808\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.6800 - accuracy: 0.4083\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.4154 - accuracy: 0.5155\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2123 - accuracy: 0.5720\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0575 - accuracy: 0.6400\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9611 - accuracy: 0.6665\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8945 - accuracy: 0.6865\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.8356 - accuracy: 0.7182\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7888 - accuracy: 0.7308\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7709 - accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7094 - accuracy: 0.7533\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6917 - accuracy: 0.7550\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6700 - accuracy: 0.7678\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6681 - accuracy: 0.7713\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6344 - accuracy: 0.7753\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6099 - accuracy: 0.7885\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6081 - accuracy: 0.7828\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6001 - accuracy: 0.7865\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5792 - accuracy: 0.7965\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.799 total time=   4.8s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.8826 - accuracy: 0.1355\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.9464 - accuracy: 0.3298\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.6668 - accuracy: 0.4342\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.3963 - accuracy: 0.5088\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2300 - accuracy: 0.5748\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0932 - accuracy: 0.6120\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9722 - accuracy: 0.6625\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8978 - accuracy: 0.6870\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8259 - accuracy: 0.7032\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7970 - accuracy: 0.7205\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7554 - accuracy: 0.7293\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7378 - accuracy: 0.7430\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7101 - accuracy: 0.7525\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7008 - accuracy: 0.7520\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6563 - accuracy: 0.7760\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6406 - accuracy: 0.7745\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6320 - accuracy: 0.7820\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6262 - accuracy: 0.7847\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6088 - accuracy: 0.7900\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5883 - accuracy: 0.7955\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.814 total time=   4.8s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.5565 - accuracy: 0.2033\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.7016 - accuracy: 0.3918\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.3887 - accuracy: 0.5023\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2018 - accuracy: 0.5800\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0774 - accuracy: 0.6210\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9413 - accuracy: 0.6722\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8846 - accuracy: 0.6920\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7996 - accuracy: 0.7107\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7718 - accuracy: 0.7247\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7327 - accuracy: 0.7398\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7076 - accuracy: 0.7517\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6746 - accuracy: 0.7675\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6510 - accuracy: 0.7722\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6221 - accuracy: 0.7837\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6009 - accuracy: 0.7955\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5838 - accuracy: 0.8027\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5646 - accuracy: 0.8090\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5585 - accuracy: 0.8062\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5490 - accuracy: 0.8152\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5522 - accuracy: 0.8108\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.806 total time=   4.8s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 3.4363 - accuracy: 0.1007\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1859 - accuracy: 0.1682\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1193 - accuracy: 0.2025\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0710 - accuracy: 0.2282\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0193 - accuracy: 0.2342\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9834 - accuracy: 0.2545\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9503 - accuracy: 0.2660\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9037 - accuracy: 0.2810\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8469 - accuracy: 0.3083\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8231 - accuracy: 0.3160\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7634 - accuracy: 0.3395\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7379 - accuracy: 0.3473\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6902 - accuracy: 0.3647\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6699 - accuracy: 0.3720\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6152 - accuracy: 0.3862\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5868 - accuracy: 0.4027\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5609 - accuracy: 0.4142\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5341 - accuracy: 0.4345\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4935 - accuracy: 0.4667\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4690 - accuracy: 0.4680\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.597 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.5971 - accuracy: 0.1497\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1053 - accuracy: 0.2042\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0044 - accuracy: 0.2435\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9299 - accuracy: 0.2755\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8324 - accuracy: 0.3095\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7727 - accuracy: 0.3368\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7195 - accuracy: 0.3652\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6116 - accuracy: 0.4103\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5677 - accuracy: 0.4322\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4931 - accuracy: 0.4708\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4639 - accuracy: 0.4737\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3946 - accuracy: 0.5065\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3738 - accuracy: 0.5125\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3256 - accuracy: 0.5305\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2899 - accuracy: 0.5270\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2413 - accuracy: 0.5445\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2069 - accuracy: 0.5615\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1745 - accuracy: 0.5633\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1461 - accuracy: 0.5740\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1017 - accuracy: 0.5900\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.775 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.0768 - accuracy: 0.1515\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0772 - accuracy: 0.2155\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9527 - accuracy: 0.2447\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8681 - accuracy: 0.2630\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8013 - accuracy: 0.2957\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7661 - accuracy: 0.3085\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7226 - accuracy: 0.3245\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6698 - accuracy: 0.3408\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6227 - accuracy: 0.3675\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6078 - accuracy: 0.3760\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5317 - accuracy: 0.4153\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4930 - accuracy: 0.4255\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4471 - accuracy: 0.4392\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4265 - accuracy: 0.4433\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3909 - accuracy: 0.4538\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3378 - accuracy: 0.4800\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2936 - accuracy: 0.5008\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2353 - accuracy: 0.5215\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2135 - accuracy: 0.5368\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1963 - accuracy: 0.5425\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.758 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.0425 - accuracy: 0.1565\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9178 - accuracy: 0.3120\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.6972 - accuracy: 0.3915\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5197 - accuracy: 0.4700\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3884 - accuracy: 0.5280\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2975 - accuracy: 0.5520\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2232 - accuracy: 0.5717\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1562 - accuracy: 0.6070\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0788 - accuracy: 0.6335\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0127 - accuracy: 0.6472\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9617 - accuracy: 0.6685\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9153 - accuracy: 0.6867\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8786 - accuracy: 0.6965\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8448 - accuracy: 0.7157\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8116 - accuracy: 0.7218\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7961 - accuracy: 0.7237\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7567 - accuracy: 0.73 - 0s 25ms/step - loss: 0.7497 - accuracy: 0.7377\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7353 - accuracy: 0.7387\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7206 - accuracy: 0.7477\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7134 - accuracy: 0.7450\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.802 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 3.0974 - accuracy: 0.1488\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0678 - accuracy: 0.2240\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8446 - accuracy: 0.3007\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6420 - accuracy: 0.3770\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5161 - accuracy: 0.4313\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.3844 - accuracy: 0.4625\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2803 - accuracy: 0.5195\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1947 - accuracy: 0.5487\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1298 - accuracy: 0.5828\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0703 - accuracy: 0.6008\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0118 - accuracy: 0.6275\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9807 - accuracy: 0.6355\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9357 - accuracy: 0.6618\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8914 - accuracy: 0.6775\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8697 - accuracy: 0.6865\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8399 - accuracy: 0.6982\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8171 - accuracy: 0.7038\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7962 - accuracy: 0.7210\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7747 - accuracy: 0.7218\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7542 - accuracy: 0.7345\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.794 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.6555 - accuracy: 0.1918\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9542 - accuracy: 0.3000\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7405 - accuracy: 0.3840\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5832 - accuracy: 0.4425\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4143 - accuracy: 0.5100\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3406 - accuracy: 0.5320\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2350 - accuracy: 0.5732\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1407 - accuracy: 0.6040\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0896 - accuracy: 0.6225\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0079 - accuracy: 0.6515\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9632 - accuracy: 0.6640\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9347 - accuracy: 0.6750\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9004 - accuracy: 0.6845\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8715 - accuracy: 0.7040\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8497 - accuracy: 0.7082\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8164 - accuracy: 0.7185\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8085 - accuracy: 0.7220\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7863 - accuracy: 0.7318\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7478 - accuracy: 0.7467\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7355 - accuracy: 0.7435\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.792 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.6482 - accuracy: 0.2490\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5458 - accuracy: 0.4523\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2054 - accuracy: 0.5903\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0538 - accuracy: 0.6417\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9215 - accuracy: 0.6885\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8469 - accuracy: 0.7130\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7873 - accuracy: 0.7265\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7348 - accuracy: 0.7527\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6848 - accuracy: 0.7620\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6737 - accuracy: 0.7757\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6558 - accuracy: 0.7735\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6155 - accuracy: 0.7883\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5977 - accuracy: 0.7925\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5676 - accuracy: 0.8033\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5640 - accuracy: 0.8005\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5578 - accuracy: 0.8040\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5366 - accuracy: 0.8055\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5274 - accuracy: 0.8135\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4984 - accuracy: 0.8217\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5008 - accuracy: 0.8223\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.812 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.3783 - accuracy: 0.2580\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5245 - accuracy: 0.4775\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2466 - accuracy: 0.5782\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0766 - accuracy: 0.6288\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9691 - accuracy: 0.6760\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8720 - accuracy: 0.7040\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8187 - accuracy: 0.7205\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7713 - accuracy: 0.7358\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7345 - accuracy: 0.7477\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6964 - accuracy: 0.7600\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6864 - accuracy: 0.7645\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6632 - accuracy: 0.7803\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6202 - accuracy: 0.7797\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6151 - accuracy: 0.7818\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5896 - accuracy: 0.7945\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5775 - accuracy: 0.7972\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5425 - accuracy: 0.8192\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5488 - accuracy: 0.8080\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5386 - accuracy: 0.8195\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5167 - accuracy: 0.8223\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.821 total time=   4.8s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.5934 - accuracy: 0.2362\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5821 - accuracy: 0.4493\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2728 - accuracy: 0.5713\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0771 - accuracy: 0.6310\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9683 - accuracy: 0.6705\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8749 - accuracy: 0.7060\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8154 - accuracy: 0.7258\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7730 - accuracy: 0.7310\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7058 - accuracy: 0.7605\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6742 - accuracy: 0.7615\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6641 - accuracy: 0.7715\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6330 - accuracy: 0.7788\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6162 - accuracy: 0.7878\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5690 - accuracy: 0.8070\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5538 - accuracy: 0.8077\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5467 - accuracy: 0.8105\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5246 - accuracy: 0.8135\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5177 - accuracy: 0.8185\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5141 - accuracy: 0.8242\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4872 - accuracy: 0.8290\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=3, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.811 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 2.7282 - accuracy: 0.0990\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2646 - accuracy: 0.1170\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1705 - accuracy: 0.1525\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1195 - accuracy: 0.1743\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0660 - accuracy: 0.1990\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.0101 - accuracy: 0.2335\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9883 - accuracy: 0.2253\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.9289 - accuracy: 0.2652\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.8831 - accuracy: 0.2673\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8231 - accuracy: 0.3002\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7640 - accuracy: 0.3300\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7000 - accuracy: 0.3550\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6369 - accuracy: 0.3875\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5553 - accuracy: 0.4207\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4708 - accuracy: 0.4642\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3999 - accuracy: 0.4925\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3413 - accuracy: 0.5070\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2688 - accuracy: 0.5357\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2361 - accuracy: 0.5465\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2192 - accuracy: 0.5437\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.712 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 2.4546 - accuracy: 0.1558\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1463 - accuracy: 0.1733\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0678 - accuracy: 0.2042\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9837 - accuracy: 0.2453\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9045 - accuracy: 0.2640\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8268 - accuracy: 0.3040\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7412 - accuracy: 0.3288\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6774 - accuracy: 0.3623\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6120 - accuracy: 0.3845\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5810 - accuracy: 0.3902\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4911 - accuracy: 0.4205\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4311 - accuracy: 0.4660\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3570 - accuracy: 0.4815\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3363 - accuracy: 0.4935\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2767 - accuracy: 0.5217\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2645 - accuracy: 0.5160\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2180 - accuracy: 0.5550\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1703 - accuracy: 0.5665\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1392 - accuracy: 0.5838\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1216 - accuracy: 0.5853\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.768 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 3.0321 - accuracy: 0.1182\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.3303 - accuracy: 0.1435\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1925 - accuracy: 0.1762\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1364 - accuracy: 0.2110\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.0538 - accuracy: 0.2333\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9692 - accuracy: 0.2842\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8863 - accuracy: 0.3410\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8043 - accuracy: 0.3500\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7383 - accuracy: 0.3787\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6765 - accuracy: 0.4075\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6242 - accuracy: 0.4327\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5598 - accuracy: 0.4580\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5233 - accuracy: 0.4725\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.4670 - accuracy: 0.4997\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.4285 - accuracy: 0.5145\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3745 - accuracy: 0.5272\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3392 - accuracy: 0.5293\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3001 - accuracy: 0.5525\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2710 - accuracy: 0.5552\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2256 - accuracy: 0.5713\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=16;, score=0.737 total time=   4.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 3.1955 - accuracy: 0.1255\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2560 - accuracy: 0.1940\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1062 - accuracy: 0.2320\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9947 - accuracy: 0.2702\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8603 - accuracy: 0.3153\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7829 - accuracy: 0.3385\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.7028 - accuracy: 0.3643\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5994 - accuracy: 0.4038\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5222 - accuracy: 0.4383\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4451 - accuracy: 0.4663\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3683 - accuracy: 0.5173\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2738 - accuracy: 0.5452\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2162 - accuracy: 0.5642\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1565 - accuracy: 0.5867\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0754 - accuracy: 0.6093\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0505 - accuracy: 0.6298\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0184 - accuracy: 0.6410\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9763 - accuracy: 0.6417\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9658 - accuracy: 0.6565\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9404 - accuracy: 0.6665\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.760 total time=   4.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.4810 - accuracy: 0.1485\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2655 - accuracy: 0.1895\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0542 - accuracy: 0.2465\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9528 - accuracy: 0.3015\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8393 - accuracy: 0.3525\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7207 - accuracy: 0.3963\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5824 - accuracy: 0.4473\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4690 - accuracy: 0.4965\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3777 - accuracy: 0.5272\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2938 - accuracy: 0.5490\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1995 - accuracy: 0.5820\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1521 - accuracy: 0.6012\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1020 - accuracy: 0.6192\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0531 - accuracy: 0.6300\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0169 - accuracy: 0.6447\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9789 - accuracy: 0.6503\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9345 - accuracy: 0.6737\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9194 - accuracy: 0.6877\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9152 - accuracy: 0.6837\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8815 - accuracy: 0.6905\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.764 total time=   4.1s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 3.3996 - accuracy: 0.1040\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2895 - accuracy: 0.1768\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.1013 - accuracy: 0.2282\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0040 - accuracy: 0.2670\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8524 - accuracy: 0.3200\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7403 - accuracy: 0.3623\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6385 - accuracy: 0.4072\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5597 - accuracy: 0.4363\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.4418 - accuracy: 0.4857\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3702 - accuracy: 0.5110\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2933 - accuracy: 0.5310\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2290 - accuracy: 0.5665\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1803 - accuracy: 0.5847\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1249 - accuracy: 0.6105\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1105 - accuracy: 0.6140\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0804 - accuracy: 0.6252\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0473 - accuracy: 0.6290\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9875 - accuracy: 0.6658\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9680 - accuracy: 0.6743\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9425 - accuracy: 0.6848\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=32;, score=0.765 total time=   4.2s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.7014 - accuracy: 0.1210\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0273 - accuracy: 0.2715\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7374 - accuracy: 0.3860\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4604 - accuracy: 0.4765\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2683 - accuracy: 0.5475\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1198 - accuracy: 0.6177\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0184 - accuracy: 0.6385\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9402 - accuracy: 0.6733\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8663 - accuracy: 0.6865\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8526 - accuracy: 0.6967\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8129 - accuracy: 0.7070\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7758 - accuracy: 0.7222\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7502 - accuracy: 0.7375\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7158 - accuracy: 0.7400\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6931 - accuracy: 0.7465\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6785 - accuracy: 0.7588\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6622 - accuracy: 0.7640\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6479 - accuracy: 0.7653\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6228 - accuracy: 0.7755\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6043 - accuracy: 0.7840\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.786 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.5393 - accuracy: 0.1637\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0003 - accuracy: 0.2928\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.7059 - accuracy: 0.4070\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4658 - accuracy: 0.4807\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2683 - accuracy: 0.5460\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1450 - accuracy: 0.5910\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0404 - accuracy: 0.6357\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9585 - accuracy: 0.6630\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8812 - accuracy: 0.7007\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8329 - accuracy: 0.7120\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8173 - accuracy: 0.7175\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7605 - accuracy: 0.7375\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7146 - accuracy: 0.7487\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7014 - accuracy: 0.7570\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6777 - accuracy: 0.7673\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6494 - accuracy: 0.7775\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6294 - accuracy: 0.7825\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6111 - accuracy: 0.7865\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6065 - accuracy: 0.7878\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6018 - accuracy: 0.7903\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.803 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.8819 - accuracy: 0.1475\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0326 - accuracy: 0.2503\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8590 - accuracy: 0.3230\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6703 - accuracy: 0.3940\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4867 - accuracy: 0.4515\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3347 - accuracy: 0.5095\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1820 - accuracy: 0.5655\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0474 - accuracy: 0.6140\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9484 - accuracy: 0.6480\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8822 - accuracy: 0.6823\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8347 - accuracy: 0.6948\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7973 - accuracy: 0.7140\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7617 - accuracy: 0.7193\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7074 - accuracy: 0.7477\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6988 - accuracy: 0.7510\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6794 - accuracy: 0.7542\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6472 - accuracy: 0.7695\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6301 - accuracy: 0.7745\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6232 - accuracy: 0.7768\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5974 - accuracy: 0.7835\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=16, best_MLP_denoising_autoencoder__nn2=64;, score=0.785 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 3.6222 - accuracy: 0.1058\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.3336 - accuracy: 0.1287\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1963 - accuracy: 0.1497\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1185 - accuracy: 0.1883\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0546 - accuracy: 0.2118\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9807 - accuracy: 0.2390\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8911 - accuracy: 0.2835\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8291 - accuracy: 0.3105\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7547 - accuracy: 0.3355\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7240 - accuracy: 0.3372\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6581 - accuracy: 0.3713\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5965 - accuracy: 0.3972\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5589 - accuracy: 0.4017\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5324 - accuracy: 0.4120\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4670 - accuracy: 0.4420\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4492 - accuracy: 0.4403\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4167 - accuracy: 0.4495\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3755 - accuracy: 0.4675\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3622 - accuracy: 0.4832\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3396 - accuracy: 0.5005\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.711 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.8325 - accuracy: 0.1353\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.1542 - accuracy: 0.1863\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.0528 - accuracy: 0.2128\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9600 - accuracy: 0.2525\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8898 - accuracy: 0.2682\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7983 - accuracy: 0.3212\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7216 - accuracy: 0.3550\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6574 - accuracy: 0.3735\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5872 - accuracy: 0.4078\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.5449 - accuracy: 0.4157\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4789 - accuracy: 0.4420\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4528 - accuracy: 0.4595\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3965 - accuracy: 0.4830\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3519 - accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3234 - accuracy: 0.5160\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2722 - accuracy: 0.5320\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2484 - accuracy: 0.5330\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2100 - accuracy: 0.5530\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1830 - accuracy: 0.5560\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1537 - accuracy: 0.5692\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.750 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 2.6915 - accuracy: 0.1295\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2192 - accuracy: 0.1807\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0953 - accuracy: 0.2282\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9683 - accuracy: 0.2880\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8715 - accuracy: 0.3352\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7601 - accuracy: 0.3817\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6883 - accuracy: 0.4090\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5954 - accuracy: 0.4277\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5450 - accuracy: 0.4498\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4705 - accuracy: 0.4753\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4556 - accuracy: 0.4790\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3946 - accuracy: 0.4913\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3460 - accuracy: 0.5125\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3060 - accuracy: 0.5215\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2801 - accuracy: 0.5215\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2589 - accuracy: 0.5275\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2319 - accuracy: 0.5380\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2127 - accuracy: 0.5490\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1884 - accuracy: 0.5500\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1441 - accuracy: 0.5730\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=16;, score=0.749 total time=   4.4s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.2437 - accuracy: 0.1423\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.1643 - accuracy: 0.2095\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0100 - accuracy: 0.2735\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.8556 - accuracy: 0.3450\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6970 - accuracy: 0.4100\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5624 - accuracy: 0.4658\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.4533 - accuracy: 0.5055\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3545 - accuracy: 0.5477\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2698 - accuracy: 0.5763\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1805 - accuracy: 0.6148\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1225 - accuracy: 0.6400\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0576 - accuracy: 0.6435\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0106 - accuracy: 0.6708\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9843 - accuracy: 0.6708\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9195 - accuracy: 0.7005\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8951 - accuracy: 0.6980\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8662 - accuracy: 0.7067\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8364 - accuracy: 0.7243\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8183 - accuracy: 0.7355\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7756 - accuracy: 0.7343\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.794 total time=   4.6s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.0406 - accuracy: 0.1398\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1456 - accuracy: 0.2095\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.9389 - accuracy: 0.2862\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8009 - accuracy: 0.3625\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6685 - accuracy: 0.3988\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5508 - accuracy: 0.4478\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4250 - accuracy: 0.5052\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3500 - accuracy: 0.5293\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2443 - accuracy: 0.5602\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.1955 - accuracy: 0.5845\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1420 - accuracy: 0.6122\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0932 - accuracy: 0.6265\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0510 - accuracy: 0.6365\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0203 - accuracy: 0.6565\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9968 - accuracy: 0.6472\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9379 - accuracy: 0.6825\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9236 - accuracy: 0.6800\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8853 - accuracy: 0.6982\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8868 - accuracy: 0.6975\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8531 - accuracy: 0.7115\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.801 total time=   4.9s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.4181 - accuracy: 0.1505\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9771 - accuracy: 0.2350\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7593 - accuracy: 0.3065\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.5886 - accuracy: 0.3805\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4322 - accuracy: 0.4465\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3198 - accuracy: 0.4965\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2146 - accuracy: 0.5577\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1336 - accuracy: 0.6018\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0784 - accuracy: 0.6280\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0333 - accuracy: 0.6355\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9650 - accuracy: 0.6575\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9284 - accuracy: 0.6833\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9059 - accuracy: 0.6852\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8769 - accuracy: 0.6905\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8549 - accuracy: 0.6975\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8170 - accuracy: 0.7072\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7934 - accuracy: 0.7200\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7898 - accuracy: 0.7237\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7525 - accuracy: 0.7275\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7536 - accuracy: 0.7352\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=32;, score=0.792 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 3.8003 - accuracy: 0.1535\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.9659 - accuracy: 0.3113\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.6089 - accuracy: 0.4507\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.3631 - accuracy: 0.5360\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.2099 - accuracy: 0.5960\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0816 - accuracy: 0.6435\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9670 - accuracy: 0.6775\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9079 - accuracy: 0.6963\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8285 - accuracy: 0.7172\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7824 - accuracy: 0.7310\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7447 - accuracy: 0.7437\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6952 - accuracy: 0.7660\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6736 - accuracy: 0.7707\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6544 - accuracy: 0.7765\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6457 - accuracy: 0.7828\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6198 - accuracy: 0.7900\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6050 - accuracy: 0.7925\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5764 - accuracy: 0.8048\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5554 - accuracy: 0.8073\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5583 - accuracy: 0.8043\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.795 total time=   4.9s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 2.9176 - accuracy: 0.1785\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.9066 - accuracy: 0.3440\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.5628 - accuracy: 0.4820\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.2978 - accuracy: 0.5625\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1656 - accuracy: 0.6093\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0593 - accuracy: 0.6420\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9687 - accuracy: 0.6675\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8994 - accuracy: 0.6855\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.8296 - accuracy: 0.7120\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7956 - accuracy: 0.7280\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7609 - accuracy: 0.7337\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7185 - accuracy: 0.7465\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7034 - accuracy: 0.7455\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6707 - accuracy: 0.7635\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6396 - accuracy: 0.7803\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6147 - accuracy: 0.7922\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5954 - accuracy: 0.7915\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6009 - accuracy: 0.7940\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5753 - accuracy: 0.7943\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5596 - accuracy: 0.8098\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.809 total time=   4.9s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 34ms/step - loss: 2.6293 - accuracy: 0.1443\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.0042 - accuracy: 0.2805\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1.6777 - accuracy: 0.4210\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.3839 - accuracy: 0.5293\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1818 - accuracy: 0.6047\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.0309 - accuracy: 0.6635\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9336 - accuracy: 0.6862\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.8786 - accuracy: 0.7105\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.8004 - accuracy: 0.7393\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7458 - accuracy: 0.7483\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7255 - accuracy: 0.7477\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6867 - accuracy: 0.7663\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6625 - accuracy: 0.7742\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6298 - accuracy: 0.7890\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6141 - accuracy: 0.7875\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5958 - accuracy: 0.8015\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5710 - accuracy: 0.8058\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5692 - accuracy: 0.8067\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5371 - accuracy: 0.8163\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5158 - accuracy: 0.8220\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=32, best_MLP_denoising_autoencoder__nn2=64;, score=0.805 total time=   5.0s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 29ms/step - loss: 3.2950 - accuracy: 0.1525\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1277 - accuracy: 0.2290\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0013 - accuracy: 0.2652\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9044 - accuracy: 0.3010\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8378 - accuracy: 0.3158\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.7656 - accuracy: 0.3325\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.7200 - accuracy: 0.3580\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6381 - accuracy: 0.3828\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5802 - accuracy: 0.4025\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5585 - accuracy: 0.4078\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5006 - accuracy: 0.4210\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4491 - accuracy: 0.4465\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3873 - accuracy: 0.4608\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3680 - accuracy: 0.4680\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3278 - accuracy: 0.4815\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2928 - accuracy: 0.4963\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2704 - accuracy: 0.5148\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2374 - accuracy: 0.5320\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1769 - accuracy: 0.5627\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1543 - accuracy: 0.5683\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.755 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 2.5390 - accuracy: 0.1160\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2515 - accuracy: 0.1968\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2104 - accuracy: 0.2453\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.1470 - accuracy: 0.2713\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0701 - accuracy: 0.2925\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.0272 - accuracy: 0.2738\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9098 - accuracy: 0.2792\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8016 - accuracy: 0.3210\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7058 - accuracy: 0.3530\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6103 - accuracy: 0.3885\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5339 - accuracy: 0.4212\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4823 - accuracy: 0.4425\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4365 - accuracy: 0.4593\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4169 - accuracy: 0.4688\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3469 - accuracy: 0.4920\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3203 - accuracy: 0.5017\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3099 - accuracy: 0.5113\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2614 - accuracy: 0.5315\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2335 - accuracy: 0.5485\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2237 - accuracy: 0.5403\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.731 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.7393 - accuracy: 0.1388\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.1359 - accuracy: 0.1935\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.0085 - accuracy: 0.2295\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.9305 - accuracy: 0.2780\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8538 - accuracy: 0.3038\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7801 - accuracy: 0.3525\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7178 - accuracy: 0.3700\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6388 - accuracy: 0.4000\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5422 - accuracy: 0.4360\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5099 - accuracy: 0.4455\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4070 - accuracy: 0.4865\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3579 - accuracy: 0.4918\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3533 - accuracy: 0.4873\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3039 - accuracy: 0.5055\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2596 - accuracy: 0.5170\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2222 - accuracy: 0.5310\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1805 - accuracy: 0.5360\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1806 - accuracy: 0.5468\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1454 - accuracy: 0.5540\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1220 - accuracy: 0.5585\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=16;, score=0.743 total time=   4.3s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 30ms/step - loss: 3.3228 - accuracy: 0.1340\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1416 - accuracy: 0.2185\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.9177 - accuracy: 0.2985\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7502 - accuracy: 0.3735\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5965 - accuracy: 0.4290\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4571 - accuracy: 0.4782\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3344 - accuracy: 0.5490\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2636 - accuracy: 0.5610\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1666 - accuracy: 0.5955\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0758 - accuracy: 0.6298\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0182 - accuracy: 0.6478\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9690 - accuracy: 0.6675\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9380 - accuracy: 0.6725\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8825 - accuracy: 0.6977\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8492 - accuracy: 0.7028\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7983 - accuracy: 0.7212\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7904 - accuracy: 0.7268\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7622 - accuracy: 0.7350\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7268 - accuracy: 0.7473\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7110 - accuracy: 0.7513\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.793 total time=   4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 3.2800 - accuracy: 0.1460\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0386 - accuracy: 0.2528\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8008 - accuracy: 0.3455\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6178 - accuracy: 0.4243\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.4686 - accuracy: 0.4900\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3727 - accuracy: 0.5230\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2440 - accuracy: 0.5627\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1275 - accuracy: 0.5945\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1149 - accuracy: 0.6053\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0477 - accuracy: 0.6260\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0018 - accuracy: 0.6457\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9434 - accuracy: 0.6735\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9146 - accuracy: 0.6777\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8867 - accuracy: 0.6982\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8547 - accuracy: 0.7007\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8331 - accuracy: 0.7050\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8079 - accuracy: 0.7222\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7931 - accuracy: 0.7205\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7494 - accuracy: 0.7433\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7523 - accuracy: 0.7393\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.801 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 2.9784 - accuracy: 0.1737\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.9619 - accuracy: 0.3142\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.6811 - accuracy: 0.4210\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5102 - accuracy: 0.4755\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3509 - accuracy: 0.5328\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2432 - accuracy: 0.5692\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1793 - accuracy: 0.6012\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1036 - accuracy: 0.6273\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0734 - accuracy: 0.6280\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9987 - accuracy: 0.6553\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9649 - accuracy: 0.6697\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9111 - accuracy: 0.6910\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8803 - accuracy: 0.6883\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8422 - accuracy: 0.7170\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8283 - accuracy: 0.7160\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7998 - accuracy: 0.7188\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7669 - accuracy: 0.7390\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7354 - accuracy: 0.7455\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7257 - accuracy: 0.7452\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7217 - accuracy: 0.7430\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=32;, score=0.801 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 3.0792 - accuracy: 0.1978\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8081 - accuracy: 0.3660\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.4726 - accuracy: 0.4888\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2523 - accuracy: 0.5748\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0564 - accuracy: 0.6338\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9399 - accuracy: 0.6747\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8664 - accuracy: 0.6930\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8121 - accuracy: 0.7215\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7773 - accuracy: 0.7303\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7074 - accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6714 - accuracy: 0.7660\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6577 - accuracy: 0.7763\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6164 - accuracy: 0.7845\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5940 - accuracy: 0.7878\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5785 - accuracy: 0.7980\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5670 - accuracy: 0.8092\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5397 - accuracy: 0.8112\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5349 - accuracy: 0.8177\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5082 - accuracy: 0.8213\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4951 - accuracy: 0.8298\n",
      "[CV 1/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.816 total time=   4.6s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 2.5213 - accuracy: 0.2190\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6265 - accuracy: 0.4285\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3486 - accuracy: 0.5232\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1155 - accuracy: 0.6093\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9736 - accuracy: 0.6575\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9046 - accuracy: 0.6820\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8163 - accuracy: 0.7193\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7583 - accuracy: 0.7405\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7266 - accuracy: 0.7588\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6890 - accuracy: 0.7682\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6558 - accuracy: 0.7747\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6236 - accuracy: 0.7853\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6026 - accuracy: 0.7860\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5881 - accuracy: 0.7987\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5363 - accuracy: 0.8152\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5314 - accuracy: 0.8190\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5208 - accuracy: 0.8192\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4964 - accuracy: 0.8335\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4834 - accuracy: 0.8335\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4864 - accuracy: 0.8307\n",
      "[CV 2/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.817 total time=   4.5s\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2.9084 - accuracy: 0.1655\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7903 - accuracy: 0.3697\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.4129 - accuracy: 0.5075\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1453 - accuracy: 0.6093\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9936 - accuracy: 0.6565\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8791 - accuracy: 0.6970\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7931 - accuracy: 0.7285\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7445 - accuracy: 0.7467\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6890 - accuracy: 0.7590\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6603 - accuracy: 0.7730\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6363 - accuracy: 0.7732\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6024 - accuracy: 0.7955\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5751 - accuracy: 0.7997\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5560 - accuracy: 0.8077\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5469 - accuracy: 0.8173\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5183 - accuracy: 0.8253\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5196 - accuracy: 0.8250\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4995 - accuracy: 0.8298\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4854 - accuracy: 0.8298\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4547 - accuracy: 0.8445\n",
      "[CV 3/3] END best_MLP_denoising_autoencoder__dropout_dense=0.5, best_MLP_denoising_autoencoder__n_layers=4, best_MLP_denoising_autoencoder__nn1=64, best_MLP_denoising_autoencoder__nn2=64;, score=0.809 total time=   4.5s\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 1s 28ms/step - loss: 2.9410 - accuracy: 0.2960\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 1.1987 - accuracy: 0.5943\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.9178 - accuracy: 0.6832\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.7817 - accuracy: 0.7270\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.7103 - accuracy: 0.7400\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6610 - accuracy: 0.7578\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6217 - accuracy: 0.7772\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6138 - accuracy: 0.7772\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.5689 - accuracy: 0.7932\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.5416 - accuracy: 0.8020\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.5418 - accuracy: 0.8107\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.5268 - accuracy: 0.8143\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.5050 - accuracy: 0.8233\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.4909 - accuracy: 0.8260\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.4822 - accuracy: 0.8298\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.4725 - accuracy: 0.8308\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.4551 - accuracy: 0.8378\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.4466 - accuracy: 0.8398\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.4451 - accuracy: 0.8418\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.4284 - accuracy: 0.8433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('best_MLP_denoising_autoencoder',\n",
       "                                        <keras.wrappers.scikit_learn.KerasClassifier object at 0x7fc6e19f58e0>)]),\n",
       "             param_grid={'best_MLP_denoising_autoencoder__dropout_dense': [0.1,\n",
       "                                                                           0.25,\n",
       "                                                                           0.5],\n",
       "                         'best_MLP_denoising_autoencoder__n_layers': [2, 3, 4],\n",
       "                         'best_MLP_denoising_autoencoder__nn1': [16, 32, 64],\n",
       "                         'best_MLP_denoising_autoencoder__nn2': [16, 32, 64]},\n",
       "             scoring=make_scorer(my_custom_loss_func), verbose=3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_3.fit(X_joined_train_reduced.reshape(-1, 28, 28, 1), y_joined_train_reduced, best_MLP_denoising_autoencoder__callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO: PONER EL RESULTADO DEL FIT Y EL MEJOR MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_denoising_autoencoder_CV\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 7, 7, 8)           1160      \n",
      "_________________________________________________________________\n",
      "encoder (Conv2D)             (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "flatten_309 (Flatten)        (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "Capa_Oculta_0 (Dense)        (None, 64)                25152     \n",
      "_________________________________________________________________\n",
      "Capa_Oculta_1 (Dense)        (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "Dropout_dense_0.25 (Dropout) (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Capa_Salida (Dense)          (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 31,866\n",
      "Trainable params: 31,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model_mlp_autoencoder_denoising = grid_3.best_estimator_\n",
    "best_model_mlp_autoencoder_denoising['best_MLP_denoising_autoencoder'].model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La accuracy del mejor modelo para MLP post-autoencoder denoising es:  0.824\n"
     ]
    }
   ],
   "source": [
    "best_score_mlp_autoencoder_denoising = grid_3.best_score_\n",
    "print('La accuracy del mejor modelo para MLP post-autoencoder denoising es: ', best_score_mlp_autoencoder_denoising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7495    , 0.76383333, 0.7895    , 0.783     , 0.80316667,\n",
       "       0.80733333, 0.7995    , 0.8145    , 0.81883333, 0.73183333,\n",
       "       0.7825    , 0.79      , 0.7845    , 0.79283333, 0.80916667,\n",
       "       0.76416667, 0.81      , 0.82116667, 0.728     , 0.77366667,\n",
       "       0.792     , 0.76633333, 0.795     , 0.80583333, 0.79316667,\n",
       "       0.80983333, 0.816     , 0.74916667, 0.7765    , 0.78266667,\n",
       "       0.779     , 0.79016667, 0.797     , 0.79516667, 0.80666667,\n",
       "       0.824     , 0.725     , 0.75633333, 0.79616667, 0.76283333,\n",
       "       0.8005    , 0.80983333, 0.78116667, 0.80916667, 0.8175    ,\n",
       "       0.72316667, 0.75683333, 0.79716667, 0.7645    , 0.78783333,\n",
       "       0.80716667, 0.78483333, 0.80216667, 0.8215    , 0.6345    ,\n",
       "       0.69716667, 0.767     , 0.74866667, 0.76933333, 0.79666667,\n",
       "       0.77616667, 0.79833333, 0.81616667, 0.70833333, 0.75233333,\n",
       "       0.76733333, 0.7065    , 0.78383333, 0.8065    , 0.71033333,\n",
       "       0.796     , 0.81466667, 0.73916667, 0.76316667, 0.7915    ,\n",
       "       0.73666667, 0.79616667, 0.803     , 0.74283333, 0.79866667,\n",
       "       0.81366667])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_3.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO: Comentar los resultados aquí__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "[1] <a href='tensorflow.org/datasets/catalog/fashion_mnist'>Conjunto de datos Fashion MNIST</a>\n",
    "\n",
    "[2] <a href='https://www.astesj.com/publications/ASTESJ_0601109.pdf'>Artículo: CNNs for Fashion-MNIST</a>\n",
    "\n",
    "[3] http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf\n",
    "\n",
    "[4] https://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-networks\n",
    "\n",
    "[5] https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-fashion-mnist-clothing-classification/\n",
    "\n",
    "[6] https://towardsdatascience.com/simplified-math-behind-dropout-in-deep-learning-6d50f3f47275\n",
    "\n",
    "[7] https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
    "\n",
    "[8] https://towardsdatascience.com/7-tips-to-choose-the-best-optimizer-47bb9c1219e\n",
    "\n",
    "[9] https://colab.research.google.com/github/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb#scrollTo=1ShU787gZZg0\n",
    "\n",
    "[10] http://yann.lecun.com/exdb/publis/psgz/lecun-98.ps.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
